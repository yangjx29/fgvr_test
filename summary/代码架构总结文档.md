# 细粒度视觉分类系统架构总结文档

## 系统概述

这是一个基于快慢思考机制的细粒度视觉分类（FGVR）系统，能够对图像进行高精度的细分类识别。系统采用分层架构，结合了传统的特征检索方法和现代的大型多模态语言模型（MLLM），实现了高效准确的细粒度分类。

## 核心架构组件

### 1. 主要入口文件 - discovering.py

**功能：** 系统的主要运行入口，提供多种运行模式

**支持的运行模式：**
- `identify`: 超类识别模式
- `describe`: 属性描述生成模式
- `guess`: 基于属性的类别推测模式
- `build_gallery`: 构建多模态模板库
- `build_knowledge_base`: 构建快慢思考知识库
- `classify`: 单张图像分类
- `evaluate`: 批量评估模式
- `fastonly`: 仅快思考评估
- `slowonly`: 仅慢思考评估
- `fast_slow`: 完整快慢思考评估
- `fast_slow_infer`: 快慢思考推理落盘（保存候选与中间结果）
- `fast_slow_classify`: 基于推理结果的快速分类/消融

**主要功能：**
- 命令行参数解析和配置管理
- 不同模式下的工作流程协调
- 实验结果保存和日志记录
- 测试数据集构建和评估

### 2. 多模态检索模块 - multimodal_retrieval.py

**核心类：** `MultimodalRetrieval`

**主要功能：**
- **特征提取：** 支持CLIP和BLIP模型进行图像和文本特征提取
- **特征融合：** 提供多种融合策略（concat、average、weighted、cross_attention）
- **模板库构建：** 基于K-shot样本构建类别模板库
- **相似度检索：** 使用余弦相似度进行Top-K检索
- **RAG增强推理：** 结合检索结果和MLLM进行最终分类

**特征融合方法：**
```python
- concat: 特征拼接 [img_feat, text_feat]
- average: 特征平均 (img_feat + text_feat) / 2
- weighted: 加权融合 α * text_feat + (1-α) * img_feat
- cross_atten: 使用BLIP进行跨模态注意力融合
```

**检索流程：**
1. 图像特征提取 → CLIP图像编码器
2. 文本描述生成 → CDV-Captioner
3. 文本特征提取 → CLIP文本编码器
4. 多模态特征融合 → 根据fusion_method
5. 相似度计算 → 余弦相似度
6. 亲和度计算 → R = exp(-β(1-cos_sim))
7. RAG推理 → MLLM基于Top-K候选进行最终决策

## 快慢思考系统架构

### 1. 快慢思考系统核心 - FastSlowThinkingSystem

**功能：** 整个系统的核心协调器，管理快慢思考流程

**核心组件：**
- MLLM Bot（多模态大语言模型）
- 知识库构建器（KnowledgeBaseBuilder）
- 快思考模块（FastThinking）
- 慢思考模块（SlowThinking）

**工作流程：**
```
输入图像 → 快思考 → 判断置信度 → [高] → 输出
                   ↓
                [低] → 慢思考 → 深度分析/增强检索 → [快慢一致] 直接输出
                                                  ↓
                                               [不一致] → 最终裁决(MLLM) → 输出
```

### 2. 快思考模块 - FastThinking

**设计理念：** 基于双模态检索的快速分类

**核心流程：**
1. **图像到图像检索：** 在知识库中检索相似图像
2. **图像到文本检索：** 基于图像特征检索相关文本描述
3. **结果融合：** 使用概率融合和倒数排序融合（RRF）
4. **触发判断：** 基于置信度、边际差异、Top-K重叠度等判断是否需要慢思考

**触发慢思考的条件：**
- 融合置信度 < 阈值
- Top-1与Top-2差距 < 边际阈值
- 图像检索和文本检索结果不一致
- Top-K结果重叠度低

### 3. 慢思考模块 - SlowThinking

**设计理念：** 基于MLLM的深度分析和推理

**核心流程：**
1. **困难点分析：** 使用MLLM分析图像识别的困难点
2. **关键区域提取：** 基于困难点分析提取关键视觉区域
3. **结构化描述生成：** 生成详细的结构化图像描述
4. **多模态检索：** 基于增强描述进行检索
5. **最终推理：** MLLM结合所有信息进行最终分类

### 4. 知识库构建器 - KnowledgeBaseBuilder

**功能：** 构建和管理系统的知识库

**知识库类型：**
- **图像知识库：** 存储类别的图像特征向量
- **文本知识库：** 存储类别的文本描述特征
- **类别描述库：** 存储每个类别的详细描述

**数据增强策略：**
- 亮度调整
- 对比度增强
- 饱和度调整
- 模糊处理
- 旋转变换

## 辅助模块

### 1. CDV-Captioner（类驱动视觉描述生成器）

**功能：** 生成面向分类任务的结构化图像描述

**特点：**
- 类别驱动的描述生成
- 支持区域级别的细节描述
- 结合少样本学习进行描述优化

### 2. 各类Bot模块

- **MLLMBot：** 多模态大语言模型接口
- **LLMBot：** 纯文本语言模型接口
- **VQABot：** 视觉问答模型接口

## 数据流程架构

### 训练阶段
```
训练样本 → 特征提取 → 模板库构建 → 知识库保存
         ↓
    CDV-Captioner → 描述生成 → 文本特征提取
```

### 推理阶段
```
查询图像 → 快思考流程 → 置信度判断 → [高] → 输出结果
                      ↓
                   [低] → 慢思考流程 → 深度分析 → 输出结果
```

### 评估阶段
```
测试数据集 → 批量推理 → 结果统计 → 性能指标计算
           ↓
       数据增强 → 知识库更新 → 系统优化
```

## 配置和参数管理

### 主要配置文件
- `configs/env_machine.yml`: 环境相关配置
- `configs/expts/`: 实验相关配置

### 关键参数
- `kshot`: 每类样本数量
- `region_num`: 区域选择数量
- `fusion_method`: 特征融合方法
- `confidence_threshold`: 置信度阈值
- `similarity_threshold`: 相似度阈值

## 使用示例

### 1. 构建知识库
```bash
CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=build_knowledge_base \
  --config_file_env=./configs/env_machine.yml \
  --config_file_expt=./configs/expts/dog120_all.yml \
  --knowledge_base_dir=./experiments/dog120/knowledge_base
```

### 3. 单张图像分类
```bash
CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=classify \
  --query_image=./test_image.jpg \
  --knowledge_base_dir=./experiments/dog120/knowledge_base
```

### 4. 系统评估
```bash
CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_slow \
  --test_data_dir=./test_data \
  --knowledge_base_dir=./experiments/dog120/knowledge_base
```

## 系统特点

### 优势
1. **分层架构：** 快慢思考机制提供了效率和准确性的平衡
2. **多模态融合：** 结合图像和文本信息提升分类性能
3. **自适应机制：** 根据置信度自动选择处理策略
4. **模块化设计：** 各组件独立，便于维护和扩展
5. **灵活配置：** 支持多种融合方法和参数调整

### 适用场景
- 细粒度物体分类（如宠物品种、鸟类分类等）
- 需要高准确性的视觉识别任务
- 计算资源敏感的应用场景
- 需要可解释性的分类系统

## 扩展性

系统采用模块化设计，便于扩展：
- 可以轻松替换不同的特征提取模型
- 支持添加新的融合策略
- 可以集成更多的数据增强方法
- 便于添加新的评估指标

这个系统为细粒度视觉分类提供了一个完整的解决方案，结合了传统方法的效率和深度学习方法的准确性。

## 文件-架构实现映射（按职责对照）

- discovering.py（入口与流程编排）
  - 对应架构环节：
    - 知识库构建：调用 `FastSlowThinkingSystem.build_knowledge_base`，落盘图像/文本库与统计信息（mode=build_knowledge_base）
    - 推理与评估：统一编排“快思考→触发→慢思考”的自适应流程与指标统计（mode=classify/evaluate/fastonly/slowonly/fast_slow）
    - 模板库构建：组织 K-shot 样本并调用检索子系统生成 gallery（mode=build_gallery）
    - 传统发现流程：提供 identify/describe/guess/howto/postprocess 等函数（辅助能力，默认不走主路径）
  - 关键作用：命令行入口、配置加载、数据组织、流程调度、结果落盘与日志

- retrieval/multimodal_retrieval.py（多模态检索子系统）
  - 对应架构环节：
    - 特征抽取：CLIP 图像/文本特征；可选 BLIP 进行跨注意力融合
    - 模态融合：concat/average/weighted/cross_atten 四种策略
    - 模板库（gallery）：离线构建（K-shot 平均）与在线加载
    - 相似度检索：余弦相似度/亲和度，Top-K 返回
    - RAG 判别（可选）：对 Top-K 组装提示，交由 MLLM 最终裁决
    - 批量评估：对数据集执行检索式 FGVC 并输出准确率
  - 关键作用：承担“检索与RAG交互”能力，支撑快/慢思考中与知识库的匹配与（可选）最终裁决

> 快速对照：
> - “系统编排/运行模式/评测”看 `discovering.py`
> - “特征抽取/融合/检索/RAG判别/构建gallery”看 `retrieval/multimodal_retrieval.py`
