/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Namespace(mode='fast_slow', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', num_per_category='3', kshot=None, region_num=None, superclass=None, gallery_out=None, fusion_method='concat', knowledge_base_dir='./experiments/pet37/knowledge_base', query_image=None, test_data_dir='./datasets/pet_37/images_discovery_all_1', results_out='./results/pet_fast_slow_results.json', use_slow_thinking=None, confidence_threshold=0.8, similarity_threshold=0.7, enable_mllm_intermediate_judge=False)
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'pet', 'num_classes': 37, 'num_base': 19, 'num_novel': 18, 'seed': 1, 'batch_size': 32, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'FlanT5-XXL', 'model_size_mllm': 'Qwen2.5-VL-7B', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'xiao', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/pet_37', 'expt_dir': './experiments/pet37', 'expt_dir_describe': './experiments/pet37/describe', 'path_vqa_questions': './experiments/pet37/describe/pet_vqa_questions_ours', 'path_vqa_answers': './experiments/pet37/describe/pet_attributes_pairs', 'path_llm_prompts': './experiments/pet37/describe/pet_llm_prompts', 'path_identify_answers': './experiments/pet37/identify', 'expt_dir_guess': './experiments/pet37/guess', 'path_llm_replies_raw': './experiments/pet37/guess/pet_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/pet37/guess/pet_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/pet37/guess/pet_llm_gussed_names', 'expt_dir_gallery': './experiments/pet37/gallery', 'path_references': './experiments/pet37/gallery/pet_image_references', 'path_regions': './experiments/pet37/gallery/pet_image_regions', 'path_descriptions': './experiments/pet37/gallery/pet_image_descriptions_attn', 'expt_dir_grouping': './experiments/pet37/grouping'}
åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨...
ğŸš€ èåˆæ–¹æ³•ä¸º 'weighted'ï¼Œè·³è¿‡BLIPæ¨¡å‹åŠ è½½ä»¥èŠ‚çœæ˜¾å­˜
è·å–MLLMæ¨¡å‹å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰...
ğŸš€ åˆå§‹åŒ–MLLMæ¨¡å‹: Qwen2.5-VL-7B on cuda
ğŸ“Š å½“å‰æ˜¾å­˜: 0.56GB / 47.40GB
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [09:10<36:40, 550.16s/it]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [10:40<42:41, 640.50s/it]
Traceback (most recent call last):
  File "/home/hdl/project/fgvr_test/discovering.py", line 653, in <module>
    # åˆå§‹åŒ–å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿï¼ˆå†…éƒ¨ä¼šåˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨ã€å¿«/æ…¢æ€è€ƒæ¨¡å—ã€MLLMç­‰ï¼‰
  File "/home/hdl/project/fgvr_test/fast_slow_thinking_system.py", line 69, in __init__
    self.mllm_bot = get_mllm_bot(
  File "/home/hdl/project/fgvr_test/utils/mllm_singleton.py", line 103, in get_mllm_bot
    return _mllm_manager.get_mllm_bot(model_tag, device)
  File "/home/hdl/project/fgvr_test/utils/mllm_singleton.py", line 50, in get_mllm_bot
    self._mllm_bot = MLLMBot(
  File "/home/hdl/project/fgvr_test/agents/mllm_bot.py", line 90, in __init__
    self.qwen2_5 = Qwen2_5_VLForConditionalGeneration.from_pretrained(local_model_path,
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 262, in _wrapper
    return func(*args, **kwargs)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4319, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4897, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 896, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/accelerate/utils/modeling.py", line 343, in set_module_tensor_to_device
    new_value = value.to(device, non_blocking=non_blocking)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 112.25 MiB is free. Process 2668405 has 9.21 GiB memory in use. Including non-PyTorch memory, this process has 9.21 GiB memory in use. Process 2789393 has 7.59 GiB memory in use. Process 2843693 has 21.25 GiB memory in use. Of the allocated memory 8.72 GiB is allocated by PyTorch, and 241.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
