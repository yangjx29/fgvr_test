/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/data/oldhome/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Namespace(mode='terminal_decision_enhanced', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/flower102_all.yml', num_per_category='3', knowledge_base_dir='./knowledge_base', query_image=None, test_data_dir=None, results_out='./results.json', use_slow_thinking=None, confidence_threshold=0.8, similarity_threshold=0.7, enable_mllm_intermediate_judge=False, infer_dir='./experiments/flower102/infer', classify_dir='./experiments/flower102/classify')
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'flower', 'num_classes': 102, 'num_base': 51, 'num_novel': 51, 'seed': 1, 'batch_size': 256, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'FlanT5-XXL', 'model_size_mllm': 'Qwen2.5-VL-7B', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'xiao', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/flowers_102', 'expt_dir': './experiments/flower102', 'expt_dir_describe': './experiments/flower102/describe', 'path_vqa_questions': './experiments/flower102/describe/flower_vqa_questions_ours', 'path_vqa_answers': './experiments/flower102/describe/flower_attributes_pairs', 'path_llm_prompts': './experiments/flower102/describe/flower_llm_prompts', 'path_identify_answers': './experiments/flower102/identify', 'expt_dir_guess': './experiments/flower102/guess', 'path_llm_replies_raw': './experiments/flower102/guess/flower_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/flower102/guess/flower_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/flower102/guess/flower_llm_gussed_names', 'expt_dir_gallery': './experiments/flower102/gallery', 'path_references': './experiments/flower102/gallery/flower_image_references', 'path_regions': './experiments/flower102/gallery/flower_image_regions', 'path_descriptions': './experiments/flower102/gallery/flower_image_descriptions_attn', 'expt_dir_grouping': './experiments/flower102/grouping'}
ğŸ”§ ç»ˆç«¯å†³ç­–å¢å¼ºæ¨¡å¼
ğŸ“ åˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: ./experiments/flower102/classify
ğŸ” æ£€æŸ¥å¿«æ€è€ƒå¢å¼ºç»“æœ: ./experiments/flower102/classify/fast_classification_results_enhanced.json
ğŸ” æ£€æŸ¥æ…¢æ€è€ƒå¢å¼ºç»“æœ: ./experiments/flower102/classify/slow_classification_results_enhanced.json
âœ… åŠ è½½äº† 65 ä¸ªå¢å¼ºå¿«æ€è€ƒåˆ†ç±»ç»“æœ
âœ… åŠ è½½äº† 37 ä¸ªå¢å¼ºæ…¢æ€è€ƒåˆ†ç±»ç»“æœ
ğŸ”„ æ›´æ–°å¢å¼ºç»“æœä¸­çš„is_correctå­—æ®µ...
âœ… å·²æ›´æ–°æ‰€æœ‰å¢å¼ºç»“æœçš„is_correctå­—æ®µ
ğŸ” å‘ç° 17 ä¸ªéœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
ğŸš€ å¼€å§‹å¤„ç†éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬...
åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨...
ğŸš€ èåˆæ–¹æ³•ä¸º 'weighted'ï¼Œè·³è¿‡BLIPæ¨¡å‹åŠ è½½ä»¥èŠ‚çœæ˜¾å­˜
è·å–MLLMæ¨¡å‹å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰...
ğŸš€ åˆå§‹åŒ–MLLMæ¨¡å‹: Qwen2.5-VL-7B on cuda
ğŸ“Š å½“å‰æ˜¾å­˜: 0.56GB / 47.40GB
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:07,  1.87s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:04<00:06,  2.09s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:06<00:04,  2.14s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:08<00:02,  2.16s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.63s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.84s/it]
local_model_path: ./models/Qwen/Qwen2.5-VL-7B-Instruct
âœ… MLLMæ¨¡å‹åˆå§‹åŒ–å®Œæˆ
ğŸ“Š åŠ è½½åæ˜¾å­˜: 31.59GB / 47.40GB
åˆå§‹åŒ–å¿«æ€è€ƒæ¨¡å—...
æœªæ‰¾åˆ°å†å²ç»Ÿè®¡é‡æ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹
åˆå§‹åŒ–æ…¢æ€è€ƒæ¨¡å—...
å¿«æ…¢æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!
ä» ./experiments/flower102/knowledge_base åŠ è½½çŸ¥è¯†åº“...
ç±»åˆ«å›¾åƒè·¯å¾„å·²ä» ./experiments/flower102/knowledge_base/category_image_paths.json åŠ è½½
åŠ è½½äº† 100 ä¸ªç±»åˆ«çš„å›¾åƒè·¯å¾„
çŸ¥è¯†åº“å·²ä» ./experiments/flower102/knowledge_base åŠ è½½
çŸ¥è¯†åº“åŠ è½½å®Œæˆ!
å·²åŠ è½½çŸ¥è¯†åº“: ./experiments/flower102/knowledge_base
Processing terminal decisions:   0%|          | 0/17 [00:00<?, ?it/s]/tmp/run_discovery_flower_2409281.sh: line 2: 2409436 Killed                  python discovering.py --mode=terminal_decision_enhanced --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/flower102_all.yml --infer_dir=./experiments/flower102/infer --classify_dir=./experiments/flower102/classify
