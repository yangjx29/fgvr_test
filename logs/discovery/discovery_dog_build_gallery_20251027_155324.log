/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 7504 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
  warnings.warn(
Namespace(mode='build_gallery', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/dog120_all.yml', num_per_category='3', kshot=3, region_num=3, superclass='dog', gallery_out='./experiments/dog120/gallery/dog120_gallery_concat_atten.json', fusion_method='concat', knowledge_base_dir='./knowledge_base', query_image=None, test_data_dir=None, results_out='./results.json', use_slow_thinking=None, confidence_threshold=0.8, similarity_threshold=0.7)
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'dog', 'num_classes': 120, 'num_base': 60, 'num_novel': 60, 'seed': 1, 'batch_size': 256, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'OPT6.7B-COCO', 'model_size_mllm': 'Qwen2.5-VL-7B', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'xiao', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/dogs_120', 'expt_dir': './experiments/dog120', 'expt_dir_describe': './experiments/dog120/describe', 'path_vqa_questions': './experiments/dog120/describe/dog_vqa_questions_ours', 'path_vqa_answers': './experiments/dog120/describe/dog_attributes_pairs', 'path_llm_prompts': './experiments/dog120/describe/dog_llm_prompts', 'path_identify_answers': './experiments/dog120/identify', 'expt_dir_guess': './experiments/dog120/guess', 'path_llm_replies_raw': './experiments/dog120/guess/dog_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/dog120/guess/dog_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/dog120/guess/dog_llm_gussed_names', 'expt_dir_gallery': './experiments/dog120/gallery', 'path_references': './experiments/dog120/gallery/dog_image_references', 'path_regions': './experiments/dog120/gallery/dog_image_regions', 'path_descriptions': './experiments/dog120/gallery/dog_image_descriptions_attn', 'expt_dir_grouping': './experiments/dog120/grouping'}
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [07:20<29:20, 440.17s/it]Loading checkpoint shards:  40%|████      | 2/5 [11:37<16:37, 332.43s/it]Loading checkpoint shards:  60%|██████    | 3/5 [15:56<09:57, 298.93s/it]Loading checkpoint shards:  80%|████████  | 4/5 [21:32<05:13, 313.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [22:29<00:00, 221.02s/it]Loading checkpoint shards: 100%|██████████| 5/5 [22:29<00:00, 269.85s/it]
local_model_path: /home/Dataset/Models/Qwen/Qwen2.5-VL-7B-Instruct
Traceback (most recent call last):
  File "/home/hdl/project/fgvr_test/discovering.py", line 741, in <module>
    mllm_bot = MLLMBot(
  File "/home/hdl/project/fgvr_test/cvd/cdv_captioner.py", line 34, in __init__
    self.clip_model = CLIPModel.from_pretrained(image_encoder_name).to(self.device)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3162, in to
    return super().to(*args, **kwargs)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1369, in to
    return self._apply(convert)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torch/nn/modules/module.py", line 928, in _apply
    module._apply(fn)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torch/nn/modules/module.py", line 928, in _apply
    module._apply(fn)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torch/nn/modules/module.py", line 928, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torch/nn/modules/module.py", line 955, in _apply
    param_applied = fn(param)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1355, in convert
    return t.to(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 5.62 MiB is free. Process 3002764 has 44.41 GiB memory in use. Process 171219 has 502.00 MiB memory in use. Process 313468 has 260.00 MiB memory in use. Process 852681 has 748.00 MiB memory in use. Including non-PyTorch memory, this process has 748.00 MiB memory in use. Process 862594 has 748.00 MiB memory in use. Of the allocated memory 457.41 MiB is allocated by PyTorch, and 30.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
