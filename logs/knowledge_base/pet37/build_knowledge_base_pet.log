/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Namespace(mode='build_knowledge_base', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', num_per_category='1', kshot=None, region_num=None, superclass=None, gallery_out=None, fusion_method='concat', knowledge_base_dir='./experiments/pet37/knowledge_base', query_image=None, test_data_dir=None, results_out='./results.json', use_slow_thinking=None, confidence_threshold=0.8, similarity_threshold=0.7, enable_mllm_intermediate_judge=False)
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'pet', 'num_classes': 37, 'num_base': 19, 'num_novel': 18, 'seed': 1, 'batch_size': 32, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'FlanT5-XXL', 'model_size_mllm': 'Qwen2.5-VL-7B', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'xiao', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/pet_37', 'expt_dir': './experiments/pet37', 'expt_dir_describe': './experiments/pet37/describe', 'path_vqa_questions': './experiments/pet37/describe/pet_vqa_questions_ours', 'path_vqa_answers': './experiments/pet37/describe/pet_attributes_pairs', 'path_llm_prompts': './experiments/pet37/describe/pet_llm_prompts', 'path_identify_answers': './experiments/pet37/identify', 'expt_dir_guess': './experiments/pet37/guess', 'path_llm_replies_raw': './experiments/pet37/guess/pet_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/pet37/guess/pet_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/pet37/guess/pet_llm_gussed_names', 'expt_dir_gallery': './experiments/pet37/gallery', 'path_references': './experiments/pet37/gallery/pet_image_references', 'path_regions': './experiments/pet37/gallery/pet_image_regions', 'path_descriptions': './experiments/pet37/gallery/pet_image_descriptions_attn', 'expt_dir_grouping': './experiments/pet37/grouping'}
ÂàùÂßãÂåñMLLMÊ®°Âûã...
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|‚ñà‚ñà        | 1/5 [00:44<02:58, 44.72s/it]Loading checkpoint shards:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [02:37<04:13, 84.57s/it]Loading checkpoint shards:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [03:30<02:21, 70.50s/it]Loading checkpoint shards:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [04:22<01:03, 63.05s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [04:36<00:00, 45.24s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [04:36<00:00, 55.25s/it]
local_model_path: /home/Dataset/Models/Qwen/Qwen2.5-VL-7B-Instruct
ÂàùÂßãÂåñÁü•ËØÜÂ∫ìÊûÑÂª∫Âô®...
üöÄ ËûçÂêàÊñπÊ≥ï‰∏∫ 'weighted'ÔºåË∑≥ËøáBLIPÊ®°ÂûãÂä†ËΩΩ‰ª•ËäÇÁúÅÊòæÂ≠ò
ÂàùÂßãÂåñÂø´ÊÄùËÄÉÊ®°Âùó...
Â∑≤Âä†ËΩΩÂéÜÂè≤ÁªüËÆ°Èáè: 667 Ê¨°È¢ÑÊµã
ÂàùÂßãÂåñÊÖ¢ÊÄùËÄÉÊ®°Âùó...
Âø´ÊÖ¢ÊÄùËÄÉÁ≥ªÁªüÂàùÂßãÂåñÂÆåÊàê!
Traceback (most recent call last):
  File "/home/hdl/project/fgvr_test/discovering.py", line 405, in <module>
    for name, path in data_discovery.subcat_to_sample.items():
AttributeError: 'PetDiscovery37' object has no attribute 'subcat_to_sample'
