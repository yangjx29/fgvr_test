/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.

=== Experiment Start Time: 2025-11-21 22:05:51 ===

=== Experiment Arguments ===
{'confidence_threshold': 0.8,
 'config_file_env': './configs/env_machine.yml',
 'config_file_expt': './configs/expts/bird200_all.yml',
 'fusion_method': 'concat',
 'gallery_out': None,
 'knowledge_base_dir': './experiments/bird200/knowledge_base',
 'kshot': None,
 'mode': 'build_knowledge_base',
 'num_per_category': '4',
 'query_image': None,
 'region_num': None,
 'results_out': './results.json',
 'similarity_threshold': 0.7,
 'superclass': None,
 'test_data_dir': None,
 'use_slow_thinking': None}
=== Configuration (cfg) ===
{'batch_size': 256,
 'clustering_method': 'multi_clip_voting',
 'data_dir': './datasets/CUB_200_2011/CUB_200_2011/',
 'dataset_name': 'bird',
 'device': 'cuda',
 'device_count': '1',
 'device_id': '0',
 'experiment': 5.0,
 'expt_dir': './experiments/bird200',
 'expt_dir_describe': './experiments/bird200/describe',
 'expt_dir_gallery': './experiments/bird200/gallery',
 'expt_dir_grouping': './experiments/bird200/grouping',
 'expt_dir_guess': './experiments/bird200/guess',
 'host': 'xiao',
 'image_size': 224,
 'model_size': 'ViT-B/16',
 'model_size_mllm': 'Qwen2.5-VL-7B',
 'model_size_vqa': 'OPT6.7B-COCO',
 'model_type_llm': 'gpt-3.5-turbo',
 'num_base': 100,
 'num_classes': 200,
 'num_novel': 100,
 'num_workers': 16,
 'path_descriptions': './experiments/bird200/gallery/bird_image_descriptions_attn',
 'path_identify_answers': './experiments/bird200/identify',
 'path_llm_gussed_names': './experiments/bird200/guess/bird_llm_gussed_names',
 'path_llm_prompts': './experiments/bird200/describe/bird_llm_prompts',
 'path_llm_replies_jsoned': './experiments/bird200/guess/bird_llm_replies_jsoned',
 'path_llm_replies_raw': './experiments/bird200/guess/bird_llm_replies_raw',
 'path_references': './experiments/bird200/gallery/bird_image_references',
 'path_regions': './experiments/bird200/gallery/bird_image_regions',
 'path_vqa_answers': './experiments/bird200/describe/bird_attributes_pairs',
 'path_vqa_questions': './experiments/bird200/describe/bird_vqa_questions_ours',
 'seed': 1,
 'setup': 'ours',
 'verbose': False}
初始化MLLM模型...
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:13<00:53, 13.34s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:50<01:21, 27.17s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:10<00:48, 24.06s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:15<00:50, 25.03s/it]
Traceback (most recent call last):
  File "/home/hdl/project/fgvr_test/discovering.py", line 408, in <module>
    system = FastSlowThinkingSystem(
  File "/home/hdl/project/fgvr_test/fast_slow_thinking_system.py", line 59, in __init__
    self.mllm_bot = MLLMBot(
  File "/home/hdl/project/fgvr_test/agents/mllm_bot.py", line 88, in __init__
    self.qwen2_5 = Qwen2_5_VLForConditionalGeneration.from_pretrained(local_model_path,
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 262, in _wrapper
    return func(*args, **kwargs)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4319, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4897, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/modeling_utils.py", line 896, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/accelerate/utils/modeling.py", line 343, in set_module_tensor_to_device
    new_value = value.to(device, non_blocking=non_blocking)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 96.88 MiB is free. Including non-PyTorch memory, this process has 26.58 GiB memory in use. Process 3595133 has 20.71 GiB memory in use. Of the allocated memory 26.01 GiB is allocated by PyTorch, and 323.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
