[INFO] === Pipeline å¯åŠ¨, YAML é…ç½®æ‘˜è¦ ===
GPU: CUDA_VISIBLE_DEVICES=3  # ä½¿ç”¨çš„GPUç¼–å·
Dataset: aircraft (num_classes=100)  # æ•°æ®é›†åŠç±»åˆ«æ•°, test_data_suffix=10  # æµ‹è¯•æ•°æ®æ ·æœ¬åç¼€
K-shot: 4  # æ£€ç´¢åº“ä½¿ç”¨æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°ç›®
Conda Env: finer_dynamic  # Condaç¯å¢ƒåç§°, Conda Base: /home/hdl/miniconda3  # Condaå®‰è£…è·¯å¾„
Knowledge Base Dir: ./experiments/aircraft100/knowledge_base  # çŸ¥è¯†åº“ç›®å½•
Test Data Dir: ./datasets/fgvc_aircraft/images_discovery_all_10  # æµ‹è¯•æ•°æ®ç›®å½•
Results Out: ./results/aircraft_fast_slow_results.json  # å¿«æ…¢æ€è€ƒè¯„ä¼°ç»“æœè¾“å‡ºæ–‡ä»¶
---------------------------

[INFO] === Step1: æ„å»ºçŸ¥è¯†åº“ ===
/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
å½“å‰æ•°æ®é›†: aircraft (aircraft100)
ç±»åˆ«æ•°: 100
å®éªŒç›®å½•: ./experiments/aircraft100
å½“å‰ä½¿ç”¨çš„ GPU ä¸ºï¼š3

=== Experiment Start Time: 2025-11-22 22:10:45 ===

=== Experiment Arguments ===
{'confidence_threshold': 0.8,
 'config_file_env': './configs/env_machine.yml',
 'config_file_expt': './configs/expts/aircraft100_all.yml',
 'fusion_method': 'concat',
 'gallery_out': None,
 'knowledge_base_dir': './experiments/aircraft100/knowledge_base',
 'kshot': None,
 'mode': 'build_knowledge_base',
 'num_per_category': '4',
 'query_image': None,
 'region_num': None,
 'results_out': './results.json',
 'similarity_threshold': 0.7,
 'superclass': None,
 'test_data_dir': None,
 'use_slow_thinking': None}
=== Configuration (cfg) ===
{'batch_size': 64,
 'clustering_method': 'multi_clip_voting',
 'data_dir': './datasets/fgvc_aircraft',
 'dataset_name': 'aircraft',
 'device': 'cuda',
 'device_count': '1',
 'device_id': '0',
 'experiment': 5.0,
 'expt_dir': './experiments/aircraft100',
 'expt_dir_describe': './experiments/aircraft100/describe',
 'expt_dir_gallery': './experiments/aircraft100/gallery',
 'expt_dir_grouping': './experiments/aircraft100/grouping',
 'expt_dir_guess': './experiments/aircraft100/guess',
 'host': 'xiao',
 'image_size': 224,
 'model_size': 'ViT-B/16',
 'model_size_mllm': 'Qwen2.5-VL-7B',
 'model_size_vqa': 'OPT6.7B-COCO',
 'model_type_llm': 'gpt-3.5-turbo',
 'num_base': 50,
 'num_classes': 100,
 'num_novel': 50,
 'num_workers': 16,
 'path_descriptions': './experiments/aircraft100/gallery/aircraft_image_descriptions_attn',
 'path_identify_answers': './experiments/aircraft100/identify',
 'path_llm_gussed_names': './experiments/aircraft100/guess/aircraft_llm_gussed_names',
 'path_llm_prompts': './experiments/aircraft100/describe/aircraft_llm_prompts',
 'path_llm_replies_jsoned': './experiments/aircraft100/guess/aircraft_llm_replies_jsoned',
 'path_llm_replies_raw': './experiments/aircraft100/guess/aircraft_llm_replies_raw',
 'path_references': './experiments/aircraft100/gallery/aircraft_image_references',
 'path_regions': './experiments/aircraft100/gallery/aircraft_image_regions',
 'path_vqa_answers': './experiments/aircraft100/describe/aircraft_attributes_pairs',
 'path_vqa_questions': './experiments/aircraft100/describe/aircraft_vqa_questions_ours',
 'seed': 1,
 'setup': 'ours',
 'verbose': False}

================= å¿«æ…¢æ€è€ƒç³»ç»Ÿåˆå§‹åŒ– =================
ğŸ–¥ï¸ è®¾å¤‡: cuda
ğŸ¤– MLLM æ¨¡å‹æ ‡ç­¾: Qwen2.5-VL-7B
ğŸ¤– MLLM æ¨¡å‹åç§°: Qwen2.5-VL-7B
ğŸ–¼ï¸ å›¾åƒç¼–ç å™¨: ./models/Clip/clip-vit-base-patch32
ğŸ“„ æ–‡æœ¬ç¼–ç å™¨: ./models/Clip/clip-vit-base-patch32
ğŸ“š æ•°æ®é›†ä¿¡æ¯:
{
    "full_name": "aircraft100",
    "num_classes": 100,
    "config_file": "aircraft100_all.yml",
    "data_dir": "fgvc_aircraft",
    "experiment_dir": "aircraft100",
    "stats_file": "aircraft100/knowledge_base/stats.json",
    "experiments_root": "./experiments",
    "stats_file_full": "./experiments/aircraft100/knowledge_base/stats.json",
    "experiment_dir_full": "./experiments/aircraft100"
}
====================================================

ğŸš€åˆå§‹åŒ–MLLMæ¨¡å‹...

================= æ¨¡å‹åˆå§‹åŒ–ï¼ˆMLLMBotï¼‰ =================
ğŸ“Œ æ¨¡å‹æ ‡è¯†ï¼ˆmodel_tagï¼‰: Qwen2.5-VL-7B
ğŸ“Œ æ¨¡å‹åç§°ï¼ˆmodel_nameï¼‰: Qwen2.5-VL-7B
ğŸ“ æœ¬åœ°æ¨¡å‹è·¯å¾„: ./models/Qwen/Qwen2.5-VL-7B-Instruct
ğŸ–¥ï¸ è®¾å¤‡: GPU - cuda:0
ğŸ¤– ä½¿ç”¨ 8bit æ¨ç†: å¦
ğŸ” ä½¿ç”¨æ•°æ®ç±»å‹: float32ï¼ˆFP32ï¼‰
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:07,  1.89s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:04<00:06,  2.12s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:06<00:04,  2.22s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:08<00:02,  2.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.73s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.92s/it]
âœ“ å·²å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœæ˜¾å­˜
ğŸ“ local_model_path: ./models/Qwen/Qwen2.5-VL-7B-Instruct
ğŸ”¢ å½“å‰ä½¿ç”¨çš„ç²¾åº¦ dtype: float32ï¼ˆFP32ï¼‰
ğŸ”§ æœ€å¤§ç”Ÿæˆé•¿åº¦ max_answer_tokens: -1
ğŸš€ æ¨¡å‹åŠ è½½å®Œæˆï¼
========================================================

âœ… MLLM åˆå§‹åŒ–å®Œæˆ, å½“å‰ä½¿ç”¨ç²¾åº¦: æœªçŸ¥
ğŸš€ åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨...

================= çŸ¥è¯†åº“æ„å»ºå™¨åˆå§‹åŒ– =================
ğŸ•’ åˆå§‹åŒ–æ—¶é—´: 2025-11-22 22:10:56
ğŸ–¥ï¸ è®¾å¤‡: cuda
ğŸ–¼ï¸ å›¾åƒç¼–ç å™¨: ./models/Clip/clip-vit-base-patch32
ğŸ“ æ–‡æœ¬ç¼–ç å™¨: ./models/Clip/clip-vit-base-patch32
ğŸ“Š æ•°æ®é›†ä¿¡æ¯ keys: ['full_name', 'num_classes', 'config_file', 'data_dir', 'experiment_dir', 'stats_file', 'experiments_root', 'stats_file_full', 'experiment_dir_full']
ğŸ” åˆå§‹åŒ– MultimodalRetrieval æ¨¡å—...
âœ“ æ£€ç´¢æ¨¡å—åˆå§‹åŒ–å®Œæˆ
ğŸ“š çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ
====================================================

âœ… çŸ¥è¯†åº“æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆ
ğŸš€ åˆå§‹åŒ–å¿«æ€è€ƒæ¨¡å—...

================= å¿«æ€è€ƒæ¨¡å—åˆå§‹åŒ– =================
ä½¿ç”¨æ•°æ®é›†statsæ–‡ä»¶: ./experiments/aircraft100/knowledge_base/stats.json
ğŸ“Š ä½¿ç”¨æ•°æ®é›† stats æ–‡ä»¶: ./experiments/aircraft100/knowledge_base/stats.json
ğŸ”§ ç½®ä¿¡åº¦é˜ˆå€¼ confidence_threshold: 0.8
ğŸ”§ ç›¸ä¼¼åº¦é˜ˆå€¼ similarity_threshold: 0.7
ğŸ”§ èåˆæƒé‡ fusion_weight: 0.05
ğŸ”§ softmax æ¸©åº¦ softmax_temp: 0.07
ğŸ”§ èåˆé˜ˆå€¼ fused_conf_threshold: 0.75
ğŸ”§ èåˆè¾¹è·é˜ˆå€¼ fused_margin_threshold: 0.15
ğŸ”§ å•æ¨¡æ€é˜ˆå€¼ per_modality_conf_threshold: 0.65
ğŸ”§ è€ƒè™‘ topk é‡å : True, topk_for_overlap: 3
ğŸ“ˆ LCB é˜ˆå€¼: 0.65, è‡ªé€‚åº”: True, èŒƒå›´: [0.55, 0.75]
ğŸ“ˆ LCB å…ˆéªŒ: strength=2.0, p=0.6, eta=1.0, alpha=0.5, epsilon=1e-06
ğŸ’¾ ç¼“å­˜å¯ç”¨: True, ç¼“å­˜å¤§å°: 1000
====================================================

æœªæ‰¾åˆ°å†å²ç»Ÿè®¡é‡æ–‡ä»¶ï¼Œå°†ä»å¤´å¼€å§‹
âœ… å¿«æ€è€ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆ
ğŸš€ åˆå§‹åŒ–æ…¢æ€è€ƒæ¨¡å—...

================= æ…¢æ€è€ƒæ¨¡å—åˆå§‹åŒ– =================
ğŸ•’ åˆå§‹åŒ–æ—¶é—´: 2025-11-22 22:12:28
ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: cuda:0
ğŸ§  MLLMæ¨¡å‹: Qwen2.5-VL-7B
ğŸ“š çŸ¥è¯†åº“æ„å»ºå™¨: <knowledge_base_builder.KnowledgeBaseBuilder object at 0x79895b7e9af0>
âš¡ å¿«æ€è€ƒæ¨¡å—: <fast_thinking_optimized.FastThinkingOptimized object at 0x79895b7e9940>
ğŸ“– ç»éªŒåº“æ„å»ºå™¨: None
ğŸ’¾ å¯ç”¨ç¼“å­˜: æ˜¯, ç¼“å­˜å¤§å°: 1000
ğŸ” ç®€åŒ–æ¨ç†: æ˜¯
ğŸ§© ä½¿ç”¨ç»éªŒåº“: æ˜¯, top_k_experience=1
æ…¢æ€è€ƒé»˜è®¤ä¿å­˜ç›®å½•: ./experiments/aircraft100/knowledge_base
ä½¿ç”¨æ•°æ®é›†: aircraft, ç±»åˆ«æ•°: 100
âœ… æ…¢æ€è€ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆï¼Œç±»åˆ«æ˜ å°„æ•°é‡: 100
====================================================

âœ… æ…¢æ€è€ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆ
â±ï¸ å¯åŠ¨æ˜¾å­˜ç›‘æ§çº¿ç¨‹...
[2025-11-22 22:12:28] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.43GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
ğŸ‰å¿«æ…¢æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!
====================================================

æ„å»ºçŸ¥è¯†åº“ï¼ŒåŒ…å« 98 ä¸ªç±»åˆ«, dog datasets:100
ä» ./experiments/aircraft100/knowledge_base åŠ è½½çŸ¥è¯†åº“...
çŸ¥è¯†åº“å·²ä» ./experiments/aircraft100/knowledge_base åŠ è½½
çŸ¥è¯†åº“åŠ è½½å®Œæˆ!
æ„å»ºçŸ¥è¯†åº“...
è®­ç»ƒæ ·æœ¬åŒ…å« 98 ä¸ªç±»åˆ«
å¼€å§‹æ„å»ºçŸ¥è¯†åº“...
æ„å»ºå›¾åƒçŸ¥è¯†åº“...
  0%|          | 0/98 [00:00<?, ?it/s]  1%|          | 1/98 [00:00<00:31,  3.03it/s]  2%|â–         | 2/98 [00:00<00:19,  5.05it/s]  4%|â–         | 4/98 [00:00<00:12,  7.61it/s]  5%|â–Œ         | 5/98 [00:00<00:11,  8.03it/s]  7%|â–‹         | 7/98 [00:00<00:09,  9.33it/s]  9%|â–‰         | 9/98 [00:01<00:08, 10.11it/s] 11%|â–ˆ         | 11/98 [00:01<00:08, 10.71it/s] 13%|â–ˆâ–        | 13/98 [00:01<00:08, 10.51it/s] 15%|â–ˆâ–Œ        | 15/98 [00:01<00:07, 10.60it/s] 17%|â–ˆâ–‹        | 17/98 [00:01<00:07, 10.60it/s] 19%|â–ˆâ–‰        | 19/98 [00:02<00:07, 10.60it/s] 21%|â–ˆâ–ˆâ–       | 21/98 [00:02<00:06, 11.24it/s] 23%|â–ˆâ–ˆâ–       | 23/98 [00:02<00:06, 11.48it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/98 [00:02<00:06, 11.53it/s] 28%|â–ˆâ–ˆâ–Š       | 27/98 [00:02<00:06, 11.48it/s] 30%|â–ˆâ–ˆâ–‰       | 29/98 [00:02<00:06, 11.27it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/98 [00:03<00:05, 11.30it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/98 [00:03<00:05, 11.40it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/98 [00:03<00:05, 11.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 37/98 [00:03<00:05, 11.58it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 39/98 [00:03<00:05, 11.75it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 41/98 [00:03<00:04, 12.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/98 [00:04<00:04, 12.31it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/98 [00:04<00:04, 11.73it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 47/98 [00:04<00:04, 11.61it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/98 [00:04<00:04, 11.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 51/98 [00:04<00:04, 11.65it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/98 [00:04<00:03, 11.93it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/98 [00:05<00:03, 11.29it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 57/98 [00:05<00:03, 11.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 59/98 [00:05<00:03, 10.74it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 61/98 [00:05<00:03, 11.32it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 63/98 [00:05<00:03, 11.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 65/98 [00:05<00:02, 11.58it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 67/98 [00:06<00:02, 11.64it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 69/98 [00:06<00:02, 11.81it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/98 [00:06<00:02, 12.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 73/98 [00:06<00:02, 12.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 75/98 [00:06<00:01, 11.91it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 77/98 [00:07<00:01, 11.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 79/98 [00:07<00:01, 11.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/98 [00:07<00:01, 11.39it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 83/98 [00:07<00:01, 11.48it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 85/98 [00:07<00:01, 12.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 87/98 [00:07<00:00, 12.43it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 89/98 [00:08<00:00, 12.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/98 [00:08<00:00, 12.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 93/98 [00:08<00:00, 11.79it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 95/98 [00:08<00:00, 11.72it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 97/98 [00:08<00:00, 11.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:08<00:00, 11.15it/s]
å¤„ç†ç±»åˆ«: An-12
ç±»åˆ« An-12 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Fokker 50
ç±»åˆ« Fokker 50 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: BAE-125
ç±»åˆ« BAE-125 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-200
ç±»åˆ« 737-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Dornier 328
ç±»åˆ« Dornier 328 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Tornado
ç±»åˆ« Tornado å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: MD-87
ç±»åˆ« MD-87 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A380
ç±»åˆ« A380 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: EMB-120
ç±»åˆ« EMB-120 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DC-10
ç±»åˆ« DC-10 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A310
ç±»åˆ« A310 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: PA-28
ç±»åˆ« PA-28 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Embraer Legacy 600
ç±»åˆ« Embraer Legacy 600 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 757-300
ç±»åˆ« 757-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 747-200
ç±»åˆ« 747-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A320
ç±»åˆ« A320 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-400
ç±»åˆ« 737-400 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: MD-80
ç±»åˆ« MD-80 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A318
ç±»åˆ« A318 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Cessna 172
ç±»åˆ« Cessna 172 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Metroliner
ç±»åˆ« Metroliner å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Tu-134
ç±»åˆ« Tu-134 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Cessna 208
ç±»åˆ« Cessna 208 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: ERJ 135
ç±»åˆ« ERJ 135 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DR-400
ç±»åˆ« DR-400 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: C-47
ç±»åˆ« C-47 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A340-600
ç±»åˆ« A340-600 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: MD-11
ç±»åˆ« MD-11 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Cessna 525
ç±»åˆ« Cessna 525 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: C-130
ç±»åˆ« C-130 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DC-8
[2025-11-22 22:12:31] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
ç±»åˆ« DC-8 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 757-200
ç±»åˆ« 757-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Saab 340
ç±»åˆ« Saab 340 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DC-3
ç±»åˆ« DC-3 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Eurofighter Typhoon
ç±»åˆ« Eurofighter Typhoon å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: ERJ 145
ç±»åˆ« ERJ 145 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: SR-20
ç±»åˆ« SR-20 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-500
ç±»åˆ« 737-500 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DH-82
ç±»åˆ« DH-82 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Beechcraft 1900
ç±»åˆ« Beechcraft 1900 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: E-170
ç±»åˆ« E-170 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 777-300
ç±»åˆ« 777-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Yak-42
ç±»åˆ« Yak-42 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-800
ç±»åˆ« 737-800 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-600
ç±»åˆ« 737-600 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Boeing 717
ç±»åˆ« Boeing 717 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-700
ç±»åˆ« 737-700 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A319
ç±»åˆ« A319 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DC-9-30
ç±»åˆ« DC-9-30 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A340-200
ç±»åˆ« A340-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 707-320
ç±»åˆ« 707-320 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-900
ç±»åˆ« 737-900 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: CRJ-900
ç±»åˆ« CRJ-900 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: CRJ-700
ç±»åˆ« CRJ-700 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Falcon 2000
ç±»åˆ« Falcon 2000 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DHC-8-300
ç±»åˆ« DHC-8-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: MD-90
ç±»åˆ« MD-90 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Gulfstream V
ç±»åˆ« Gulfstream V å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DHC-1
ç±»åˆ« DHC-1 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: ATR-72
ç±»åˆ« ATR-72 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A300B4
ç±»åˆ« A300B4 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: BAE 146-300
ç±»åˆ« BAE 146-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A330-200
ç±»åˆ« A330-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Saab 2000
ç±»åˆ« Saab 2000 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DHC-6
ç±»åˆ« DHC-6 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: E-195
[2025-11-22 22:12:34] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
ç±»åˆ« E-195 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Il-76
ç±»åˆ« Il-76 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 747-100
ç±»åˆ« 747-100 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: ATR-42
ç±»åˆ« ATR-42 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Challenger 600
ç±»åˆ« Challenger 600 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DHC-8-100
ç±»åˆ« DHC-8-100 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Tu-154
ç±»åˆ« Tu-154 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: CRJ-200
ç±»åˆ« CRJ-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Fokker 70
ç±»åˆ« Fokker 70 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 767-200
ç±»åˆ« 767-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 747-400
ç±»åˆ« 747-400 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: L-1011
ç±»åˆ« L-1011 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A321
ç±»åˆ« A321 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: E-190
ç±»åˆ« E-190 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 777-200
ç±»åˆ« 777-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 767-400
ç±»åˆ« 767-400 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Cessna 560
ç±»åˆ« Cessna 560 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: DC-6
ç±»åˆ« DC-6 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Gulfstream IV
ç±»åˆ« Gulfstream IV å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 737-300
ç±»åˆ« 737-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Spitfire
ç±»åˆ« Spitfire å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 767-300
ç±»åˆ« 767-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A330-300
ç±»åˆ« A330-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 727-200
ç±»åˆ« 727-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Global Express
ç±»åˆ« Global Express å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Fokker 100
ç±»åˆ« Fokker 100 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Hawk T1
ç±»åˆ« Hawk T1 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Falcon 900
ç±»åˆ« Falcon 900 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: 747-300
ç±»åˆ« 747-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: BAE 146-200
ç±»åˆ« BAE 146-200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A340-300
ç±»åˆ« A340-300 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: Model B200
ç±»åˆ« Model B200 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
å¤„ç†ç±»åˆ«: A340-500
ç±»åˆ« A340-500 å›¾åƒç‰¹å¾ç»´åº¦: (512,)
æ„å»ºæ–‡æœ¬çŸ¥è¯†åº“...
  0%|          | 0/98 [00:00<?, ?it/s]/home/hdl/miniconda3/envs/finer_dynamic/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1e-06` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
  1%|          | 1/98 [00:12<20:12, 12.50s/it]  2%|â–         | 2/98 [00:25<20:22, 12.73s/it]  3%|â–         | 3/98 [00:37<19:49, 12.52s/it]  4%|â–         | 4/98 [00:50<20:07, 12.84s/it]  5%|â–Œ         | 5/98 [01:04<20:03, 12.94s/it]  6%|â–Œ         | 6/98 [01:17<20:12, 13.18s/it]å¤„ç†ç±»åˆ«: An-12
[2025-11-22 22:12:37] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
[2025-11-22 22:12:40] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
[2025-11-22 22:12:43] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
[2025-11-22 22:12:46] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=32.78GB, ç©ºé—²=14.97GB
wiki desc: Description for An-12 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
[2025-11-22 22:12:49] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=41.32GB, å·²ä¿ç•™=41.71GB, ç©ºé—²=6.08GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.74 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.37 GiB is free. Including non-PyTorch memory, this process has 42.02 GiB memory in use. Of the allocated memory 41.32 GiB is allocated by PyTorch, and 399.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« An-12 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for An-12 category....
å¤„ç†ç±»åˆ«: Fokker 50
[2025-11-22 22:12:52] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:12:55] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:12:58] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.71GB, ç©ºé—²=14.97GB
wiki desc: Description for Fokker 50 category.
å›¾åƒè¿‡å¤§ (1600x1078)ï¼Œç¼©å°åˆ° (1536x1034) ä»¥èŠ‚çœæ˜¾å­˜
[2025-11-22 22:13:01] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.71GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.90GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 11.56 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 46.29 GiB memory in use. Of the allocated memory 45.56 GiB is allocated by PyTorch, and 432.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Fokker 50 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Fokker 50 category....
å¤„ç†ç±»åˆ«: BAE-125
[2025-11-22 22:13:04] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.98GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:07] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.98GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:10] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.98GB, ç©ºé—²=14.97GB
wiki desc: Description for BAE-125 category.
[2025-11-22 22:13:13] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.98GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 9.15 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.85 GiB is free. Including non-PyTorch memory, this process has 43.55 GiB memory in use. Of the allocated memory 42.88 GiB is allocated by PyTorch, and 363.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« BAE-125 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for BAE-125 category....
å¤„ç†ç±»åˆ«: 737-200
[2025-11-22 22:13:16] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.24GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:19] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.24GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:22] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.24GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:25] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.24GB, ç©ºé—²=14.97GB
wiki desc: Description for 737-200 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 11.15 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 45.81 GiB memory in use. Of the allocated memory 45.10 GiB is allocated by PyTorch, and 413.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« 737-200 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for 737-200 category....
å¤„ç†ç±»åˆ«: Dornier 328
[2025-11-22 22:13:28] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.50GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:31] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.50GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:34] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.50GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:37] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.50GB, ç©ºé—²=14.97GB
wiki desc: Description for Dornier 328 category.
å›¾åƒè¿‡å¤§ (1600x1079)ï¼Œç¼©å°åˆ° (1536x1035) ä»¥èŠ‚çœæ˜¾å­˜
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.51GB, å·²ä¿ç•™=32.95GB, å‰©ä½™=14.89GB
[2025-11-22 22:13:40] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.83GB, å·²ä¿ç•™=33.22GB, ç©ºé—²=14.57GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 16.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.07 GiB is free. Including non-PyTorch memory, this process has 35.32 GiB memory in use. Of the allocated memory 34.63 GiB is allocated by PyTorch, and 393.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Dornier 328 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Dornier 328 category....
å¤„ç†ç±»åˆ«: Tornado
[2025-11-22 22:13:43] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=35.01GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:46] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=35.01GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:49] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=35.01GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:52] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=35.01GB, ç©ºé—²=14.97GB
wiki desc: Description for Tornado category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.86GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 13.23 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.49 GiB is free. Including non-PyTorch memory, this process has 34.91 GiB memory in use. Of the allocated memory 34.24 GiB is allocated by PyTorch, and 363.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Tornado æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Tornado category....
å¤„ç†ç±»åˆ«: MD-87
[2025-11-22 22:13:55] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.60GB, ç©ºé—²=14.97GB
[2025-11-22 22:13:58] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.60GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:01] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.60GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:04] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.60GB, ç©ºé—²=14.97GB
wiki desc: Description for MD-87 category.
å›¾åƒè¿‡å¤§ (1600x1097)ï¼Œç¼©å°åˆ° (1536x1053) ä»¥èŠ‚çœæ˜¾å­˜
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.90GB
[2025-11-22 22:14:07] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=45.97GB, å·²ä¿ç•™=46.38GB, ç©ºé—²=1.43GB
  7%|â–‹         | 7/98 [01:30<19:46, 13.03s/it]  8%|â–Š         | 8/98 [01:42<19:15, 12.84s/it]  9%|â–‰         | 9/98 [01:55<18:47, 12.66s/it] 10%|â–ˆ         | 10/98 [02:09<19:18, 13.17s/it] 11%|â–ˆ         | 11/98 [02:22<19:02, 13.14s/it] 12%|â–ˆâ–        | 12/98 [02:35<18:35, 12.97s/it] 13%|â–ˆâ–        | 13/98 [02:48<18:29, 13.06s/it]MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 11.93 GiB. GPU 0 has a total capacity of 47.40 GiB of which 720.31 MiB is free. Including non-PyTorch memory, this process has 46.69 GiB memory in use. Of the allocated memory 45.97 GiB is allocated by PyTorch, and 418.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« MD-87 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for MD-87 category....
å¤„ç†ç±»åˆ«: A380
[2025-11-22 22:14:10] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.38GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:13] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.38GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:16] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.38GB, ç©ºé—²=14.97GB
wiki desc: Description for A380 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.91GB
[2025-11-22 22:14:19] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.77GB, å·²ä¿ç•™=33.12GB, ç©ºé—²=14.64GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 11.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.28 GiB is free. Including non-PyTorch memory, this process has 46.12 GiB memory in use. Of the allocated memory 45.40 GiB is allocated by PyTorch, and 414.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« A380 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for A380 category....
å¤„ç†ç±»åˆ«: EMB-120
[2025-11-22 22:14:22] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.80GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:25] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.80GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:28] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.80GB, ç©ºé—²=14.97GB
wiki desc: Description for EMB-120 category.
[2025-11-22 22:14:31] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.80GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.67 GiB is free. Including non-PyTorch memory, this process has 41.73 GiB memory in use. Of the allocated memory 41.05 GiB is allocated by PyTorch, and 370.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« EMB-120 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for EMB-120 category....
å¤„ç†ç±»åˆ«: DC-10
[2025-11-22 22:14:34] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.42GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:37] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.42GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:40] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.42GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:43] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.42GB, ç©ºé—²=14.97GB
wiki desc: Description for DC-10 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.44 GiB is free. Including non-PyTorch memory, this process has 41.96 GiB memory in use. Of the allocated memory 41.25 GiB is allocated by PyTorch, and 405.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-11-22 22:14:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=33.04GB, å·²ä¿ç•™=41.64GB, ç©ºé—²=14.36GB
ç±»åˆ« DC-10 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for DC-10 category....
å¤„ç†ç±»åˆ«: A310
[2025-11-22 22:14:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.64GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.64GB, ç©ºé—²=14.97GB
[2025-11-22 22:14:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.64GB, ç©ºé—²=14.97GB
wiki desc: Description for A310 category.
[2025-11-22 22:14:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.64GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.37 GiB is free. Including non-PyTorch memory, this process has 41.02 GiB memory in use. Of the allocated memory 40.31 GiB is allocated by PyTorch, and 413.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« A310 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for A310 category....
å¤„ç†ç±»åˆ«: PA-28
[2025-11-22 22:15:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.71GB, ç©ºé—²=14.97GB
wiki desc: Description for PA-28 category.
[2025-11-22 22:15:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.71GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.88GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 11.43 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.29 GiB is free. Including non-PyTorch memory, this process has 46.10 GiB memory in use. Of the allocated memory 45.41 GiB is allocated by PyTorch, and 386.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« PA-28 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for PA-28 category....
å¤„ç†ç±»åˆ«: Embraer Legacy 600
[2025-11-22 22:15:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.79GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.79GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.79GB, ç©ºé—²=14.97GB
wiki desc: Description for Embraer Legacy 600 category.
[2025-11-22 22:15:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.79GB, ç©ºé—²=14.97GB
å›¾åƒè¿‡å¤§ (1600x1079)ï¼Œç¼©å°åˆ° (1536x1035) ä»¥èŠ‚çœæ˜¾å­˜
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.51GB, å·²ä¿ç•™=32.88GB, å‰©ä½™=14.89GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 15.66 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.21 GiB is free. Including non-PyTorch memory, this process has 35.18 GiB memory in use. Of the allocated memory 34.50 GiB is allocated by PyTorch, and 372.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Embraer Legacy 600 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Embraer Legacy 600 category....
å¤„ç†ç±»åˆ«: 757-300
[2025-11-22 22:15:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.87GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:29] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.87GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:32] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.87GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:35] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.87GB, ç©ºé—²=14.97GB
wiki desc: Description for 757-300 category.
 14%|â–ˆâ–        | 14/98 [03:01<18:06, 12.93s/it] 15%|â–ˆâ–Œ        | 15/98 [03:13<17:54, 12.94s/it] 16%|â–ˆâ–‹        | 16/98 [03:27<17:50, 13.06s/it] 17%|â–ˆâ–‹        | 17/98 [03:39<17:26, 12.92s/it] 18%|â–ˆâ–Š        | 18/98 [03:51<16:49, 12.62s/it] 19%|â–ˆâ–‰        | 19/98 [04:05<17:00, 12.92s/it] 20%|â–ˆâ–ˆ        | 20/98 [04:18<16:51, 12.97s/it]æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.86GB, å‰©ä½™=14.90GB
[2025-11-22 22:15:38] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.79GB, å·²ä¿ç•™=33.15GB, ç©ºé—²=14.61GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 13.11 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.43 GiB is free. Including non-PyTorch memory, this process has 34.96 GiB memory in use. Of the allocated memory 34.23 GiB is allocated by PyTorch, and 432.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« 757-300 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for 757-300 category....
å¤„ç†ç±»åˆ«: 747-200
[2025-11-22 22:15:41] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.65GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:44] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.65GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.65GB, ç©ºé—²=14.97GB
wiki desc: Description for 747-200 category.
å›¾åƒè¿‡å¤§ (1600x1079)ï¼Œç¼©å°åˆ° (1536x1035) ä»¥èŠ‚çœæ˜¾å­˜
[2025-11-22 22:15:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.65GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 13.41 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 34.98 GiB memory in use. Of the allocated memory 34.27 GiB is allocated by PyTorch, and 417.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« 747-200 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for 747-200 category....
å¤„ç†ç±»åˆ«: A320
[2025-11-22 22:15:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.67GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.67GB, ç©ºé—²=14.97GB
[2025-11-22 22:15:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.67GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.67GB, ç©ºé—²=14.97GB
wiki desc: Description for A320 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.48 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.65 GiB is free. Including non-PyTorch memory, this process has 41.74 GiB memory in use. Of the allocated memory 41.03 GiB is allocated by PyTorch, and 410.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« A320 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for A320 category....
å¤„ç†ç±»åˆ«: 737-400
[2025-11-22 22:16:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.43GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.43GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.43GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.43GB, ç©ºé—²=14.97GB
wiki desc: Description for 737-400 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.89GB, å‰©ä½™=14.91GB
[2025-11-22 22:16:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.76GB, å·²ä¿ç•™=33.11GB, ç©ºé—²=14.65GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 10.67 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 45.29 GiB memory in use. Of the allocated memory 44.57 GiB is allocated by PyTorch, and 417.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« 737-400 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for 737-400 category....
å¤„ç†ç±»åˆ«: MD-80
[2025-11-22 22:16:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.98GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.98GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.98GB, ç©ºé—²=14.97GB
wiki desc: Description for MD-80 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.91GB
[2025-11-22 22:16:29] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=42.94GB, å·²ä¿ç•™=43.29GB, ç©ºé—²=4.46GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 9.15 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.79 GiB is free. Including non-PyTorch memory, this process has 43.60 GiB memory in use. Of the allocated memory 42.88 GiB is allocated by PyTorch, and 421.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« MD-80 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for MD-80 category....
å¤„ç†ç±»åˆ«: A318
[2025-11-22 22:16:32] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.29GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:35] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.29GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:38] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.29GB, ç©ºé—²=14.97GB
wiki desc: Description for A318 category.
[2025-11-22 22:16:41] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.29GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 10.53 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 45.12 GiB memory in use. Of the allocated memory 44.41 GiB is allocated by PyTorch, and 411.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« A318 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for A318 category....
å¤„ç†ç±»åˆ«: Cessna 172
[2025-11-22 22:16:44] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.81GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.81GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.81GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.81GB, ç©ºé—²=14.97GB
wiki desc: Description for Cessna 172 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 6.96 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.28 GiB is free. Including non-PyTorch memory, this process has 41.11 GiB memory in use. Of the allocated memory 40.45 GiB is allocated by PyTorch, and 364.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Cessna 172 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Cessna 172 category....
å¤„ç†ç±»åˆ«: Metroliner
[2025-11-22 22:16:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.80GB, ç©ºé—²=14.97GB
[2025-11-22 22:16:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.80GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.80GB, ç©ºé—²=14.97GB
 21%|â–ˆâ–ˆâ–       | 21/98 [04:30<16:15, 12.67s/it] 22%|â–ˆâ–ˆâ–       | 22/98 [04:44<16:24, 12.95s/it] 23%|â–ˆâ–ˆâ–       | 23/98 [04:56<15:51, 12.68s/it] 24%|â–ˆâ–ˆâ–       | 24/98 [05:08<15:28, 12.54s/it] 26%|â–ˆâ–ˆâ–Œ       | 25/98 [05:21<15:33, 12.79s/it] 27%|â–ˆâ–ˆâ–‹       | 26/98 [05:33<15:02, 12.54s/it] 28%|â–ˆâ–ˆâ–Š       | 27/98 [05:46<14:59, 12.66s/it][2025-11-22 22:17:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.80GB, ç©ºé—²=14.97GB
wiki desc: Description for Metroliner category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.02 GiB is free. Including non-PyTorch memory, this process has 41.37 GiB memory in use. Of the allocated memory 40.67 GiB is allocated by PyTorch, and 403.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Metroliner æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Metroliner category....
å¤„ç†ç±»åˆ«: Tu-134
[2025-11-22 22:17:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.06GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.06GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.06GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.06GB, ç©ºé—²=14.97GB
wiki desc: Description for Tu-134 category.
[2025-11-22 22:17:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.06GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.89GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 13.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.45 GiB is free. Including non-PyTorch memory, this process has 34.94 GiB memory in use. Of the allocated memory 34.25 GiB is allocated by PyTorch, and 394.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Tu-134 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Tu-134 category....
å¤„ç†ç±»åˆ«: Cessna 208
[2025-11-22 22:17:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.63GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.63GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:29] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.63GB, ç©ºé—²=14.97GB
wiki desc: Description for Cessna 208 category.
[2025-11-22 22:17:32] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.63GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 1.63 GiB. GPU 0 has a total capacity of 47.40 GiB of which 182.31 MiB is free. Including non-PyTorch memory, this process has 47.21 GiB memory in use. Of the allocated memory 46.51 GiB is allocated by PyTorch, and 406.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Cessna 208 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Cessna 208 category....
å¤„ç†ç±»åˆ«: ERJ 135
[2025-11-22 22:17:35] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.90GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:38] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.90GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:41] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.90GB, ç©ºé—²=14.97GB
wiki desc: Description for ERJ 135 category.
[2025-11-22 22:17:44] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.90GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.03 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.16 GiB is free. Including non-PyTorch memory, this process has 41.23 GiB memory in use. Of the allocated memory 40.53 GiB is allocated by PyTorch, and 400.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« ERJ 135 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for ERJ 135 category....
å¤„ç†ç±»åˆ«: DR-400
[2025-11-22 22:17:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.92GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.92GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.92GB, ç©ºé—²=14.97GB
[2025-11-22 22:17:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=40.92GB, ç©ºé—²=14.97GB
wiki desc: Description for DR-400 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.89GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 9.37 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.61 GiB is free. Including non-PyTorch memory, this process has 43.78 GiB memory in use. Of the allocated memory 43.13 GiB is allocated by PyTorch, and 349.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-11-22 22:17:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=33.12GB, å·²ä¿ç•™=43.47GB, ç©ºé—²=14.29GB
ç±»åˆ« DR-400 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for DR-400 category....
å¤„ç†ç±»åˆ«: C-47
[2025-11-22 22:18:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.47GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.47GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.47GB, ç©ºé—²=14.97GB
wiki desc: Description for C-47 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 47.40 GiB of which 378.31 MiB is free. Including non-PyTorch memory, this process has 47.02 GiB memory in use. Of the allocated memory 46.36 GiB is allocated by PyTorch, and 365.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« C-47 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for C-47 category....
å¤„ç†ç±»åˆ«: A340-600
[2025-11-22 22:18:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.71GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=46.71GB, ç©ºé—²=14.97GB
wiki desc: Description for A340-600 category.
å›¾åƒè¿‡å¤§ (1600x1079)ï¼Œç¼©å°åˆ° (1536x1035) ä»¥èŠ‚çœæ˜¾å­˜
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.88GB, å‰©ä½™=14.90GB
[2025-11-22 22:18:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.80GB, å·²ä¿ç•™=33.18GB, ç©ºé—²=14.60GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 13.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 35.00 GiB memory in use. Of the allocated memory 34.32 GiB is allocated by PyTorch, and 381.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« A340-600 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for A340-600 category....
å¤„ç†ç±»åˆ«: MD-11
[2025-11-22 22:18:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.69GB, ç©ºé—²=14.97GB
 29%|â–ˆâ–ˆâ–Š       | 28/98 [05:59<14:43, 12.62s/it] 30%|â–ˆâ–ˆâ–‰       | 29/98 [06:11<14:34, 12.68s/it] 31%|â–ˆâ–ˆâ–ˆ       | 30/98 [06:24<14:18, 12.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/98 [06:36<14:00, 12.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 32/98 [06:48<13:31, 12.30s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/98 [07:02<13:44, 12.68s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 34/98 [07:14<13:24, 12.57s/it][2025-11-22 22:18:29] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.69GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:32] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.69GB, ç©ºé—²=14.97GB
wiki desc: Description for MD-11 category.
[2025-11-22 22:18:35] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.69GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 10.31 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.55 GiB is free. Including non-PyTorch memory, this process has 44.84 GiB memory in use. Of the allocated memory 44.17 GiB is allocated by PyTorch, and 365.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« MD-11 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for MD-11 category....
å¤„ç†ç±»åˆ«: Cessna 525
[2025-11-22 22:18:38] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.53GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:41] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.53GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:44] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.53GB, ç©ºé—²=14.97GB
wiki desc: Description for Cessna 525 category.
[2025-11-22 22:18:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.53GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.51GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 15.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.24 GiB is free. Including non-PyTorch memory, this process has 35.15 GiB memory in use. Of the allocated memory 34.43 GiB is allocated by PyTorch, and 421.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Cessna 525 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Cessna 525 category....
å¤„ç†ç±»åˆ«: C-130
[2025-11-22 22:18:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
[2025-11-22 22:18:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
wiki desc: Description for C-130 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 8.79 GiB. GPU 0 has a total capacity of 47.40 GiB of which 4.20 GiB is free. Including non-PyTorch memory, this process has 43.19 GiB memory in use. Of the allocated memory 42.49 GiB is allocated by PyTorch, and 403.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« C-130 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for C-130 category....
å¤„ç†ç±»åˆ«: DC-8
[2025-11-22 22:19:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.88GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.88GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.88GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.88GB, ç©ºé—²=14.97GB
wiki desc: Description for DC-8 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 9.68 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.20 GiB is free. Including non-PyTorch memory, this process has 44.19 GiB memory in use. Of the allocated memory 43.47 GiB is allocated by PyTorch, and 415.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-11-22 22:19:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=33.13GB, å·²ä¿ç•™=43.88GB, ç©ºé—²=14.28GB
ç±»åˆ« DC-8 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for DC-8 category....
å¤„ç†ç±»åˆ«: 757-200
[2025-11-22 22:19:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.88GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.88GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=43.88GB, ç©ºé—²=14.97GB
wiki desc: Description for 757-200 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.50GB, å·²ä¿ç•™=32.93GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 13.29 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.46 GiB is free. Including non-PyTorch memory, this process has 34.93 GiB memory in use. Of the allocated memory 34.25 GiB is allocated by PyTorch, and 380.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« 757-200 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for 757-200 category....
å¤„ç†ç±»åˆ«: Saab 340
[2025-11-22 22:19:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.62GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:29] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.62GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:32] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.62GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:35] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.62GB, ç©ºé—²=14.97GB
wiki desc: Description for Saab 340 category.
[2025-11-22 22:19:38] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.62GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.91GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 9.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.96 GiB is free. Including non-PyTorch memory, this process has 44.43 GiB memory in use. Of the allocated memory 43.78 GiB is allocated by PyTorch, and 354.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Saab 340 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Saab 340 category....
å¤„ç†ç±»åˆ«: DC-3
[2025-11-22 22:19:41] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.12GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:44] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.12GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.12GB, ç©ºé—²=14.97GB
wiki desc: Description for DC-3 category.
[2025-11-22 22:19:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.12GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.92 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.22 GiB is free. Including non-PyTorch memory, this process has 42.18 GiB memory in use. Of the allocated memory 41.51 GiB is allocated by PyTorch, and 362.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« DC-3 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for DC-3 category....
å¤„ç†ç±»åˆ«: Eurofighter Typhoon
[2025-11-22 22:19:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.87GB, ç©ºé—²=14.97GB
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/98 [07:27<13:20, 12.70s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 36/98 [07:39<12:59, 12.57s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 37/98 [07:51<12:40, 12.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 38/98 [08:25<18:40, 18.67s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 39/98 [08:37<16:30, 16.78s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/98 [08:50<15:10, 15.69s/it][2025-11-22 22:19:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.87GB, ç©ºé—²=14.97GB
[2025-11-22 22:19:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.87GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.87GB, ç©ºé—²=14.97GB
wiki desc: Description for Eurofighter Typhoon category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.51GB, å·²ä¿ç•™=32.90GB, å‰©ä½™=14.90GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 15.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 12.24 GiB is free. Including non-PyTorch memory, this process has 35.15 GiB memory in use. Of the allocated memory 34.43 GiB is allocated by PyTorch, and 416.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Eurofighter Typhoon æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Eurofighter Typhoon category....
å¤„ç†ç±»åˆ«: ERJ 145
[2025-11-22 22:20:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=34.84GB, ç©ºé—²=14.97GB
wiki desc: Description for ERJ 145 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.85GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 8.03 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.08 GiB is free. Including non-PyTorch memory, this process has 42.31 GiB memory in use. Of the allocated memory 41.64 GiB is allocated by PyTorch, and 372.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« ERJ 145 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for ERJ 145 category....
å¤„ç†ç±»åˆ«: SR-20
[2025-11-22 22:20:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.00GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.00GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.00GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=42.00GB, ç©ºé—²=14.97GB
wiki desc: Description for SR-20 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.58 GiB is free. Including non-PyTorch memory, this process has 41.81 GiB memory in use. Of the allocated memory 41.10 GiB is allocated by PyTorch, and 415.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-11-22 22:20:29] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=33.03GB, å·²ä¿ç•™=41.50GB, ç©ºé—²=14.37GB
ç±»åˆ« SR-20 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for SR-20 category....
å¤„ç†ç±»åˆ«: 737-500
[2025-11-22 22:20:32] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.50GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:35] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.50GB, ç©ºé—²=14.97GB
[2025-11-22 22:20:38] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=41.50GB, ç©ºé—²=14.97GB
wiki desc: Description for 737-500 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.83GB, å‰©ä½™=14.92GB
[2025-11-22 22:20:41] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.92GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.48GB
[2025-11-22 22:20:44] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.92GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.48GB
[2025-11-22 22:20:47] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.75GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.66GB
[2025-11-22 22:20:50] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.75GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.65GB
[2025-11-22 22:20:53] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.76GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.64GB
[2025-11-22 22:20:56] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.76GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.64GB
[2025-11-22 22:20:59] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.77GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.63GB
æ¨ç†åæ˜¾å­˜: å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.78GB, å‰©ä½™=14.97GB
MLLM description: The Boeing 737-500 is a narrow-body, twin-engine jet airliner with the following distinctive features:

1. **Distinctive Physical Features**: The 737-500 has a short fuselage compared to its larger counterparts like the 737-800 or 737 MAX series. It features a T-tail configuration, where the horizontal stabilizer is mounted on top of the vertical stabilizer. The wings have a slight sweepback, and the engines are mounted under the wings.

2. **Color Patterns and Markings**: The 737-500 can come in various liveries depending on the airline. In the first image, the aircraft displays a white livery with "Cirrus Airlines" branding and a logo on the tail. The second image shows an aircraft with a white body and blue tail, possibly indicating a different airline or special livery. The third image depicts a Lufthansa-branded aircraft with a white fuselage and dark blue tail featuring the Lufthansa logo.

3. **Size and Proportions**: The 737-500 is smaller than the 737-800 or 737 MAX
[2025-11-22 22:21:02] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.97GB
ç±»åˆ« 737-500 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: The Boeing 737-500 is a narrow-body, twin-engine jet airliner with the following distinctive feature...
å¤„ç†ç±»åˆ«: DH-82
[2025-11-22 22:21:05] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.97GB
[2025-11-22 22:21:08] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.97GB
[2025-11-22 22:21:11] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=45.78GB, ç©ºé—²=14.97GB
wiki desc: Description for DH-82 category.
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.49GB, å·²ä¿ç•™=32.86GB, å‰©ä½™=14.91GB
[2025-11-22 22:21:14] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.75GB, å·²ä¿ç•™=33.12GB, ç©ºé—²=14.65GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 10.36 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.49 GiB is free. Including non-PyTorch memory, this process has 44.90 GiB memory in use. Of the allocated memory 44.23 GiB is allocated by PyTorch, and 371.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« DH-82 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for DH-82 category....
å¤„ç†ç±»åˆ«: Beechcraft 1900
[2025-11-22 22:21:17] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.59GB, ç©ºé—²=14.97GB
[2025-11-22 22:21:20] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.59GB, ç©ºé—²=14.97GB
[2025-11-22 22:21:23] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.59GB, ç©ºé—²=14.97GB
wiki desc: Description for Beechcraft 1900 category.
[2025-11-22 22:21:26] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…=32.44GB, å·²ä¿ç•™=44.59GB, ç©ºé—²=14.97GB
æ¨ç†å‰æ˜¾å­˜: å·²åˆ†é…=32.48GB, å·²ä¿ç•™=32.84GB, å‰©ä½™=14.92GB
MLLMæè¿°ç”Ÿæˆå¤±è´¥: CUDA out of memory. Tried to allocate 7.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 5.99 GiB is free. Including non-PyTorch memory, this process has 41.40 GiB memory in use. Of the allocated memory 40.74 GiB is allocated by PyTorch, and 358.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ç±»åˆ« Beechcraft 1900 æ–‡æœ¬ç‰¹å¾ç»´åº¦: (512,)
æè¿°: Description for Beechcraft 1900 category....
å¤„ç†ç±»åˆ«: E-170
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 41/98 [09:03<14:12, 14.95s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/98 [09:17<13:43, 14.70s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/98 [09:52<19:03, 20.79s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/98 [10:05<16:35, 18.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/98 [10:19<14:53, 16.86s/it]scripts/run_pipeline.sh: line 148: 1733722 Killed                  python discovering.py --mode=build_knowledge_base --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/${CONFIG_FILE_DS} --num_per_category=${KSHOT} --knowledge_base_dir=${KNOWLEDGE_BASE_DIR}
[ERROR] Step1: çŸ¥è¯†åº“æ„å»ºå¤±è´¥ï¼Œé€€å‡º pipeline (exit code=137)
