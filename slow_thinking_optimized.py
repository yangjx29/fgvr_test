"""
ä¼˜åŒ–åçš„æ…¢æ€è€ƒæ¨¡å—
ä¸»è¦ä¼˜åŒ–:
1. å‡å°‘MLLMè°ƒç”¨æ¬¡æ•° - åˆå¹¶ç›¸ä¼¼æ­¥éª¤
2. ç®€åŒ–æ…¢æ€è€ƒæµç¨‹ - ä½¿ç”¨æ›´ç®€å•çš„æ¨ç†æ–¹æ³•
3. æ·»åŠ ç¼“å­˜æœºåˆ¶ - ç¼“å­˜MLLMå“åº”
4. å¿«é€Ÿè·¯å¾„ä¼˜åŒ– - åœ¨æ…¢æ€è€ƒä¸­ä¹Ÿå¯ä»¥æå‰é€€å‡º
"""

import os
import numpy as np
import torch
from PIL import Image
from typing import List, Tuple, Dict, Optional
import json
import re
from collections import Counter
import hashlib
from functools import lru_cache

from agents.mllm_bot import MLLMBot
from knowledge_base_builder import KnowledgeBaseBuilder
from experience_base_builder import ExperienceBaseBuilder
from fast_thinking import FastThinking
from utils.util import is_similar
from data import DATA_STATS
from difflib import get_close_matches


class SlowThinkingOptimized:
    """ä¼˜åŒ–åçš„æ…¢æ€è€ƒæ¨¡å—"""
    
    def __init__(self, mllm_bot: MLLMBot, knowledge_base_builder: KnowledgeBaseBuilder,
                 fast_thinking: FastThinking,
                 experience_base_builder: ExperienceBaseBuilder=None,
                 enable_cache: bool = True,
                 cache_size: int = 1000,
                 simplified_reasoning: bool = True,
                 use_experience_base: bool = True,
                 top_k_experience: int = 1,
                 dataset_info: dict = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–åçš„æ…¢æ€è€ƒæ¨¡å—
        
        Args:
            mllm_bot: MLLMæ¨¡å‹
            knowledge_base_builder: çŸ¥è¯†åº“æ„å»ºå™¨
            fast_thinking: å¿«æ€è€ƒæ¨¡å—
            experience_base_builder: ç»éªŒåº“æ„å»ºå™¨
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            cache_size: ç¼“å­˜å¤§å°
            simplified_reasoning: æ˜¯å¦ä½¿ç”¨ç®€åŒ–çš„æ¨ç†æ–¹æ³•
            use_experience_base: æ˜¯å¦ä½¿ç”¨ç»éªŒåº“
            top_k_experience: ä½¿ç”¨top-kä¸ªç±»åˆ«çš„ç»éªŒ
        """
        from datetime import datetime
        init_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print("\n================= æ…¢æ€è€ƒæ¨¡å—åˆå§‹åŒ– =================")
        print(f"ğŸ•’ åˆå§‹åŒ–æ—¶é—´: {init_time}")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {mllm_bot.device}")
        print(f"ğŸ§  MLLMæ¨¡å‹: {mllm_bot.model_name}")
        print(f"ğŸ“š çŸ¥è¯†åº“æ„å»ºå™¨: {knowledge_base_builder}")
        print(f"âš¡ å¿«æ€è€ƒæ¨¡å—: {fast_thinking}")
        print(f"ğŸ“– ç»éªŒåº“æ„å»ºå™¨: {experience_base_builder}")
        print(f"ğŸ’¾ å¯ç”¨ç¼“å­˜: {'æ˜¯' if enable_cache else 'å¦'}, ç¼“å­˜å¤§å°: {cache_size}")
        print(f"ğŸ” ç®€åŒ–æ¨ç†: {'æ˜¯' if simplified_reasoning else 'å¦'}")
        print(f"ğŸ§© ä½¿ç”¨ç»éªŒåº“: {'æ˜¯' if use_experience_base else 'å¦'}, top_k_experience={top_k_experience}")

        self.mllm_bot = mllm_bot
        self.kb_builder = knowledge_base_builder
        self.fast_thinking = fast_thinking
        self.exp_builder = experience_base_builder
        self.enable_cache = enable_cache
        self.cache_size = cache_size
        self.simplified_reasoning = simplified_reasoning
        self.use_experience_base = use_experience_base
        self.top_k_experience = top_k_experience
        self.dataset_info = dataset_info or {}
        
        # ä½¿ç”¨dataset_infoè·å–é»˜è®¤save_dir
        if not self.dataset_info or 'experiment_dir_full' not in self.dataset_info:
            raise ValueError(
                "SlowThinkingOptimizedåˆå§‹åŒ–å¤±è´¥: å¿…é¡»æä¾›å®Œæ•´çš„dataset_infoã€‚"
                "dataset_infoåº”åŒ…å«'experiment_dir_full'å­—æ®µï¼Œä»¥é¿å…è¯¯æ±¡æŸ“çŸ¥è¯†åº“ã€‚"
            )
        self.default_save_dir = os.path.join(
            self.dataset_info['experiment_dir_full'],
            'knowledge_base'
        )
        print(f"æ…¢æ€è€ƒé»˜è®¤ä¿å­˜ç›®å½•: {self.default_save_dir}")
        
        # ç¼“å­˜æœºåˆ¶
        self._mllm_cache = {}  # MLLMå“åº”ç¼“å­˜
        self._description_cache = {}  # æè¿°ç¼“å­˜
        
        # åŠ¨æ€è·å–å½“å‰æ•°æ®é›†çš„ç±»åˆ«åç§°
        dataset_name = self._get_dataset_name_from_info()
        if dataset_name not in DATA_STATS:
            raise ValueError(
                f"SlowThinkingOptimizedåˆå§‹åŒ–å¤±è´¥: æœªçŸ¥çš„æ•°æ®é›† '{dataset_name}'ã€‚"
                f"å¯ç”¨æ•°æ®é›†: {list(DATA_STATS.keys())}"
            )
        self.current_dataset_stats = DATA_STATS[dataset_name]
        print(f"ä½¿ç”¨æ•°æ®é›†: {dataset_name}, ç±»åˆ«æ•°: {self.current_dataset_stats['num_classes']}")
        
        # ç±»åˆ«åç§°æ˜ å°„
        self.normalized_to_original = {
            self.normalize_name(cls): cls for cls in self.current_dataset_stats['class_names']
        }
        self.normalized_class_names = list(self.normalized_to_original.keys())
        print(f"âœ… æ…¢æ€è€ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆï¼Œç±»åˆ«æ˜ å°„æ•°é‡: {len(self.normalized_class_names)}")
        print("====================================================\n")        
    
    def _get_dataset_name_from_info(self) -> str:
        """ä»dataset_infoæ¨æ–­æ•°æ®é›†åç§°"""
        # å°è¯•ä»full_nameæ¨æ–­ (ä¾‹å¦‚: dog120 -> dog)
        if 'full_name' in self.dataset_info:
            full_name = self.dataset_info['full_name'].lower()
            for dataset_name in DATA_STATS.keys():
                if dataset_name in full_name:
                    return dataset_name
        
        # å°è¯•ä»experiment_diræ¨æ–­
        if 'experiment_dir' in self.dataset_info:
            exp_dir = self.dataset_info['experiment_dir'].lower()
            for dataset_name in DATA_STATS.keys():
                if dataset_name in exp_dir:
                    return dataset_name
        
        # å¦‚æœæ— æ³•æ¨æ–­ï¼ŒæŠ›å‡ºé”™è¯¯
        raise ValueError(
            "æ— æ³•ä»dataset_infoæ¨æ–­æ•°æ®é›†åç§°ã€‚"
            "è¯·ç¡®ä¿dataset_infoåŒ…å«'full_name'æˆ–'experiment_dir'å­—æ®µã€‚"
        )
    
    def set_experience_base(self, experience_base_builder: ExperienceBaseBuilder):
        """è®¾ç½®ç»éªŒåº“æ„å»ºå™¨"""
        self.exp_builder = experience_base_builder
        print("ç»éªŒåº“å·²è®¾ç½®åˆ°æ…¢æ€è€ƒæ¨¡å—")
    
    def _get_self_belief_context(self) -> str:
        """
        è·å–å½“å‰Self-Beliefç­–ç•¥ä¸Šä¸‹æ–‡
        """
        if not self.use_experience_base or not self.exp_builder:
            return ""
        try:
            policy_text = self.exp_builder.get_self_belief()
        except AttributeError:
            return self.exp_builder.INITIAL_SELF_BELIEF
        if not policy_text or not isinstance(policy_text, str):
            return ""
        return f"Self-Belief Policy Context:\n{policy_text.strip()}"
    
    def normalize_name(self, name):
        """æ ‡å‡†åŒ–ç±»åˆ«åç§°"""
        name = name.lower()
        name = re.sub(r'[-_]', ' ', name)
        name = re.sub(r'\s+', ' ', name)
        return name.strip()
    
    def _get_cache_key(self, image_path: str, prompt: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        if not self.enable_cache:
            return None
        cache_key = hashlib.md5(f"{image_path}_{prompt}".encode()).hexdigest()
        return cache_key
    
    def _cached_mllm_call(self, image_path: str, prompt: str, image: Image.Image = None) -> str:
        """ç¼“å­˜çš„MLLMè°ƒç”¨"""
        cache_key = self._get_cache_key(image_path, prompt)
        if cache_key and cache_key in self._mllm_cache:
            return self._mllm_cache[cache_key]
        
        # è°ƒç”¨MLLM
        if image is None:
            image = Image.open(image_path).convert("RGB")
        
        reply, response = self.mllm_bot.describe_attribute(image, prompt)
        if isinstance(response, list):
            response = " ".join(response)
        
        # ç¼“å­˜ç»“æœ
        if cache_key:
            if len(self._mllm_cache) >= self.cache_size:
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                oldest_key = next(iter(self._mllm_cache))
                del self._mllm_cache[oldest_key]
            self._mllm_cache[cache_key] = response
        
        return response
    
    def reasoning_with_experience_base(self, query_image_path: str, fast_result: Dict,
                                       top_k_candidates: List[str],
                                       experience_context: str = "",
                                       top_k: int = 5) -> Dict:
        """
        åŸºäºç»éªŒåº“çš„æ¨ç†æµç¨‹ - ä½¿ç”¨ç»éªŒåº“æŒ‡å¯¼MLLMæ¨ç†
        ç§»é™¤å¢å¼ºæ£€ç´¢ï¼Œç›´æ¥ä½¿ç”¨å¿«æ€è€ƒç»“æœ + ç»éªŒåº“
        
        Args:
            query_image_path: æŸ¥è¯¢å›¾åƒè·¯å¾„
            fast_result: å¿«æ€è€ƒç»“æœ
            top_k_candidates: å¿«æ€è€ƒçš„top-kå€™é€‰ç±»åˆ«
            experience_context: ç»éªŒåº“ä¸Šä¸‹æ–‡
            top_k: å€™é€‰ç±»åˆ«æ•°é‡
            
        Returns:
            Dict: æ¨ç†ç»“æœ
        """
        image = Image.open(query_image_path).convert("RGB")
        
        # æ”¶é›†å€™é€‰ç±»åˆ«ï¼šä½¿ç”¨å¿«æ€è€ƒçš„top-kç»“æœ
        candidates = []
        fused_results = fast_result.get("fused_results", [])
        for cat, score in fused_results:
            candidates.append((str(cat), float(score)))
        
        # ç»„ç»‡å€™é€‰å±•ç¤ºæ–‡æœ¬
        candidate_text = ""
        for i, (cat, sc) in enumerate(candidates, start=1):
            candidate_text += f"{i}. {cat} (score: {sc:.4f})\n"
        
        # æ„å»ºæç¤ºè¯ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç»éªŒåº“ä½œä¸ºè¾…åŠ©ä¿¡æ¯
        prompt = f"""Candidate classes (highly likely to contain the correct option):
        {candidate_text}\n{experience_context}"""
        # f"""You are an expert in fine-grained visual recognition. Analyze the image and determine the most likely category from the candidates:
        # {candidate_text}
        # Fast thinking results:
        # - Top prediction: {fast_result.get('fused_top1', 'unknown')} (confidence: {fast_result.get('fused_top1_prob', 0):.3f})
        # - Image prediction: {fast_result.get('img_category', 'unknown')} (confidence: {fast_result.get('img_confidence', 0):.3f})
        # - Text prediction: {fast_result.get('text_category', 'unknown')} (confidence: {fast_result.get('text_confidence', 0):.3f})
        # - Margin: {fast_result.get('fused_margin', 0):.3f}

        # """
        
        # å¦‚æœæœ‰ç»éªŒåº“ä¸Šä¸‹æ–‡ï¼Œç®€æ´åœ°æ·»åŠ åˆ°æç¤ºè¯ä¸­
        # if experience_context:
        #     prompt += f"{experience_context}\n\n"
        
        # prompt += """Analyze the image and consider:
        # 1. Visual characteristics (size, shape, color, texture, distinctive features)
        # 2. Similarity scores from fast thinking
        # 3. Consistency between predictions
        # 4. Key distinguishing features

        # Return ONLY a JSON object:
        # {{
        #     "predicted_category": "exact category name",
        #     "confidence": 0.0-1.0,
        #     "reasoning": "brief rationale",
        #     "key_features": "main visual features"
        # }}"""
        
        # response = self._cached_mllm_call(query_image_path, prompt, image)
        # json_match = re.search(r'\{.*\}', response, re.DOTALL)
        # if json_match:
        #     json_str = json_match.group()
        #     result = json.loads(json_str)
        #     predicted_category = result.get("predicted_category", "unknown")
        #     confidence = float(result.get("confidence", 0.5))
        #     reasoning = result.get("reasoning", "no rationale")
        #     key_features = result.get("key_features", "no features")
        #     info = f"{reasoning} | Features: {key_features}"
        #     used_experience = bool(experience_context)
        # else:
        #     # è§£æå¤±è´¥ï¼šä½¿ç”¨å¿«æ€è€ƒçš„Top-1
        #     fallback = candidates[0][0] if candidates else "unknown"
        #     predicted_category = fallback
        #     confidence = float(candidates[0][1]) if candidates else 0.5
        #     info = "JSON parsing failed; fallback to fast thinking"
        #     used_experience = False
        prompt += """\nPlease analyze the image step by step and provide:
            1. Your reasoning chain (CoT) following the steps above
            2. Your final prediction (only the category name)
            Format your response as:
            Reasoning: [your step-by-step reasoning]
            Prediction: [category name]"""
        reply, response = self.mllm_bot.describe_attribute(image, prompt)
        if isinstance(response, list):
            response = " ".join(response)
        
        # è§£æCoTå’Œé¢„æµ‹
        cot = ""
        prediction = "unknown"
        
        # æå–æ¨ç†é“¾
        reasoning_match = re.search(r'Reasoning[:\s]+(.*?)(?=Prediction|$)', response, re.DOTALL | re.IGNORECASE)
        if reasoning_match:
            cot = reasoning_match.group(1).strip()
        else:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®æ ‡è®°ï¼Œå°è¯•æå–æ•´ä¸ªå“åº”ä½œä¸ºæ¨ç†é“¾
            cot = response
        
        # æå–é¢„æµ‹
        prediction_match = re.search(r'Prediction[:\s]+([^\n]+)', response, re.IGNORECASE)
        if prediction_match:
            # print(f"è§£ææˆåŠŸ! é¢„æµ‹: {prediction_match.group(1).strip()}")
            prediction = prediction_match.group(1).strip()
        else:
            # å°è¯•ä»å“åº”æœ«å°¾æå–ç±»åˆ«åç§°
            lines = response.strip().split('\n')
            if lines:
                last_line = lines[-1].strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯å€™é€‰ç±»åˆ«ä¹‹ä¸€
                for cat in top_k_candidates:
                    if cat.lower() in last_line.lower() or last_line.lower() in cat.lower():
                        prediction = cat
                        break
                if prediction == "unknown":
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå€™é€‰ä½œä¸ºfallback
                    prediction = top_k_candidates[0] if top_k_candidates else "unknown"
        # ç±»åˆ«åç§°ä¿®æ­£
        predicted_category = self._correct_category_name(prediction)
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆä½¿ç”¨fast_resultä¸­çš„å¾—åˆ†ï¼‰
        confidence = 0.0
        if top_k_candidates:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå€™é€‰çš„å¾—åˆ†ä½œä¸ºç½®ä¿¡åº¦
            for cat, score in fast_result.get("fused_results", []):
                if self.normalize_name(cat) == self.normalize_name(predicted_category):
                    confidence = float(score)
                    break
        
        return {
            "predicted_category": predicted_category,
            "confidence": confidence,
            "reasoning": cot,
            "fast_result": fast_result,
            "top_k_candidates": top_k_candidates,
            "simplified": True
        }
            
    
    def simplified_reasoning_with_enhanced(self, query_image_path: str, fast_result: Dict,
                                          enhanced_results: List[Tuple[str, float]], 
                                          top_k: int = 5) -> Dict:
        """
        ç»“åˆå¢å¼ºæ£€ç´¢ç»“æœçš„ç®€åŒ–æ¨ç†æµç¨‹ - æé«˜å‡†ç¡®ç‡
        """
        image = Image.open(query_image_path).convert("RGB")
        
        # æ”¶é›†å€™é€‰ç±»åˆ«ï¼šfastç»“æœ + å¢å¼ºæ£€ç´¢ç»“æœ
        candidates = []
        
        # æ·»åŠ fastç»“æœçš„Top-K
        fused_results = fast_result.get("fused_results", [])
        for cat, score in fused_results[:top_k]:
            candidates.append((str(cat), float(score)))
        
        # æ·»åŠ å¢å¼ºæ£€ç´¢ç»“æœ
        for cat, score in (enhanced_results or [])[:top_k]:
            candidates.append((str(cat), float(score)))
        
        # å»é‡å¹¶æŒ‰åˆ†æ•°é™åº
        dedup = {}
        for cat, sc in candidates:
            if cat not in dedup or sc > dedup[cat]:
                dedup[cat] = sc
        merged = sorted([(c, s) for c, s in dedup.items()], key=lambda x: x[1], reverse=True)
        
        # ç»„ç»‡å€™é€‰å±•ç¤ºæ–‡æœ¬
        candidate_text = ""
        for i, (cat, sc) in enumerate(merged[:top_k * 2], start=1):  # æ˜¾ç¤ºæ›´å¤šå€™é€‰
            candidate_text += f"{i}. {cat} (score: {sc:.4f})\n"
        
        # æ”¹è¿›çš„æç¤º - æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯
        prompt = f"""You are an expert in fine-grained visual recognition. Look at the image and determine the most likely subclass from the following candidates:

        {candidate_text}

        Fast thinking analysis:
        - Image-based prediction: {fast_result.get('img_category', 'unknown')} (confidence: {fast_result.get('img_confidence', 0):.3f})
        - Text-based prediction: {fast_result.get('text_category', 'unknown')} (confidence: {fast_result.get('text_confidence', 0):.3f})
        - Fused prediction: {fast_result.get('fused_top1', 'unknown')} (confidence: {fast_result.get('fused_top1_prob', 0):.3f})
        - Fused margin: {fast_result.get('fused_margin', 0):.3f}

        Enhanced retrieval results:
        - Top candidate: {enhanced_results[0][0] if enhanced_results else 'unknown'} (score: {(enhanced_results[0][1] if enhanced_results else 0.0):.4f})

        Please analyze the image carefully and consider:
        1. The visual characteristics of the object (size, shape, color, texture, distinctive features)
        2. The similarity scores from both fast thinking and enhanced retrieval
        3. The consistency between different predictions
        4. Any distinctive features that help distinguish between similar categories
        5. The confidence margins between top candidates

        Pay special attention to:
        - Breed-specific features (ear shape, tail, muzzle, body proportions)
        - Color patterns and markings
        - Size and overall appearance
        - Any unique identifying traits

        Return ONLY a JSON object with the following fields:
        {{
            "predicted_category": "exact category name",
            "confidence": 0.0-1.0,
            "reasoning": "brief but detailed rationale for your decision",
            "key_features": "main visual features supporting your decision",
            "alternative_candidates": ["category1", "category2"] (if applicable)
        }}"""
        
        try:
            response = self._cached_mllm_call(query_image_path, prompt, image)
            
            # è§£æJSONå“åº”
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    result = json.loads(json_str)
                    predicted_category = result.get("predicted_category", "unknown")
                    confidence = float(result.get("confidence", 0.5))
                    reasoning = result.get("reasoning", "no rationale")
                    key_features = result.get("key_features", "no features")
                    alternative_candidates = result.get("alternative_candidates", [])
                    info = f"{reasoning} | Key Features: {key_features}"
                    if alternative_candidates:
                        info += f" | Alternatives: {', '.join(alternative_candidates)}"
                else:
                    # è§£æå¤±è´¥ï¼šä½¿ç”¨å¢å¼ºæ£€ç´¢çš„Top-1
                    fallback = enhanced_results[0][0] if enhanced_results else (merged[0][0] if merged else "unknown")
                    predicted_category = fallback
                    confidence = float(enhanced_results[0][1]) if enhanced_results else (float(merged[0][1]) if merged else 0.5)
                    info = "JSON parsing failed; fallback to enhanced retrieval top candidate"
            except (json.JSONDecodeError, ValueError):
                # è§£æå¤±è´¥ï¼šä½¿ç”¨å¢å¼ºæ£€ç´¢çš„Top-1
                fallback = enhanced_results[0][0] if enhanced_results else (merged[0][0] if merged else "unknown")
                predicted_category = fallback
                confidence = float(enhanced_results[0][1]) if enhanced_results else (float(merged[0][1]) if merged else 0.5)
                info = "JSON parsing failed; fallback to enhanced retrieval top candidate"
            
            # ç±»åˆ«åç§°ä¿®æ­£
            predicted_category = self._correct_category_name(predicted_category)
            
            return {
                "predicted_category": predicted_category,
                "confidence": confidence,
                "reasoning": info,
                "enhanced_results": enhanced_results,
                "fast_result": fast_result,
                "simplified": True
            }
            
        except Exception as e:
            print(f"ç®€åŒ–æ¨ç†å¤±è´¥: {e}")
            # å›é€€åˆ°å¢å¼ºæ£€ç´¢ç»“æœ
            fallback = enhanced_results[0][0] if enhanced_results else (merged[0][0] if merged else "unknown")
            conf = float(enhanced_results[0][1]) if enhanced_results else (float(merged[0][1]) if merged else 0.0)
            return {
                "predicted_category": self._correct_category_name(fallback),
                "confidence": conf,
                "reasoning": f"Simplified reasoning failed: {str(e)}",
                "enhanced_results": enhanced_results,
                "fast_result": fast_result,
                "simplified": True
            }
    
    def simplified_reasoning_pipeline(self, query_image_path: str, fast_result: Dict, 
                                     top_k: int = 5) -> Dict:
        """
        ç®€åŒ–çš„æ¨ç†æµç¨‹ - å‡å°‘MLLMè°ƒç”¨æ¬¡æ•°
        åªè¿›è¡Œä¸€æ¬¡MLLMè°ƒç”¨,ç›´æ¥ç»™å‡ºæœ€ç»ˆé¢„æµ‹
        """
        image = Image.open(query_image_path).convert("RGB")
        
        # æ”¶é›†å€™é€‰ç±»åˆ«
        candidates = []
        fast_top1 = fast_result.get("fused_top1") or fast_result.get("predicted_category")
        if isinstance(fast_top1, str) and len(fast_top1) > 0:
            candidates.append((fast_top1, float(fast_result.get("fused_top1_prob", 1.0))))
        
        # æ·»åŠ fastç»“æœçš„Top-K
        fused_results = fast_result.get("fused_results", [])
        for cat, score in fused_results[:top_k]:
            if cat not in [c[0] for c in candidates]:
                candidates.append((str(cat), float(score)))
        
        # å»é‡å¹¶æŒ‰åˆ†æ•°é™åº
        dedup = {}
        for cat, sc in candidates:
            if cat not in dedup or sc > dedup[cat]:
                dedup[cat] = sc
        merged = sorted([(c, s) for c, s in dedup.items()], key=lambda x: x[1], reverse=True)
        
        # ç»„ç»‡å€™é€‰å±•ç¤ºæ–‡æœ¬
        candidate_text = ""
        for i, (cat, sc) in enumerate(merged, start=1):
            candidate_text += f"{i}. {cat} (score: {sc:.4f})\n"
        
        # æ”¹è¿›çš„æç¤º - æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯å’Œè¯¦ç»†åˆ†æè¦æ±‚
        prompt = f"""You are an expert in fine-grained visual recognition. Look at the image and determine the most likely subclass from the following candidates:

{candidate_text}

Fast thinking analysis:
- Image-based prediction: {fast_result.get('img_category', 'unknown')} (confidence: {fast_result.get('img_confidence', 0):.3f})
- Text-based prediction: {fast_result.get('text_category', 'unknown')} (confidence: {fast_result.get('text_confidence', 0):.3f})
- Fused prediction: {fast_result.get('fused_top1', 'unknown')} (confidence: {fast_result.get('fused_top1_prob', 0):.3f})
- Fused margin: {fast_result.get('fused_margin', 0):.3f}

Please analyze the image carefully and consider:
1. The visual characteristics of the object (size, shape, color, texture, distinctive features)
2. The similarity scores from fast thinking
3. The consistency between different predictions
4. Any distinctive features that help distinguish between similar categories
5. The confidence margins between top candidates

Pay special attention to:
- Breed-specific features (ear shape, tail, muzzle, body proportions)
- Color patterns and markings
- Size and overall appearance
- Any unique identifying traits

Return ONLY a JSON object with the following fields:
{{
    "predicted_category": "exact category name",
    "confidence": 0.0-1.0,
    "reasoning": "brief but detailed rationale for your decision",
    "key_features": "main visual features supporting your decision",
    "alternative_candidates": ["category1", "category2"] (if applicable)
}}"""
        
        try:
            response = self._cached_mllm_call(query_image_path, prompt, image)
            
            # è§£æJSONå“åº”
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    result = json.loads(json_str)
                    predicted_category = result.get("predicted_category", "unknown")
                    confidence = float(result.get("confidence", 0.5))
                    reasoning = result.get("reasoning", "no rationale")
                    key_features = result.get("key_features", "no features")
                    alternative_candidates = result.get("alternative_candidates", [])
                    info = f"{reasoning} | Key Features: {key_features}"
                    if alternative_candidates:
                        info += f" | Alternatives: {', '.join(alternative_candidates)}"
                else:
                    # è§£æå¤±è´¥ï¼šå›é€€åˆ°åˆ†æ•°æœ€é«˜çš„å€™é€‰
                    fallback = merged[0][0] if merged else (fast_top1 or "unknown")
                    predicted_category = fallback
                    confidence = float(merged[0][1]) if merged else 0.5
                    info = "JSON parsing failed; fallback to top candidate"
            except (json.JSONDecodeError, ValueError):
                fallback = merged[0][0] if merged else (fast_top1 or "unknown")
                predicted_category = fallback
                confidence = float(merged[0][1]) if merged else 0.5
                info = "JSON parsing failed; fallback to top candidate"
            
            # ç±»åˆ«åç§°ä¿®æ­£
            predicted_category = self._correct_category_name(predicted_category)
            
            return {
                "predicted_category": predicted_category,
                "confidence": confidence,
                "reasoning": info,
                "simplified": True,
                "fast_result": fast_result
            }
            
        except Exception as e:
            print(f"ç®€åŒ–æ¨ç†å¤±è´¥: {e}")
            # å›é€€åˆ°fastç»“æœ
            fallback = merged[0][0] if merged else (fast_top1 or "unknown")
            conf = float(merged[0][1]) if merged else 0.0
            return {
                "predicted_category": self._correct_category_name(fallback),
                "confidence": conf,
                "reasoning": f"Simplified reasoning failed: {str(e)}",
                "simplified": True,
                "fast_result": fast_result
            }
    
    def _correct_category_name(self, predicted_category: str) -> str:
        """ä¿®æ­£ç±»åˆ«åç§°"""
        if predicted_category not in self.current_dataset_stats['class_names']:
            # æ ‡å‡†åŒ–åç§°
            norm_pred = self.normalize_name(predicted_category)
            
            # ç²¾ç¡®åŒ¹é…
            if norm_pred in self.normalized_class_names:
                corrected_category = self.normalized_to_original[norm_pred]
                print(f"ç²¾ç¡®æ ‡å‡†åŒ–åŒ¹é…ç±»åˆ«ä¿®æ­£: '{predicted_category}' -> '{corrected_category}'")
                return corrected_category
            else:
                # æ¨¡ç³ŠåŒ¹é…
                close_matches = get_close_matches(norm_pred, self.normalized_class_names, n=1, cutoff=0.3)
                if close_matches:
                    best_match_norm = close_matches[0]
                    corrected_category = self.normalized_to_original[best_match_norm]
                    print(f"æ¨¡ç³ŠåŒ¹é…ç±»åˆ«ä¿®æ­£: '{predicted_category}' -> '{corrected_category}'")
                    return corrected_category
                else:
                    print(f'å‘ç°æ–°ç±»åˆ«:{predicted_category}')
                    return predicted_category
        return predicted_category
    
    def enhanced_retrieval_only(self, query_image_path: str, fast_result: Dict, 
                               top_k: int = 5) -> List[Tuple[str, float]]:
        """
        æ”¹è¿›çš„å¢å¼ºæ£€ç´¢ - ç»“åˆå¤šç§æ£€ç´¢ç­–ç•¥æé«˜å‡†ç¡®ç‡
        åŸºäºfastç»“æœã€å›¾åƒç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œå¤šæ¨¡æ€æ£€ç´¢
        """
        try:
            # æå–å›¾åƒç‰¹å¾
            img_feat = self.kb_builder.retrieval.extract_image_feat(query_image_path)
            
            # 1. å›¾åƒ-å›¾åƒæ£€ç´¢
            img_img_similarities = {}
            for category, kb_feat in self.kb_builder.image_knowledge_base.items():
                sim = np.dot(img_feat, kb_feat)
                img_img_similarities[category] = float(sim)
            
            # 2. å›¾åƒ-æ–‡æœ¬æ£€ç´¢
            img_text_similarities = {}
            for category, text_feat in self.kb_builder.text_knowledge_base.items():
                sim = np.dot(img_feat, text_feat)
                img_text_similarities[category] = float(sim)
            
            # 3. ä½¿ç”¨fastç»“æœçš„Top-Kç±»åˆ«è¿›è¡ŒåŠ æƒæ£€ç´¢
            fused_results = fast_result.get("fused_results", [])
            fast_scores = {}
            for category, score in fused_results[:top_k * 3]:  # æ‰©å¤§å€™é€‰èŒƒå›´
                fast_scores[category] = float(score)
            
            # 4. èåˆå¤šç§æ£€ç´¢ç»“æœ - æ”¹è¿›çš„èåˆç­–ç•¥
            weighted_similarities = {}
            for category in set(list(img_img_similarities.keys()) + 
                               list(img_text_similarities.keys()) + 
                               list(fast_scores.keys())):
                img_img_score = img_img_similarities.get(category, 0.0)
                img_text_score = img_text_similarities.get(category, 0.0)
                fast_score = fast_scores.get(category, 0.0)
                
                # æ”¹è¿›çš„åŠ æƒç­–ç•¥ï¼š
                # - å¦‚æœfastç»“æœä¸­æœ‰è¯¥ç±»åˆ«ï¼Œç»™äºˆæ›´é«˜æƒé‡
                # - å›¾åƒ-å›¾åƒå’Œå›¾åƒ-æ–‡æœ¬æ£€ç´¢å„å ä¸€å®šæƒé‡
                if category in fast_scores:
                    # fastç»“æœä¸­æœ‰ï¼šfastæƒé‡0.4, å›¾åƒ-å›¾åƒ0.35, å›¾åƒ-æ–‡æœ¬0.25
                    weighted_sim = (fast_score * 0.4 + 
                                   img_img_score * 0.35 + 
                                   img_text_score * 0.25)
                else:
                    # fastç»“æœä¸­æ²¡æœ‰ï¼šå›¾åƒ-å›¾åƒ0.55, å›¾åƒ-æ–‡æœ¬0.45
                    weighted_sim = (img_img_score * 0.55 + 
                                   img_text_score * 0.45)
                
                weighted_similarities[category] = weighted_sim
            
            # æ’åºå¹¶è¿”å›top-k
            sorted_results = sorted(weighted_similarities.items(), key=lambda x: x[1], reverse=True)
            return sorted_results[:top_k]
            
        except Exception as e:
            print(f"å¢å¼ºæ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def slow_thinking_pipeline_optimized(self, query_image_path: str, fast_result: Dict, 
                                        top_k: int = 5, save_dir: str = None) -> Dict:
        """
        ä¼˜åŒ–åçš„æ…¢æ€è€ƒæµç¨‹ - ä½¿ç”¨ç»éªŒåº“æŒ‡å¯¼MLLMæ¨ç†
        ç§»é™¤å¢å¼ºæ£€ç´¢ï¼Œç›´æ¥ä½¿ç”¨å¿«æ€è€ƒç»“æœ + ç»éªŒåº“è¿›è¡ŒMLLMæ¨ç†
        """
        print(f"å¼€å§‹ä¼˜åŒ–åçš„æ…¢æ€è€ƒæµç¨‹ï¼ŒæŸ¥è¯¢å›¾åƒ: {query_image_path}")
        
        # æ­¥éª¤1: ä»å¿«æ€è€ƒç»“æœä¸­æå–top-kå€™é€‰ç±»åˆ«
        print("æ­¥éª¤1: æå–å¿«æ€è€ƒå€™é€‰ç±»åˆ«...")
        fused_results = fast_result.get("fused_results", [])
        top_k_candidates = [cat for cat, score in fused_results]
        
        print(f"å¿«æ€è€ƒTop-{top_k}å€™é€‰ç±»åˆ«: {top_k_candidates}")
        
        # æ­¥éª¤2: æ³¨å…¥Self-Beliefç­–ç•¥ä¸Šä¸‹æ–‡
        experience_context = ""
        fused_top1_prob = float(fast_result.get("fused_top1_prob", 0.0))
        fused_margin = float(fast_result.get("fused_margin", 0.0))
        
        policy_context = self._get_self_belief_context()
        
        experience_context = policy_context
        
        # æ­¥éª¤3: ä½¿ç”¨MLLMè¿›è¡Œæœ€ç»ˆæ¨ç† - ä½¿ç”¨ç»éªŒåº“ä½œä¸ºä¸Šä¸‹æ–‡
        print("æ­¥éª¤3: ä½¿ç”¨MLLMè¿›è¡Œæœ€ç»ˆæ¨ç†ï¼ˆåŸºäºç»éªŒåº“ï¼‰...")
        result = self.reasoning_with_experience_base(
            query_image_path=query_image_path,
            fast_result=fast_result,
            top_k_candidates=top_k_candidates,
            experience_context=experience_context,
            top_k=top_k
        )
        
        # æ›´æ–°ç»Ÿè®¡
        predicted_category = result.get("predicted_category", "unknown")
        confidence = result.get("confidence", 0.0)
        # self._update_stats(predicted_category, confidence, fast_result, result, save_dir)
        
        return result
    
    def _update_stats(self, predicted_category: str, confidence: float, 
                     fast_result: Dict, slow_result: Dict, save_dir: str = None):
        """æ›´æ–°ç»Ÿè®¡é‡"""
        # è·å–å¿«æ€è€ƒç»“æœ
        fused_top1_prob = float(fast_result.get("fused_top1_prob", 0.0))
        fused_margin = float(fast_result.get("fused_margin", 0.0))
        fused_top1 = str(fast_result.get("fused_top1", "unknown"))
        fast_slow_consistent = is_similar(fused_top1, predicted_category, threshold=0.5)
        
        # è·å–LCBå€¼
        lcb_map = fast_result.get('lcb_map', {}) or {}
        lcb_value = float(lcb_map.get(predicted_category, 0.5)) if isinstance(lcb_map, dict) else 0.5
        
        # æ”¹è¿›çš„å¤šé‡ç½®ä¿¡åº¦æ£€æŸ¥ - æ›´ä¸¥æ ¼çš„æ ‡å‡†
        confidence_checks = [
            float(confidence) >= 0.85,  # æé«˜é˜ˆå€¼
            (fused_top1_prob >= 0.88 and fused_margin >= 0.18),  # æé«˜é˜ˆå€¼
            (fast_slow_consistent and lcb_value >= 0.75 and float(confidence) >= 0.75),  # æ›´ä¸¥æ ¼
            (float(confidence) >= 0.75 and lcb_value >= 0.70)  # æ›´ä¸¥æ ¼
        ]
        
        is_confident_for_stats = any(confidence_checks)
        
        # æ›´æ–°ç»Ÿè®¡
        self.fast_thinking.update_stats(predicted_category, is_confident_for_stats, used_slow_thinking=True)
        
        used_experience = slow_result.get("used_experience_base", False)
        print(f"ç»Ÿè®¡æ›´æ–°: ç±»åˆ«={predicted_category}, ç½®ä¿¡åº¦={confidence:.3f}, LCB={lcb_value:.3f}, "
              f"ä¸€è‡´æ€§={fast_slow_consistent}, ä½¿ç”¨ç»éªŒåº“={used_experience}, æ›´æ–°m={is_confident_for_stats}")


