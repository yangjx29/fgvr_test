"""
å¿«æ…¢æ€è€ƒç»†ç²’åº¦å›¾åƒè¯†åˆ«ç³»ç»Ÿ
æ•´åˆå¿«æ€è€ƒå’Œæ…¢æ€è€ƒæ¨¡å—ï¼Œå®ç°å®Œæ•´çš„FGVRæµç¨‹

åŠŸèƒ½ï¼š
1. çŸ¥è¯†åº“æ„å»ºå’Œç®¡ç†
2. å¿«æ€è€ƒæµç¨‹ï¼ˆCLIPåŒæ¨¡æ€æ£€ç´¢ï¼‰
3. æ…¢æ€è€ƒæµç¨‹ï¼ˆMLLM+CLIPæ·±åº¦åˆ†æï¼‰
4. ç»“æœèåˆå’Œè¯„ä¼°
5. æ‰¹é‡å¤„ç†æ¥å£
"""

import os
import json
import numpy as np
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm
import time
import torch
from collections import defaultdict
import threading
from datetime import datetime

from agents.mllm_bot import MLLMBot
from knowledge_base_builder import KnowledgeBaseBuilder
from experience_base_builder import ExperienceBaseBuilder
from fast_thinking import FastThinking
from fast_thinking_optimized import FastThinkingOptimized
from slow_thinking_optimized import SlowThinkingOptimized
from slow_thinking import SlowThinking
from utils.fileios import dump_json, load_json
from utils.util import is_similar


class FastSlowThinkingSystem:
    """å¿«æ…¢æ€è€ƒç»†ç²’åº¦å›¾åƒè¯†åˆ«ç³»ç»Ÿ"""
    
    def __init__(self, 
                 model_tag: str = "Qwen2.5-VL-7B",
                 model_name: str = "Qwen2.5-VL-7B",
                 image_encoder_name: str = "./models/Clip/clip-vit-base-patch32",
                 text_encoder_name: str = "./models/Clip/clip-vit-base-patch32",
                 device: str = "cuda" if torch.cuda.is_available() else "cpu",
                 cfg: Optional[Dict] = None,
                 dataset_info: Optional[Dict] = None):
        """
        åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        
        Args:
            model_tag: MLLMæ¨¡å‹æ ‡ç­¾
            model_name: MLLMæ¨¡å‹åç§°
            image_encoder_name: å›¾åƒç¼–ç å™¨åç§°
            text_encoder_name: æ–‡æœ¬ç¼–ç å™¨åç§°
            device: è®¾å¤‡
            cfg: é…ç½®å‚æ•°
        """
        self.device = device
        self.cfg = cfg or {}
        self.dataset_info = dataset_info or {}

        print("\n================= å¿«æ…¢æ€è€ƒç³»ç»Ÿåˆå§‹åŒ– =================")
        print(f"ğŸ–¥ï¸ è®¾å¤‡: {self.device}")
        print(f"ğŸ¤– MLLM æ¨¡å‹æ ‡ç­¾: {model_tag}")
        print(f"ğŸ¤– MLLM æ¨¡å‹åç§°: {model_name}")
        print(f"ğŸ–¼ï¸ å›¾åƒç¼–ç å™¨: {image_encoder_name}")
        print(f"ğŸ“„ æ–‡æœ¬ç¼–ç å™¨: {text_encoder_name}")
        print("ğŸ“š æ•°æ®é›†ä¿¡æ¯:")
        print(json.dumps(self.dataset_info, indent=4, ensure_ascii=False))
        print("====================================================\n")
        
        # åˆå§‹åŒ–MLLM
        print("ğŸš€åˆå§‹åŒ–MLLMæ¨¡å‹...")
        self.mllm_bot = MLLMBot(
            model_tag=model_tag,
            model_name=model_name,
            device=device
        )
        print(f"âœ… MLLM åˆå§‹åŒ–å®Œæˆ, å½“å‰ä½¿ç”¨ç²¾åº¦: {getattr(self.mllm_bot, 'dtype_used', 'æœªçŸ¥')}")
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨
        print("ğŸš€ åˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨...")
        self.kb_builder = KnowledgeBaseBuilder(
            image_encoder_name=image_encoder_name,
            text_encoder_name=text_encoder_name,
            device=device,
            cfg=cfg,
            dataset_info=self.dataset_info
        )
        print("âœ… çŸ¥è¯†åº“æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–å¿«æ€è€ƒæ¨¡å—
        print("ğŸš€ åˆå§‹åŒ–å¿«æ€è€ƒæ¨¡å—...")
        self.fast_thinking = FastThinkingOptimized(
            knowledge_base_builder=self.kb_builder,
            confidence_threshold=self.cfg.get('confidence_threshold', 0.8),
            similarity_threshold=self.cfg.get('similarity_threshold', 0.7),
            dataset_info=self.dataset_info
        )
        print("âœ… å¿«æ€è€ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æ…¢æ€è€ƒæ¨¡å—
        print("ğŸš€ åˆå§‹åŒ–æ…¢æ€è€ƒæ¨¡å—...")
        self.slow_thinking = SlowThinkingOptimized(
            mllm_bot=self.mllm_bot,
            knowledge_base_builder=self.kb_builder,
            fast_thinking=self.fast_thinking,
            dataset_info=self.dataset_info
        )
        print("âœ… æ…¢æ€è€ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–ç»éªŒåº“æ„å»ºå™¨ï¼ˆå¯é€‰ï¼‰
        self.exp_builder = None
        
        # å¯åŠ¨æ˜¾å­˜ç›‘æ§çº¿ç¨‹
        print("â±ï¸ å¯åŠ¨æ˜¾å­˜ç›‘æ§çº¿ç¨‹...")
        self.memory_monitor_stop = threading.Event()
        self.memory_monitor_thread = threading.Thread(
            target=self._monitor_memory,
            daemon=True
        )
        self.memory_monitor_thread.start()

        print("ğŸ‰å¿«æ…¢æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
        print("====================================================\n")
        
    def __del__(self):
        """ææ„å‡½æ•°ï¼šæ¸…ç†ç³»ç»Ÿèµ„æº"""
        self.cleanup()
        
    def _monitor_memory(self):
        """åå°çº¿ç¨‹ï¼šæ¯3ç§’è®°å½•ä¸€æ¬¡æ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
        while not self.memory_monitor_stop.is_set():
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated() / 1024**3
                memory_reserved = torch.cuda.memory_reserved() / 1024**3
                memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                memory_free = memory_total - memory_allocated
                current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[{current_time}] [æ˜¾å­˜ç›‘æ§] å·²åˆ†é…={memory_allocated:.2f}GB, å·²ä¿ç•™={memory_reserved:.2f}GB, ç©ºé—²={memory_free:.2f}GB")
            self.memory_monitor_stop.wait(3)
    
    def cleanup(self):
        """æ‰‹åŠ¨æ¸…ç†ç³»ç»Ÿèµ„æº"""
        try:
            # åœæ­¢æ˜¾å­˜ç›‘æ§çº¿ç¨‹
            if hasattr(self, 'memory_monitor_stop'):
                self.memory_monitor_stop.set()
            if hasattr(self, 'memory_monitor_thread') and self.memory_monitor_thread.is_alive():
                self.memory_monitor_thread.join(timeout=2)
            
            if hasattr(self, 'mllm_bot') and self.mllm_bot:
                self.mllm_bot.cleanup()
                del self.mllm_bot
            if hasattr(self, 'kb_builder'):
                del self.kb_builder
            if hasattr(self, 'fast_thinking'):
                del self.fast_thinking
            if hasattr(self, 'slow_thinking'):
                del self.slow_thinking
            if hasattr(self, 'exp_builder'):
                del self.exp_builder
            torch.cuda.empty_cache()
            print("FastSlowThinkingSystemèµ„æºå·²æ¸…ç†")
        except Exception as e:
            print(f"æ¸…ç†FastSlowThinkingSystemèµ„æºæ—¶å‡ºé”™: {e}")
    
    def build_knowledge_base(self, train_samples: Dict[str, List[str]], 
                           save_dir: str = "./knowledge_base",
                           augmentation: bool = True) -> Tuple[Dict, Dict]:
        """
        æ„å»ºçŸ¥è¯†åº“
        
        Args:
            train_samples: {category: [image_paths]} è®­ç»ƒæ ·æœ¬
            save_dir: çŸ¥è¯†åº“ä¿å­˜ç›®å½•
            augmentation: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
            
        Returns:
            Tuple[Dict, Dict]: (image_kb, text_kb)
        """
        print("æ„å»ºçŸ¥è¯†åº“...")
        print(f"è®­ç»ƒæ ·æœ¬åŒ…å« {len(train_samples)} ä¸ªç±»åˆ«")
        
        # æ„å»ºçŸ¥è¯†åº“
        image_kb, text_kb = self.kb_builder.build_knowledge_base(
            self.mllm_bot, train_samples, augmentation
        )
        
        # ä¿å­˜çŸ¥è¯†åº“
        self.kb_builder.save_knowledge_base(save_dir)

        self.initialize_experience_base()
        self.exp_builder.build_experience_base(train_samples,max_iterations=1, max_reflections_per_iter=3, top_k=5)
        self.exp_builder.save_experience_base(save_dir)
        # ä½¿ç”¨è®­ç»ƒé›†åˆå§‹åŒ–LCBç»Ÿè®¡å‚æ•°
        print("\nå¼€å§‹åˆå§‹åŒ–LCBç»Ÿè®¡å‚æ•°...")
        stats_summary = self.kb_builder.initialize_lcb_stats_with_labels(
            train_samples, self.fast_thinking, top_k=5
        )
        print(f"åˆå§‹åŒ–å‡†ç¡®ç‡: {stats_summary['initialization_accuracy']:.4f}")

        print("çŸ¥è¯†åº“æ„å»ºå®Œæˆ!")
        return image_kb, text_kb
    
    def load_knowledge_base(self, load_dir: str = "./knowledge_base"):
        """
        åŠ è½½çŸ¥è¯†åº“
        
        Args:
            load_dir: çŸ¥è¯†åº“åŠ è½½ç›®å½•
        """
        print(f"ä» {load_dir} åŠ è½½çŸ¥è¯†åº“...")
        self.kb_builder.load_knowledge_base(load_dir)
        print("çŸ¥è¯†åº“åŠ è½½å®Œæˆ!")
    
    def initialize_experience_base(self):
        """
        åˆå§‹åŒ–ç»éªŒåº“æ„å»ºå™¨
        """
        if self.exp_builder is None:
            print("åˆå§‹åŒ–ç»éªŒåº“æ„å»ºå™¨...")
            self.exp_builder = ExperienceBaseBuilder(
                mllm_bot=self.mllm_bot,
                knowledge_base_builder=self.kb_builder,
                fast_thinking_module=self.fast_thinking,
                slow_thinking_module=self.slow_thinking,
                device=self.device,
                dataset_info=self.dataset_info
            )
            print("ç»éªŒåº“æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆ!")
        return self.exp_builder
    
    def build_experience_base(self,
                              validation_samples: Dict[str, List[str]],
                              max_iterations: int = 3,
                              top_k: int = 5,
                              max_reflections_per_iter: int = 5,
                              min_improvement: float = 0.01,
                              max_samples_per_category: Optional[int] = None,
                              save_dir: str = "./experience_base") -> Dict:
        """
        æ„å»ºç»éªŒåº“ï¼ˆSelf-Beliefä¼˜åŒ–ï¼‰
        
        Args:
            validation_samples: {true_category: [image_paths]} éªŒè¯æ ·æœ¬
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            top_k: æ£€ç´¢top-kç»“æœ
            max_reflections_per_iter: æ¯æ¬¡è¿­ä»£æœ€å¤šåæ€çš„æ ·æœ¬æ•°
            min_improvement: æœ€å°æ€§èƒ½æå‡é˜ˆå€¼
            max_samples_per_category: æ¯ä¸ªç±»åˆ«æœ€å¤šå¤„ç†çš„æ ·æœ¬æ•°
            save_dir: ä¿å­˜ç›®å½•
            
        Returns:
            Dict: æ„å»ºç»“æœ
        """
        # åˆå§‹åŒ–ç»éªŒåº“æ„å»ºå™¨
        exp_builder = self.initialize_experience_base()
        
        # æ„å»ºç»éªŒåº“
        result = exp_builder.build_experience_base(
            validation_samples=validation_samples,
            max_iterations=max_iterations,
            top_k=top_k,
            max_reflections_per_iter=max_reflections_per_iter,
            min_improvement=min_improvement,
            max_samples_per_category=max_samples_per_category
        )
        
        # ä¿å­˜ç»éªŒåº“
        exp_builder.save_experience_base(save_dir)
        
        return result
    
    def load_experience_base(self, load_dir: str = "./experience_base"):
        """
        åŠ è½½ç»éªŒåº“
        
        Args:
            load_dir: ç»éªŒåº“åŠ è½½ç›®å½•
        """
        # åˆå§‹åŒ–ç»éªŒåº“æ„å»ºå™¨
        exp_builder = self.initialize_experience_base()
        
        # åŠ è½½ç»éªŒåº“
        exp_builder.load_experience_base(load_dir)
        
        # å°†Self-Beliefä¼ é€’ç»™æ…¢æ€è€ƒæ¨¡å—ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if hasattr(self.slow_thinking, 'set_experience_base'):
            self.slow_thinking.set_experience_base(exp_builder)
        
        print("ç»éªŒåº“åŠ è½½å®Œæˆ!")   
        
    def classify_single_image(self, query_image_path: str, 
                            use_slow_thinking: bool = None,
                            top_k: int = 5) -> Dict:
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œåˆ†ç±»
        
        Args:
            query_image_path: æŸ¥è¯¢å›¾åƒè·¯å¾„
            use_slow_thinking: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨æ…¢æ€è€ƒï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨åˆ¤æ–­ï¼‰
            top_k: æ£€ç´¢top-kç»“æœ
            
        Returns:
            Dict: åˆ†ç±»ç»“æœ
        """
        print(f"å¼€å§‹åˆ†ç±»å›¾åƒ: {query_image_path}")
        start_time = time.time()
        
        # 1. å¿«æ€è€ƒ
        print("æ‰§è¡Œå¿«æ€è€ƒ...")
        fast_result = self.fast_thinking.fast_thinking_pipeline(query_image_path, top_k)
        fast_time = time.time() - start_time
        
        result = {
            "query_image": query_image_path,
            "fast_result": fast_result,
            "fast_time": fast_time,
            "total_time": fast_time
        }
        
        # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ…¢æ€è€ƒ
        need_slow_thinking = use_slow_thinking if use_slow_thinking is not None else fast_result["need_slow_thinking"]
        
        if need_slow_thinking:
            print("å¿«æ€è€ƒç»“æœä¸ç¡®å®šï¼Œæ‰§è¡Œæ…¢æ€è€ƒ...")
            slow_start_time = time.time()
            
            # 3. æ…¢æ€è€ƒ
            slow_result = self.slow_thinking.slow_thinking_pipeline_optimized(
                query_image_path, fast_result, top_k
            )
            # slow_result = self.slow_thinking.slow_thinking_pipeline_update(
            #     query_image_path, fast_result, top_k
            # )
            slow_time = time.time() - slow_start_time
            
            # 4. æ”¹è¿›çš„æœ€ç»ˆå†³ç­–ï¼šæ™ºèƒ½èåˆå¿«æ…¢æ€è€ƒç»“æœ
            fast_pred = fast_result.get("fused_top1", fast_result.get("predicted_category", "unknown"))
            slow_pred = slow_result["predicted_category"]
            fast_conf = fast_result.get("fused_top1_prob", fast_result.get("confidence", 0.0))
            slow_conf = slow_result.get("confidence", 0.0)
            
            # æ£€æŸ¥ç»“æœä¸€è‡´æ€§
            fast_slow_consistent = is_similar(fast_pred, slow_pred, threshold=0.5)
            
            # æ”¹è¿›çš„èåˆç­–ç•¥ï¼š
            # 1. å¦‚æœç»“æœä¸€è‡´ï¼Œä¼˜å…ˆä½¿ç”¨æ…¢æ€è€ƒç»“æœï¼ˆé€šå¸¸æ›´å‡†ç¡®ï¼‰
            # 2. å¦‚æœç»“æœä¸ä¸€è‡´ï¼Œæ ¹æ®ç½®ä¿¡åº¦å’ŒLCBå€¼è¿›è¡Œå†³ç­–
            # 3. å¦‚æœæ…¢æ€è€ƒç½®ä¿¡åº¦å¾ˆé«˜ï¼Œä¼˜å…ˆä½¿ç”¨æ…¢æ€è€ƒç»“æœ
            # 4. å¦‚æœå¿«æ€è€ƒç½®ä¿¡åº¦å¾ˆé«˜ä¸”LCBå€¼å¾ˆé«˜ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å¿«æ€è€ƒç»“æœ
            if fast_slow_consistent:
                # ç»“æœä¸€è‡´ï¼Œä½¿ç”¨æ…¢æ€è€ƒç»“æœï¼ˆæ›´è¯¦ç»†çš„åˆ†æï¼‰
                final_prediction = slow_pred
                final_confidence = slow_conf
                final_reasoning = slow_result["reasoning"]
            else:
                # ç»“æœä¸ä¸€è‡´ï¼Œè¿›è¡Œæ™ºèƒ½å†³ç­–
                lcb_map = fast_result.get('lcb_map', {}) or {}
                lcb_value = float(lcb_map.get(slow_pred, lcb_map.get(fast_pred, 0.5))) if isinstance(lcb_map, dict) else 0.5
                
                # å†³ç­–è§„åˆ™ï¼š
                # 1. å¦‚æœæ…¢æ€è€ƒç½®ä¿¡åº¦å¾ˆé«˜(>=0.80)ï¼Œä¼˜å…ˆä½¿ç”¨æ…¢æ€è€ƒ
                # 2. å¦‚æœå¿«æ€è€ƒç½®ä¿¡åº¦å¾ˆé«˜(>=0.75)ä¸”LCBå€¼å¾ˆé«˜(>=0.70)ï¼Œä½¿ç”¨å¿«æ€è€ƒ
                # 3. å¦‚æœæ…¢æ€è€ƒç½®ä¿¡åº¦ä¸­ç­‰(>=0.70)ä¸”å¿«æ€è€ƒç½®ä¿¡åº¦è¾ƒä½(<0.70)ï¼Œä½¿ç”¨æ…¢æ€è€ƒ
                # 4. å…¶ä»–æƒ…å†µï¼Œä½¿ç”¨æ…¢æ€è€ƒï¼ˆæ›´è¯¦ç»†çš„åˆ†æï¼‰
                if slow_conf >= 0.80:
                    # æ…¢æ€è€ƒç½®ä¿¡åº¦å¾ˆé«˜ï¼Œä¼˜å…ˆä½¿ç”¨
                    final_prediction = slow_pred
                    final_confidence = slow_conf
                    final_reasoning = slow_result["reasoning"] + " | Fast prediction: " + fast_pred
                elif fast_conf >= 0.75 and lcb_value >= 0.70:
                    # å¿«æ€è€ƒç½®ä¿¡åº¦å¾ˆé«˜ä¸”LCBå€¼å¾ˆé«˜ï¼Œä½¿ç”¨å¿«æ€è€ƒ
                    final_prediction = fast_pred
                    final_confidence = fast_conf
                    final_reasoning = f"Fast thinking with high confidence (LCB: {lcb_value:.3f}) | Slow prediction: {slow_pred}"
                elif slow_conf >= 0.70 and fast_conf < 0.70:
                    # æ…¢æ€è€ƒç½®ä¿¡åº¦ä¸­ç­‰ä¸”å¿«æ€è€ƒç½®ä¿¡åº¦è¾ƒä½ï¼Œä½¿ç”¨æ…¢æ€è€ƒ
                    final_prediction = slow_pred
                    final_confidence = slow_conf
                    final_reasoning = slow_result["reasoning"] + " | Fast prediction: " + fast_pred
                else:
                    # å…¶ä»–æƒ…å†µï¼Œä½¿ç”¨æ…¢æ€è€ƒï¼ˆæ›´è¯¦ç»†çš„åˆ†æï¼‰
                    print("å¿«æ…¢æ€è€ƒç»“æœä¸ä¸€è‡´ï¼Œè¿›è¡Œæœ€ç»ˆèåˆå†³ç­–...")
                    final_prediction, final_confidence, final_reasoning = self._final_decision(
                        query_image_path, fast_result, slow_result, top_k
                    )
            
            result.update({
                "slow_result": slow_result,
                "slow_time": slow_time,
                "total_time": fast_time + slow_time,
                "final_prediction": final_prediction,
                "final_confidence": final_confidence,
                "final_reasoning": final_reasoning,
                "used_slow_thinking": True,
                "fast_slow_consistent": is_similar(fast_pred, slow_pred, threshold=0.5)
            })
        else:
            print("å¿«æ€è€ƒç»“æœç¡®å®šï¼Œç›´æ¥è¿”å›...")
            final_prediction = fast_result["predicted_category"]
            final_confidence = fast_result["confidence"]
            
            result.update({
                "final_prediction": final_prediction,
                "final_confidence": final_confidence,
                "final_reasoning": "Fast thinking result",
                "used_slow_thinking": False
            })
        
        total_time = time.time() - start_time
        result["total_time"] = total_time
        
        print(f"åˆ†ç±»å®Œæˆ: {final_prediction} (ç½®ä¿¡åº¦: {final_confidence:.4f})")
        print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        return result
    
    def classify_batch_images(self, query_image_paths: List[str],
                            use_slow_thinking: bool = None,
                            top_k: int = 5) -> List[Dict]:
        """
        æ‰¹é‡åˆ†ç±»å›¾åƒ
        
        Args:
            query_image_paths: æŸ¥è¯¢å›¾åƒè·¯å¾„åˆ—è¡¨
            use_slow_thinking: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨æ…¢æ€è€ƒ
            top_k: æ£€ç´¢top-kç»“æœ
            
        Returns:
            List[Dict]: æ¯ä¸ªå›¾åƒçš„åˆ†ç±»ç»“æœ
        """
        print(f"å¼€å§‹æ‰¹é‡åˆ†ç±» {len(query_image_paths)} å¼ å›¾åƒ...")
        results = []
        
        for i, img_path in enumerate(tqdm(query_image_paths, desc="åˆ†ç±»è¿›åº¦")):
            try:
                result = self.classify_single_image(img_path, use_slow_thinking, top_k)
                results.append(result)
            except Exception as e:
                print(f"åˆ†ç±»å¤±è´¥ {img_path}: {e}")
                results.append({
                    "query_image": img_path,
                    "final_prediction": "error",
                    "final_confidence": 0.0,
                    "error": str(e)
                })
        
        print("æ‰¹é‡åˆ†ç±»å®Œæˆ!")
        return results
    
    def evaluate_on_dataset(self, test_samples: Dict[str, List[str]],
                          use_slow_thinking: bool = None,
                          top_k: int = 5) -> Dict:
        """
        åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°ç³»ç»Ÿæ€§èƒ½
        
        Args:
            test_samples: {true_category: [image_paths]} æµ‹è¯•æ ·æœ¬
            use_slow_thinking: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨æ…¢æ€è€ƒ
            top_k: æ£€ç´¢top-kç»“æœ
            
        Returns:
            Dict: è¯„ä¼°ç»“æœ
        """
        print("å¼€å§‹æ•°æ®é›†è¯„ä¼°...")
        
        all_results = []
        correct_count = 0
        total_count = 0
        fast_thinking_count = 0
        slow_thinking_count = 0
        
        for true_category, image_paths in test_samples.items():
            print(f"è¯„ä¼°ç±»åˆ«: {true_category} ({len(image_paths)} å¼ å›¾åƒ)")
            
            for img_path in image_paths:
                try:
                    result = self.classify_single_image(img_path, use_slow_thinking, top_k)
                    
                    # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®
                    predicted = result["final_prediction"]
                    is_correct = is_similar(predicted, true_category, threshold=0.5)
                    
                    if is_correct:
                        correct_count += 1
                    
                    total_count += 1
                    
                    if result.get("used_slow_thinking", False):
                        slow_thinking_count += 1
                    else:
                        fast_thinking_count += 1
                    
                    result["true_category"] = true_category
                    result["is_correct"] = is_correct
                    all_results.append(result)
                    
                except Exception as e:
                    print(f"è¯„ä¼°å¤±è´¥ {img_path}: {e}")
                    total_count += 1
                    all_results.append({
                        "query_image": img_path,
                        "true_category": true_category,
                        "final_prediction": "error",
                        "is_correct": False,
                        "error": str(e)
                    })
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = correct_count / total_count if total_count > 0 else 0.0
        fast_thinking_ratio = fast_thinking_count / total_count if total_count > 0 else 0.0
        slow_thinking_ratio = slow_thinking_count / total_count if total_count > 0 else 0.0
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        total_times = [r.get("total_time", 0) for r in all_results if "total_time" in r]
        avg_time = np.mean(total_times) if total_times else 0.0
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        confidences = [r.get("final_confidence", 0) for r in all_results if "final_confidence" in r]
        avg_confidence = np.mean(confidences) if confidences else 0.0
        
        evaluation_result = {
            "accuracy": accuracy,
            "correct_count": correct_count,
            "total_count": total_count,
            "fast_thinking_count": fast_thinking_count,
            "slow_thinking_count": slow_thinking_count,
            "fast_thinking_ratio": fast_thinking_ratio,
            "slow_thinking_ratio": slow_thinking_ratio,
            "avg_time": avg_time,
            "avg_confidence": avg_confidence,
            "detailed_results": all_results
        }
        
        print("è¯„ä¼°å®Œæˆ!")
        print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"å¿«æ€è€ƒæ¯”ä¾‹: {fast_thinking_ratio:.4f}")
        print(f"æ…¢æ€è€ƒæ¯”ä¾‹: {slow_thinking_ratio:.4f}")
        print(f"å¹³å‡æ—¶é—´: {avg_time:.2f}ç§’")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f}")
        
        return evaluation_result
    
    def save_results(self, results: List[Dict], save_path: str):
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            results: ç»“æœåˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
        """
        # æ¸…ç†ç»“æœï¼Œç§»é™¤ä¸èƒ½åºåˆ—åŒ–çš„å¯¹è±¡
        cleaned_results = []
        for result in results:
            cleaned_result = {}
            for key, value in result.items():
                if isinstance(value, (str, int, float, bool, list, dict, type(None))):
                    cleaned_result[key] = value
                else:
                    cleaned_result[key] = str(value)
            cleaned_results.append(cleaned_result)
        
        dump_json(save_path, cleaned_results)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    def get_system_stats(self) -> Dict:
        """
        è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            "image_kb_size": len(self.kb_builder.image_knowledge_base),
            "text_kb_size": len(self.kb_builder.text_knowledge_base),
            "device": self.device,
            "model_tag": self.mllm_bot.model_tag if hasattr(self.mllm_bot, 'model_tag') else "unknown",
            "confidence_threshold": self.fast_thinking.confidence_threshold,
            "similarity_threshold": self.fast_thinking.similarity_threshold
        }
        return stats
    
    def _final_decision(self, query_image_path: str, fast_result: Dict, slow_result: Dict, top_k: int = 5) -> Tuple[str, float, str]:
        """
        æœ€ç»ˆå†³ç­–ï¼šå½“å¿«æ…¢æ€è€ƒç»“æœä¸ä¸€è‡´æ—¶ï¼Œè®©MLLMåŸºäºå€™é€‰ç±»åˆ«è¿›è¡Œæœ€ç»ˆé€‰æ‹©
        
        Args:
            query_image_path: æŸ¥è¯¢å›¾åƒè·¯å¾„
            fast_result: å¿«æ€è€ƒç»“æœ
            slow_result: æ…¢æ€è€ƒç»“æœ
            top_k: å€™é€‰ç±»åˆ«æ•°é‡
            
        Returns:
            Tuple[str, float, str]: (æœ€ç»ˆé¢„æµ‹ç±»åˆ«, ç½®ä¿¡åº¦, æ¨ç†è¿‡ç¨‹)
        """
        from PIL import Image
        import json
        import re
        
        image = Image.open(query_image_path).convert("RGB")
        
        # è·å–å¿«æ€è€ƒçš„å€™é€‰ç±»åˆ«ï¼ˆèåˆç»“æœï¼‰
        fast_candidates = fast_result.get("fused_results", [])[:top_k]
        fast_candidates_text = ""
        for i, (category, score) in enumerate(fast_candidates):
            fast_candidates_text += f"{i+1}. {category} (fast similarity: {score:.4f})\n"
        
        # è·å–æ…¢æ€è€ƒçš„å€™é€‰ç±»åˆ«ï¼ˆå¢å¼ºæ£€ç´¢ç»“æœï¼‰
        slow_candidates = slow_result.get("enhanced_results", [])[:top_k]
        slow_candidates_text = ""
        for i, (category, score) in enumerate(slow_candidates):
            slow_candidates_text += f"{i+1}. {category} (slow similarity: {score:.4f})\n"
        
        # è·å–æ…¢æ€è€ƒçš„ç»“æ„åŒ–æè¿°
        structured_description = slow_result.get("structured_description", "")
        
        # æ„å»ºæœ€ç»ˆå†³ç­–æç¤º
        prompt = f"""You are an expert in fine-grained visual recognition. I need you to make a final decision between two different analysis approaches.

Fast Thinking Analysis (CLIP-based retrieval):
{fast_candidates_text}

Slow Thinking Analysis (MLLM + detailed analysis):
{slow_candidates_text}

Detailed visual analysis from slow thinking:
{structured_description}

Please carefully analyze the image and consider:
1. The visual characteristics described in the detailed analysis
2. The similarity scores from both approaches
3. The consistency between fast and slow thinking results
4. Which approach provides more reliable evidence for classification

Make your final prediction in JSON format:
{{
    "predicted_category": "exact category name",
    "confidence": 0.0-1.0,
    "reasoning": "detailed explanation of your decision process",
    "chosen_approach": "fast" or "slow" or "hybrid",
    "key_evidence": "main visual evidence supporting your decision"
}}"""
        
        try:
            reply, response = self.mllm_bot.describe_attribute(image, prompt)
            if isinstance(response, list):
                response = " ".join(response)
            
            # è§£æJSONå“åº”
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    result = json.loads(json_str)
                    predicted_category = result.get("predicted_category", "unknown")
                    confidence = float(result.get("confidence", 0.5))
                    reasoning = result.get("reasoning", "No reasoning provided")
                    chosen_approach = result.get("chosen_approach", "hybrid")
                    key_evidence = result.get("key_evidence", "No evidence provided")
                    
                    # å¢å¼ºæ¨ç†ä¿¡æ¯
                    enhanced_reasoning = f"Final Decision - {chosen_approach.upper()}: {reasoning} | Key Evidence: {key_evidence}"
                    
                else:
                    # å¦‚æœæ— æ³•è§£æJSONï¼Œä½¿ç”¨æ…¢æ€è€ƒç»“æœä½œä¸ºfallback
                    predicted_category = slow_result["predicted_category"]
                    confidence = slow_result["confidence"]
                    reasoning = "JSON parsing failed, using slow thinking result as fallback"
                    enhanced_reasoning = reasoning
                    
            except (json.JSONDecodeError, ValueError):
                predicted_category = slow_result["predicted_category"]
                confidence = slow_result["confidence"]
                reasoning = "JSON parsing failed, using slow thinking result as fallback"
                enhanced_reasoning = reasoning
            
            return predicted_category, confidence, enhanced_reasoning
            
        except Exception as e:
            print(f"æœ€ç»ˆå†³ç­–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # ä½¿ç”¨æ…¢æ€è€ƒç»“æœä½œä¸ºfallbackï¼Œå¸¦é»˜è®¤å€¼
            predicted_category = slow_result.get("predicted_category", slow_result.get("category", "unknown"))
            confidence = slow_result.get("confidence", slow_result.get("similarity", 0.0))
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆå€¼ï¼Œä½¿ç”¨å¿«æ€è€ƒç»“æœ
            if not predicted_category or predicted_category == "unknown":
                if fast_result and "predicted_category" in fast_result:
                    predicted_category = fast_result["predicted_category"]
                    confidence = fast_result.get("confidence", 0.0)
                else:
                    # ä»èåˆç»“æœä¸­è·å–
                    fused_results = fast_result.get("fused_results", [])
                    if fused_results:
                        predicted_category = fused_results[0][0]
                        confidence = fused_results[0][1]
                    else:
                        predicted_category = "unknown"
                        confidence = 0.0
            
            return predicted_category, confidence, f"Final decision failed: {str(e)}"


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = FastSlowThinkingSystem(
        model_tag="Qwen2.5-VL-7B",
        model_name="Qwen2.5-VL-7B",
        device="cuda"
    )
    
    # æ„å»ºçŸ¥è¯†åº“
    train_samples = {
        "Chihuahua": ["path/to/chihuahua1.jpg", "path/to/chihuahua2.jpg"],
        "Shiba Inu": ["path/to/shiba1.jpg", "path/to/shiba2.jpg"]
    }
    
    # æ„å»ºçŸ¥è¯†åº“
    image_kb, text_kb = system.build_knowledge_base(train_samples)
    
    # æµ‹è¯•å•å¼ å›¾åƒ
    query_image = "path/to/test_image.jpg"
    result = system.classify_single_image(query_image)
    print("åˆ†ç±»ç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    # æµ‹è¯•æ‰¹é‡å›¾åƒ
    test_images = ["path/to/test1.jpg", "path/to/test2.jpg"]
    batch_results = system.classify_batch_images(test_images)
    
    # ä¿å­˜ç»“æœ
    system.save_results(batch_results, "classification_results.json")
    
    print("ç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
