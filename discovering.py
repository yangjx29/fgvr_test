import torch 
import os 
import argparse 
import json 
from tqdm import tqdm  
from termcolor import colored  
from collections import Counter 
from utils.configuration import setup_config, seed_everything 
from utils.fileios import dump_json, load_json, dump_txt  

from data import DATA_STATS, PROMPTERS, DATA_DISCOVERY  
from data.prompt_identify import prompts_howto  
from agents.vqa_bot import VQABot  
from agents.llm_bot import LLMBot 
from agents.mllm_bot import MLLMBot
from cvd.cdv_captioner import CDVCaptioner  
from retrieval.multimodal_retrieval import MultimodalRetrieval 
from fast_slow_thinking_system import FastSlowThinkingSystem
from utils.util import is_similar
import re 
import hashlib
from collections import defaultdict
import numpy as np


DEBUG = False  # è®¾ç½®è°ƒè¯•æ¨¡å¼ä¸ºå…³é—­çŠ¶æ€


def cint2cname(label: int, cname_sheet: list):
    """å°†ç±»åˆ«æ•´æ•°ç´¢å¼•è½¬æ¢ä¸ºç±»åˆ«åç§°"""
    return cname_sheet[label]


def extract_superidentify(cfg, individual_results):
    """ä»ä¸ªä½“è¯†åˆ«ç»“æœä¸­æå–è¶…ç±»è¯†åˆ«ç»“æœ"""
    words = []  # åˆå§‹åŒ–å•è¯åˆ—è¡¨
    for v in individual_results.values():  # éå†æ‰€æœ‰ä¸ªä½“è¯†åˆ«ç»“æœ
        this_word = v.split(' ')[-1]  # å–æœ€åä¸€ä¸ªå•è¯ä½œä¸ºç±»åˆ«æ ‡è¯†
        words.append(this_word.lower())  # è½¬æ¢ä¸ºå°å†™å¹¶æ·»åŠ åˆ°åˆ—è¡¨
    word_counts = Counter(words)  # ç»Ÿè®¡æ¯ä¸ªå•è¯çš„å‡ºç°æ¬¡æ•°
    # print(f"extract_superidentify ä¸­æ¯ä¸ªå•è¯å‡ºç°æ¬¡æ•°: {word_counts}")
    if cfg['dataset_name'] == 'pet':  # å¦‚æœæ˜¯å® ç‰©æ•°æ®é›†
        return [super_name for super_name, _ in word_counts.most_common(2)]  # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„2ä¸ªè¶…ç±»
    else:  # å…¶ä»–æ•°æ®é›†
        return [super_name for super_name, _ in word_counts.most_common(1)]  # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„1ä¸ªè¶…ç±»



def extract_python_list(text):
    """ä»æ–‡æœ¬ä¸­æå–Pythonåˆ—è¡¨æ ¼å¼çš„å†…å®¹"""
    pattern = r"\[(.*?)\]"  # å®šä¹‰åŒ¹é…æ–¹æ‹¬å·å†…å®¹çš„æ­£åˆ™è¡¨è¾¾å¼
    matches = re.findall(pattern, text)  # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„å†…å®¹
    return matches  # è¿”å›åŒ¹é…ç»“æœåˆ—è¡¨


def trim_result2json(raw_reply: str):
    """
    the raw_answer is a dirty output from LLM following our template.
    this function helps to extract the target JSON content contained in the
    output.
    """
    # ä»LLMçš„åŸå§‹è¾“å‡ºä¸­æå–JSONæ ¼å¼çš„å†…å®¹
    if raw_reply.find("Output JSON:") >= 0:  # å¦‚æœåŒ…å«"Output JSON:"æ ‡è®°
        answer = raw_reply.split("Output JSON:")[1].strip()  # æå–æ ‡è®°åçš„å†…å®¹
    else:  # å¦åˆ™ç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹
        answer = raw_reply.strip()  # å»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦

    if not answer.startswith('{'): answer = '{' + answer  # å¦‚æœå¼€å¤´ä¸æ˜¯{ï¼Œåˆ™æ·»åŠ 

    if not answer.endswith('}'): answer = answer + '}'  # å¦‚æœç»“å°¾ä¸æ˜¯}ï¼Œåˆ™æ·»åŠ 

    # json_answer = json.loads(answer)  # æ³¨é‡Šæ‰çš„JSONè§£æä»£ç 
    return answer  # è¿”å›å¤„ç†åçš„JSONå­—ç¬¦ä¸²


def clean_name(name: str):
    """æ¸…ç†ç±»åˆ«åç§°ï¼Œç»Ÿä¸€æ ¼å¼"""
    name = name.title() 
    name = name.replace("-", " ")  
    name = name.replace("'s", "") 
    return name  


def extract_names(gussed_names, clean=True):
    """ä»çŒœæµ‹çš„åç§°åˆ—è¡¨ä¸­æå–å’Œæ¸…ç†åç§°"""
    gussed_names = [name.strip() for name in gussed_names]
    if clean:  # å¦‚æœéœ€è¦æ¸…ç†
        gussed_names = [clean_name(name) for name in gussed_names]  
    gussed_names = list(set(gussed_names))  # å»é‡å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
    return gussed_names  # è¿”å›å¤„ç†åçš„åç§°åˆ—è¡¨


def how_to_distinguish(bot, prompt):
    """è¯¢é—®LLMå¦‚ä½•åŒºåˆ†ä¸åŒç±»åˆ«"""
    reply = bot.infer(prompt, temperature=0.1) 
    used_tokens = bot.get_used_tokens()  
    print(f"llm used_tokens: {used_tokens},")
    print(20*"=")  
    print(reply)  #
    print(20*"=") 

    return reply  

def main_identify(cfg, bot, data_disco):
    """è¯†åˆ«å›¾åƒçš„è¶…ç±»"""
    json_super_classes = {}             # img: [attr1, attr2, ..., attrN] - åˆå§‹åŒ–è¶…ç±»ç»“æœå­—å…¸

    # print(f"ç°åœ¨å¼€å§‹éå†å‘ç°é›†data_disco: {data_disco}")
    for idx, (img, label) in tqdm(enumerate(data_disco)):  # éå†å‘ç°æ•°æ®é›†ä¸­çš„å›¾åƒå’Œæ ‡ç­¾
        # prompt_identify = "Question: What is the main object in this image (choose from: Car, Flower, or Pokemon)? Answer:"
        
        prompt_identify = "Question: What is the category (car, bird, flower, dog, cat, or Pokemon) of the main object in this image? Answer:" 

        reply, trimmed_reply = bot.describe_attribute(img, prompt_identify) 
        trimmed_reply = trimmed_reply.lower()  
        json_super_classes[str(idx)] = trimmed_reply 

        # DEBUG mode - è°ƒè¯•æ¨¡å¼
        if DEBUG and idx >= 2: 
            break  
    # print(f"main_identify è¯†åˆ«ç»“æœ: {json_super_classes}")
    return json_super_classes  # è¿”å›è¶…ç±»è¯†åˆ«ç»“æœ


def main_describe(cfg, bot, data_disco, prompter, cname_sheet):
    """
    1.è°ƒç”¨VQAæ¨¡å‹ä¸ºæ¯ä¸ªå±æ€§ç”Ÿæˆå¯¹åº”çš„æè¿°
    2.ç”ŸæˆLLMpromotæè¿°
    """
    json_attrs = {}             # img: [attr1, attr2, ..., attrN] - åˆå§‹åŒ–å±æ€§ç»“æœå­—å…¸
    json_llm_prompts = {}       # img: LLM-prompt (has all attrs) - åˆå§‹åŒ–LLMæç¤ºå­—å…¸

    # è¿™é‡Œæ˜¯è®­ç»ƒé›†ï¼Œé¢„å…ˆå®šä¹‰å¥½çš„
    for idx, (img, label) in tqdm(enumerate(data_disco)): 
        if cfg['dataset_name'] == 'pet': 
            # first check what is the animal
            pet_prompt = "Questions: What is the animal in this photo (dog or car)? Answer:"
            pet_re, pet_trimmed_re = bot.describe_attribute(img, pet_prompt) 
            pet_trimmed_re = pet_trimmed_re.lower() 
            # print(pet_trimmed_re)
            if 'dog' in pet_trimmed_re:
                prompter.set_superclass('dog')
            else:
                prompter.set_superclass('cat')

        # generate attributes and per-attribute prompts for VQA bot  è·å¾—å±æ€§åˆ—è¡¨
        attrs = prompter.get_attributes()
        # ç”Ÿæˆå¯¹åº”å±æ€§çš„promotæè¿°ï¼Œè®©LLMè¿›è¡Œæè¿°
        attr_prompts = prompter.get_attribute_prompt() 
        if len(attrs) != len(attr_prompts):  # æ£€æŸ¥å±æ€§åˆ—è¡¨å’Œæç¤ºåˆ—è¡¨é•¿åº¦æ˜¯å¦ä¸€è‡´
            raise IndexError("Attribute list should have the same length as attribute prompts")

        print(f"å½“å‰idx:{idx}: label={label}")

        iname = cint2cname(label, cname_sheet)
        iname += f"_{idx}"  # å¯¹åº”ç”¨å¤šå°‘ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†
        json_attrs[iname] = []  # åˆå§‹åŒ–è¯¥å›¾åƒçš„å±æ€§åˆ—è¡¨

        # describe each attrs - æè¿°æ¯ä¸ªå±æ€§
        pair_attr_reply = []    # (attr1: prompt) - åˆå§‹åŒ–å±æ€§-å€¼å¯¹åˆ—è¡¨
        for attr, p_attr in zip(attrs, attr_prompts):  # éå†å±æ€§å’Œå¯¹åº”çš„prompt
            re_attr, trimmed_re_attr = bot.describe_attribute(img, p_attr) 
            # print(f"è°ƒç”¨bot.describe_attributeå¾—åˆ°çš„reply:{re_attr} \n tritrimmed_re_attr:{trimmed_re_attr}")
            pair_attr_reply.append([attr, trimmed_re_attr])
            json_attrs[iname].append(trimmed_re_attr)  # å°†å±æ€§å€¼æ·»åŠ åˆ°å¯¹åº”çš„ç±»åˆ«æè¿°ä¸­
        
        print(f'è·å¾—çš„VQA pair_attr_reply: {pair_attr_reply}\n json_attrs: {json_attrs}')
        # generate LLM prompt - ç”ŸæˆLLMæç¤º
        llm_prompt = prompter.get_llm_prompt(pair_attr_reply)  # æ ¹æ®å±æ€§-å€¼å¯¹ç”ŸæˆLLMæç¤º
        json_llm_prompts[iname] = llm_prompt 
        print(f'json_llm_prompts: {json_llm_prompts}')
        print(30 * '=')
        print(iname + f" with label {label}") 
        print(30 * '=')
        # print()  # æ‰“å°ç©ºè¡Œ
        # print(f"llm_prompt: {llm_prompt}")  # æ‰“å°LLMæç¤º
        # print()  # æ‰“å°ç©ºè¡Œ
        # print('END' + 30 * '=')  # æ‰“å°ç»“æŸåˆ†éš”çº¿
        # print()  # æ‰“å°ç©ºè¡Œ

        # DEBUG mode - è°ƒè¯•æ¨¡å¼
        if DEBUG and idx >= 2:  # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ä¸”å¤„ç†äº†2ä¸ªä»¥ä¸Šæ ·æœ¬
            break  # è·³å‡ºå¾ªç¯

    return json_attrs, json_llm_prompts  # è¿”å›å±æ€§ç»“æœå’ŒLLMæç¤º


def main_guess(cfg, bot, reasoning_prompts):
    """ä¸»è¦çŒœæµ‹å‡½æ•°ï¼šåŸºäºå±æ€§æè¿°æ¨ç†ç±»åˆ«åç§°"""
    prompt_list = reasoning_prompts  
    replies_raw = {}  
    replies_json_to_save = {}  

    # LLM inferring - LLMæ¨ç†
    for i, (key, prompt) in tqdm(enumerate(prompt_list.items())):  
        raw_reply = bot.infer(prompt, temperature=0.9)  # use a high temperature for better diversity
        used_tokens = bot.get_used_tokens()  # è·å–ä½¿ç”¨çš„tokenæ•°é‡

        replies_raw[key] = raw_reply  # å°†åŸå§‹å›å¤å­˜å‚¨åˆ°å­—å…¸

        print(30 * '=')  # æ‰“å°åˆ†éš”çº¿
        print(f"\t\tinferring [{i}] for {key} used tokens = {used_tokens}") 
        print(30 * '=')  
        print("Raw----")  
        print(raw_reply)  
        print()  

        jsoned_reply = trim_result2json(raw_reply=raw_reply) 

        replies_json_to_save[key] = jsoned_reply  

        print("Trimed----")  
        print(jsoned_reply)
        print()  # æ‰“å°ç©ºè¡Œ
        print('END' + 30 * '=')  
        print()  

        # DEBUG - è°ƒè¯•
        if DEBUG and i >= 2:  # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ä¸”å¤„ç†äº†2ä¸ªä»¥ä¸Šæ ·æœ¬
            break 

    print(30 * '=')  
    print(f"\t\t Finish Discovering, token consumed {bot.get_used_tokens()}"  
          f" = ${bot.get_used_tokens()*0.001*0.002}") 
    print(30 * '=')  
    print('END' + 30 * '=')  
    print()  
    return replies_raw, replies_json_to_save 


def post_process(cfg, jsoned_replies):
    """åå¤„ç†å‡½æ•°ï¼šæ¸…ç†å’Œæ•´ç†LLMæ¨ç†ç»“æœ"""
    reply_list = []  
    num_of_failures = 0  
    # duplicated dict - é‡å¤å­—å…¸
    for k, v in jsoned_replies.items():  # éå†JSONå›å¤å­—å…¸
        print(k)  
        print(v) 
        print()
        print() 
        try:  
            v_json = json.loads(v)  
            reply_list.append(v_json)
        except json.JSONDecodeError:  
            print(f"Failed to decode JSON for key: {k}") 
            num_of_failures += 1  
            continue  

        # v_json = json.loads(v) 
        # reply_list.append(v_json) 

    guessed_names = [] 
    for item in reply_list: 
        guessed_names.extend(list(item.keys()))  

    guessed_names = extract_names(guessed_names, clean=False) 

    if cfg['dataset_name'] in ['pet', 'dog']: 
        clean_gussed_names = []  
        for aitem in guessed_names:
            clean_gussed_names.extend(aitem.split(','))  
        clean_gussed_names = [name.strip() for name in clean_gussed_names]  
        guessed_names = clean_gussed_names  

    print(30 * '=') 
    print(f"\t\t Finished Post-processing")  
    print(30 * '=')  

    print(f"\t\t ---> total discovered names = {len(guessed_names)}")  
    print(guessed_names)  
    print()  
    print(f"\t\t ---> total discovered names = {len(guessed_names)}")  
    print(f"\t\t ---> number of failure entries = {num_of_failures}") 

    print('END' + 30 * '=')  
    print()  
    return guessed_names 


def load_train_samples(cfg, kshot=None):
    """åŠ è½½K-shotè®­ç»ƒæ ·æœ¬ï¼Œè¿”å› {category: [image_paths]}ã€‚
    ä¼˜å…ˆä» cfg['path_train_samples'] (JSON) è¯»å–ï¼›å¦åˆ™ä» cfg['train_root'] ç›®å½•æ‰«æã€‚
    """
    samples = {}
    if 'path_train_samples' in cfg and os.path.exists(cfg['path_train_samples']):
        try:
            samples = load_json(cfg['path_train_samples'])
        except Exception as e:
            print(f"failed to load path_train_samples: {cfg['path_train_samples']}, err={e}")
            samples = {}
    elif 'train_root' in cfg and os.path.isdir(cfg['train_root']):
        train_root = cfg['train_root']
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        for cname in sorted(os.listdir(train_root)):
            cdir = os.path.join(train_root, cname)
            if not os.path.isdir(cdir):
                continue
            imgs = []
            for fname in sorted(os.listdir(cdir)):
                fpath = os.path.join(cdir, fname)
                ext = os.path.splitext(fname)[1].lower()
                if os.path.isfile(fpath) and ext in valid_exts:
                    imgs.append(fpath)
            if imgs:
                samples[cname] = imgs
    else:
        raise FileNotFoundError("Neither cfg['path_train_samples'] nor cfg['train_root'] is valid.")

    if kshot is not None:
        trimmed = {}
        for cat, paths in samples.items():
            trimmed[cat] = paths[:kshot]
        return trimmed
    return samples


def build_gallery(cfg, mllm_bot, captioner, retrieval, kshot=5,region_num=3, superclass=None, data_discovery=None):
    """æ„å»ºå¤šæ¨¡æ€ç±»åˆ«æ¨¡æ¿åº“å¹¶ä¿å­˜åˆ°JSON(å‘é‡è½¬list)ã€‚"""

    # è¯»å–è®­ç»ƒæ ·æœ¬
    k = kshot if kshot is not None else int(str(cfg.get('k_shot', '3')))
    # train_samples = load_train_samples(cfg, kshot=k)
    train_samples = defaultdict(list)
    for name, path in data_discovery.subcat_to_sample.items():
        train_samples[name].append(path)
    print(f"loaded train samples for {len(train_samples)} classes, kshot={k}")
    print(f"train_samples: {train_samples}") 

    # æ„å»ºæ¨¡æ¿åº“
    gallery = retrieval.build_template_gallery(mllm_bot, train_samples, captioner, superclass, kshot, region_num)
    
    return gallery

if __name__ == "__main__":
    """
    CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=build_gallery --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --kshot=5 --region_num=3 --superclass=dog  --gallery_out=./experiments/dog120/gallery/dog120_gallery_concat_atten.json --fusion_method=concat 2>&1 | tee ./logs/build_gallery_dog_concat_atten.log
    """
    parser = argparse.ArgumentParser(description='Discovery', formatter_class=argparse.ArgumentDefaultsHelpFormatter) 

    parser.add_argument('--mode',  
                        type=str, 
                        default='describe', 
                        choices=['identify', 'howto', 'describe', 'guess', 'postprocess', 'build_gallery', 'build_knowledge_base', 'classify', 'evaluate', 'fastonly', 'slowonly', 'fast_slow'],  # å¯é€‰å€¼åˆ—è¡¨
                        help='operating mode for each stage')  
    parser.add_argument('--config_file_env',  
                        type=str,  
                        default='./configs/env_machine.yml',  # é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
                        help='location of host environment related config file')  
    parser.add_argument('--config_file_expt',  # æ·»åŠ å®éªŒé…ç½®æ–‡ä»¶å‚æ•°
                        type=str,  
                        default='./configs/expts/bird200_all.yml', 
                        help='location of host experiment related config file') 
    # arguments for control experiments - æ§åˆ¶å®éªŒçš„å‚æ•°
    parser.add_argument('--num_per_category',  # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡å‚æ•°
                        type=str, 
                        default='3',  
                        choices=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'random'], 
                        )
    # build_gallery ç›¸å…³
    parser.add_argument('--kshot', type=int, default=None, help='shots per class when building gallery (override cfg)')
    parser.add_argument('--region_num', type=int, default=None, help='region selelct per class when building gallery (override cfg)')
    parser.add_argument('--superclass', type=str, default=None, help='superclass for CDV prompts (override cfg)')
    parser.add_argument('--gallery_out', type=str, default=None, help='path to save built gallery json')
    parser.add_argument('--fusion_method', type=str, default='concat', help='fusion method')
    
    # å¿«æ…¢æ€è€ƒç³»ç»Ÿç›¸å…³å‚æ•°
    parser.add_argument('--knowledge_base_dir', type=str, default='./knowledge_base', help='knowledge base directory')
    parser.add_argument('--query_image', type=str, default=None, help='query image path for classification')
    parser.add_argument('--test_data_dir', type=str, default=None, help='test data directory for evaluation')
    parser.add_argument('--results_out', type=str, default='./results.json', help='output path for results')
    parser.add_argument('--use_slow_thinking', type=bool, default=None, help='force use slow thinking (None for auto)')
    parser.add_argument('--confidence_threshold', type=float, default=0.8, help='confidence threshold for fast thinking')
    parser.add_argument('--similarity_threshold', type=float, default=0.7, help='similarity threshold for trigger mechanism')
    parser.add_argument('--enable_mllm_intermediate_judge', action='store_true', default=False, help='enable MLLM intermediate judge between fast and slow thinking (for ablation studies)')

    args = parser.parse_args()  
    print(colored(args, 'blue'))  

    cfg = setup_config(args.config_file_env, args.config_file_expt)  
    print(colored(cfg, 'yellow')) 

    # drop the seed - è®¾ç½®éšæœºç§å­
    seed_everything(cfg['seed']) 

    expt_id_suffix = f"_{args.num_per_category}"  # åˆ›å»ºå®éªŒIDåç¼€

    if args.mode == 'build_knowledge_base':
        """
        æ„å»ºå¿«æ…¢æ€è€ƒç³»ç»Ÿçš„çŸ¥è¯†åº“
        CUDA_VISIBLE_DEVICES=3 python discovering.py --mode=build_knowledge_base --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --num_per_category=10 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base 2>&1 | tee ./logs/build_knowledge_base_dog120.log
        """
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½è®­ç»ƒæ ·æœ¬
        data_discovery = DATA_DISCOVERY[cfg['dataset_name']](cfg, folder_suffix=expt_id_suffix)
        train_samples = defaultdict(list)
        # {"Chihuaha": "./datasets/dogs_120/images_discovery_all_3/000.Chihuaha_000000.jpg", "Poodle": "./datasets/dogs_120/images_discovery_all_3/001.Poodle_000000.jpg", ...}
        for name, path in data_discovery.subcat_to_sample.items():
            for p in path:
                train_samples[name].append(p)
        
        print(f"æ„å»ºçŸ¥è¯†åº“ï¼ŒåŒ…å« {len(train_samples)} ä¸ªç±»åˆ«, dog datasets:{len(DATA_STATS[cfg['dataset_name']]['class_names'])}")
        
        # æ„å»ºçŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir) # æ–¹ä¾¿æ„å»ºstats
        image_kb, text_kb = system.build_knowledge_base(
            train_samples, 
            save_dir=args.knowledge_base_dir,
            augmentation=True
        )
        
        print(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œä¿å­˜åˆ°: {args.knowledge_base_dir}")
    
    elif args.mode == 'classify':
        """
        ä½¿ç”¨å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œå•å¼ å›¾åƒåˆ†ç±»
        CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --query_image=./test_image.jpg --knowledge_base_dir=/data/yjx/MLLM/Try/experiments/dog120/knowledge_base 2>&1 | tee ././logs/testfast.log
        """
        if args.query_image is None:
            raise ValueError("è¯·æä¾›æŸ¥è¯¢å›¾åƒè·¯å¾„ --query_image")
        
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)
        
        # åˆ†ç±»å›¾åƒ
        result = system.classify_single_image(
            args.query_image,
            use_slow_thinking=args.use_slow_thinking
        )
        
        # ä¿å­˜ç»“æœ
        system.save_results([result], args.results_out)
        
        print(f"åˆ†ç±»ç»“æœ: {result['final_prediction']} (ç½®ä¿¡åº¦: {result['final_confidence']:.4f})")
        print(f"ä½¿ç”¨æ…¢æ€è€ƒ: {result.get('used_slow_thinking', False)}")
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.results_out}")

    elif args.mode == 'evaluate':
        """
        åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=evaluate --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=./test_data --knowledge_base_dir=./knowledge_base_dog120 --results_out=./evaluation_results.json
        """
        if args.test_data_dir is None:
            raise ValueError("è¯·æä¾›æµ‹è¯•æ•°æ®ç›®å½• --test_data_dir")
        
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)
        
        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = defaultdict(list)
        for class_name in os.listdir(args.test_data_dir):
            class_dir = os.path.join(args.test_data_dir, class_name)
            if os.path.isdir(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                        img_path = os.path.join(class_dir, img_name)
                        test_samples[class_name].append(img_path)
        
        print(f"æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # è¯„ä¼°ç³»ç»Ÿ
        evaluation_result = system.evaluate_on_dataset(
            test_samples,
            use_slow_thinking=args.use_slow_thinking
        )
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        system.save_results([evaluation_result], args.results_out)
        
        print(f"è¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: {evaluation_result['accuracy']:.4f}")
        print(f"å¿«æ€è€ƒæ¯”ä¾‹: {evaluation_result['fast_thinking_ratio']:.4f}")
        print(f"æ…¢æ€è€ƒæ¯”ä¾‹: {evaluation_result['slow_thinking_ratio']:.4f}")
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.results_out}")
    
    elif args.mode == 'fastonly':
        """
        CUDA_VISIBLE_DEVICES=2 python discovering.py --mode=fastonly --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_10 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base --results_out=./logs/fastonly_eval.json 2>&1 | tee ./logs/fastonly_eval_lcb.log
        """

        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆä»…ç”¨äºåŠ è½½ç»„ä»¶ï¼‰ï¼Œéšååªç”¨fastæ¨¡å—
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            # print(f'cat name:{cat_name}')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            # print(f'img_path:{img_path}\tfilename:{file_names}')
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[fastonly] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        # ä»…ä½¿ç”¨å¿«æ€è€ƒè¯„ä¼°
        fast_module = system.fast_thinking
        correct = 0
        total = 0
        correct_slow_true = 0    # æ­£ç¡®ä¸”éœ€è¦ slow thinking
        correct_slow_false = 0   # æ­£ç¡®ä½†ä¸éœ€è¦ slow thinking é¢„æœŸ
        error_slow_true = 0      # é”™è¯¯ä¸”éœ€è¦ slow thinking é¢„æœŸ
        error_slow_false = 0     # é”™è¯¯ä½†ä¸éœ€è¦ slow thinking
        for true_cat, paths in test_samples.items():
            for path in paths:
                try:
                    fast_res = fast_module.fast_thinking_pipeline(path, top_k=5)
                    # ä½¿ç”¨èåˆTop-1ä½œä¸ºfast-onlyé¢„æµ‹ï¼Œå…¼å®¹æ—§é€»è¾‘å…œåº•
                    pred = fast_res.get('predicted_fast') or fast_res.get('fused_top1') or fast_res.get('predicted_category') or fast_res.get('img_category', 'unknown')
                    ok = is_similar(pred, true_cat, threshold=0.5)
                    if ok:
                        print(f"succ. pred cate:{pred}, true cate:{true_cat}, need_slow_thinking:{fast_res['need_slow_thinking']}")
                        if fast_res['need_slow_thinking']:
                            correct_slow_true+=1
                        else:
                            correct_slow_false+=1
                        correct += 1
                    else:
                        print(f"failed. pred cate:{pred}, true cate:{true_cat}, need_slow_thinking:{fast_res['need_slow_thinking']}")
                        if fast_res['need_slow_thinking']:
                            error_slow_true += 1
                        else:
                            error_slow_false += 1
                    total += 1

                except Exception as e:
                    print(f'Exception:{e}')
                    total += 1


        acc = correct / total if total > 0 else 0.0
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­éœ€è¦ slow thinking: {correct_slow_true}")
        print(f"  - å…¶ä¸­ä¸éœ€è¦ slow thinking: {correct_slow_false}")

        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"  - å…¶ä¸­éœ€è¦ slow thinking: {error_slow_true}")
        print(f"  - å…¶ä¸­ä¸éœ€è¦ slow thinking: {error_slow_false}")
        print(f"[fastonly] å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
    elif args.mode == 'slowonly':
        """
        CUDA_VISIBLE_DEVICES=3 python discovering.py --mode=slowonly --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_10 --knowledge_base_dir=/data/yjx/MLLM/Try/experiments/dog120/knowledge_base --results_out=./logs/slowonly_eval.json 2>&1 | tee ./logs/slowonly_eval.log
        """

        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆä»…ç”¨äºåŠ è½½ç»„ä»¶ï¼‰ï¼Œéšååªç”¨slowæ¨¡å—
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[slowonly] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # ä»…ä½¿ç”¨æ…¢æ€è€ƒè¯„ä¼°
        slow_module = system.slow_thinking
        fast_module = system.fast_thinking  # æ…¢æ€è€ƒéœ€è¦å¿«æ€è€ƒç»“æœä½œä¸ºè¾“å…¥
        correct = 0
        total = 0
        
        for true_cat, paths in test_samples.items():
            for path in paths:
                try:
                    # å…ˆæ‰§è¡Œå¿«æ€è€ƒè·å–ç»“æœï¼ˆæ…¢æ€è€ƒéœ€è¦è¿™ä¸ªè¾“å…¥ï¼‰
                    fast_res = fast_module.fast_thinking_pipeline(path, top_k=5)
                    
                    # æ‰§è¡Œæ…¢æ€è€ƒ
                    slow_res = slow_module.slow_thinking_pipeline(path, fast_res, top_k=5)
                     
                    # ä½¿ç”¨æ…¢æ€è€ƒçš„æœ€ç»ˆé¢„æµ‹
                    pred = slow_res.get('predicted_category', 'unknown')
                    ok = is_similar(pred, true_cat, threshold=0.5)
                    
                    if ok:
                        print(f"succ. pred cate:{pred}, true cate:{true_cat}, confidence:{slow_res.get('confidence', 0):.4f}")
                        correct += 1
                    else:
                        print(f"failed. pred cate:{pred}, true cate:{true_cat}, confidence:{slow_res.get('confidence', 0):.4f}")
                    
                    total += 1

                except Exception as e:
                    print(f'Exception:{e}')
                    total += 1

        acc = correct / total if total > 0 else 0.0
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"[slowonly] å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        
    elif args.mode == 'fast_slow':
        """
        CUDA_VISIBLE_DEVICES=2 python discovering.py --mode=fast_slow --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_1 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base --results_out=./logs/fast_and_slow_eval.json 2>&1 | tee ./logs/fast_and_slow_update_lcb_1_context256.log
        """

        # åˆå§‹åŒ–å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[fast and slow] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # ä½¿ç”¨å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿè¯„ä¼°
        correct = 0
        total = 0
        fast_only_correct = 0    # ä»…å¿«æ€è€ƒæ­£ç¡®çš„æ•°é‡
        slow_triggered = 0       # è§¦å‘æ…¢æ€è€ƒçš„æ•°é‡
        slow_triggered_correct = 0  # è§¦å‘æ…¢æ€è€ƒä¸”æ­£ç¡®çš„æ•°é‡
        
        # for true_cat, paths in test_samples.items():
        from tqdm import tqdm
        for true_cat, paths in tqdm(test_samples.items(), desc="Processing fast and slow thinking"):
            for path in paths:
                # ä½¿ç”¨å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿåˆ†ç±»
                result = system.classify_single_image(path, use_slow_thinking=None, top_k=5)
                
                pred = result.get('final_prediction', 'unknown')
                ok = is_similar(pred, true_cat, threshold=0.5)
                used_slow = result.get('used_slow_thinking', False)
                
                if ok:
                    print(f"succ. pred cate:{pred}, true cate:{true_cat}, used_slow:{used_slow}, confidence:{result.get('final_confidence', 0):.4f}")
                    correct += 1
                    if not used_slow:
                        fast_only_correct += 1
                    if used_slow:
                        slow_triggered_correct += 1
                else:
                    print(f"failed. pred cate:{pred}, true cate:{true_cat}, used_slow:{used_slow}, confidence:{result.get('final_confidence', 0):.4f}")
                    # if used_slow:
                    #     slow_triggered_correct += 1  # å³ä½¿é”™è¯¯ä¹Ÿç»Ÿè®¡
                
                if used_slow:
                    slow_triggered += 1
                
                total += 1

        acc = correct / total if total > 0 else 0.0
        fast_only_acc = fast_only_correct / (total-slow_triggered) if total > 0 else 0.0
        slow_trigger_ratio = slow_triggered / total if total > 0 else 0.0
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0
        
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[fast and slow] æ€»ä½“å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        print(f"[fast and slow] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[fast and slow] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[fast and slow] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
    
    elif args.mode == 'build_gallery':
        """
        æ„å»ºå¤šæ¨¡æ€ç±»åˆ«æ¨¡æ¿åº“
        """
        print("è¿›å…¥build_galleryæ¨¡å¼")
        try:
            from agents.mllm_bot import MLLMBot
            from cvd.cdv_captioner import CDVCaptioner
            from retrieval.multimodal_retrieval import MultimodalRetrieval
            print("æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
        except Exception as e:
            print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            raise
        
        # ä½¿ç”¨MLLMå•ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½ï¼ˆæ˜¾å­˜ä¼˜åŒ–ï¼‰
        print("è·å–MLLM Botå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰...")
        from utils.mllm_singleton import get_mllm_bot
        mllm_bot = get_mllm_bot(
            model_tag=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu'
        )
        print("MLLM Botè·å–å®Œæˆ")
        
        print("åˆå§‹åŒ–CDV Captioner...")
        captioner = CDVCaptioner()
        print("CDV Captioneråˆå§‹åŒ–å®Œæˆ")
        
        print("åˆå§‹åŒ–å¤šæ¨¡æ€æ£€ç´¢æ¨¡å—...")
        retrieval = MultimodalRetrieval(
            fusion_method=args.fusion_method,
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu'
        )
        print("å¤šæ¨¡æ€æ£€ç´¢æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        
        # åŠ è½½å‘ç°æ•°æ®é›†
        print("åŠ è½½å‘ç°æ•°æ®é›†...")
        data_discovery = DATA_DISCOVERY[cfg['dataset_name']](cfg, folder_suffix=expt_id_suffix)
        print(f"å‘ç°æ•°æ®é›†åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(data_discovery.samples)} ä¸ªæ ·æœ¬")
        
        # æ„å»ºgallery
        print("å¼€å§‹æ„å»ºgallery...")
        gallery = build_gallery(
            cfg, mllm_bot, captioner, retrieval,
            kshot=args.kshot,
            region_num=args.region_num,
            superclass=args.superclass,
            data_discovery=data_discovery
        )
        print("Galleryæ„å»ºå®Œæˆ")
        
        # ä¿å­˜gallery
        if args.gallery_out:
            import json
            import os
            os.makedirs(os.path.dirname(args.gallery_out), exist_ok=True)
            # å°†numpyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
            gallery_serializable = {}
            for cat, feat in gallery.items():
                gallery_serializable[cat] = feat.tolist()
            
            with open(args.gallery_out, 'w') as f:
                json.dump(gallery_serializable, f, indent=2)
            print(f"Gallery saved to: {args.gallery_out}")
        
        print(f"Gallery built with {len(gallery)} categories")
    
    else:
        raise NotImplementedError 

