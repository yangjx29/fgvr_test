import torch 
import os 
import argparse 
import json
import sys 
from tqdm import tqdm  
from termcolor import colored  
from collections import Counter 
from utils.configuration import setup_config, seed_everything 
from utils.fileios import dump_json, load_json, dump_txt, dump_json_override  

from data import DATA_STATS, PROMPTERS, DATA_DISCOVERY  
from data.prompt_identify import prompts_howto  
from agents.vqa_bot import VQABot  
from agents.llm_bot import LLMBot 
from agents.mllm_bot import MLLMBot
from cvd.cdv_captioner import CDVCaptioner  
from retrieval.multimodal_retrieval import MultimodalRetrieval 
from fast_slow_thinking_system import FastSlowThinkingSystem
from utils.util import is_similar
import re 
import hashlib
import time
from collections import defaultdict
import numpy as np


DEBUG = False  # è®¾ç½®è°ƒè¯•æ¨¡å¼ä¸ºå…³é—­çŠ¶æ€


def cint2cname(label: int, cname_sheet: list):
    """å°†ç±»åˆ«æ•´æ•°ç´¢å¼•è½¬æ¢ä¸ºç±»åˆ«åç§°"""
    return cname_sheet[label]


def extract_superidentify(cfg, individual_results):
    """ä»ä¸ªä½“è¯†åˆ«ç»“æœä¸­æå–è¶…ç±»è¯†åˆ«ç»“æœ"""
    words = []  # åˆå§‹åŒ–å•è¯åˆ—è¡¨
    for v in individual_results.values():  # éå†æ‰€æœ‰ä¸ªä½“è¯†åˆ«ç»“æœ
        this_word = v.split(' ')[-1]  # å–æœ€åä¸€ä¸ªå•è¯ä½œä¸ºç±»åˆ«æ ‡è¯†
        words.append(this_word.lower())  # è½¬æ¢ä¸ºå°å†™å¹¶æ·»åŠ åˆ°åˆ—è¡¨
    word_counts = Counter(words)  # ç»Ÿè®¡æ¯ä¸ªå•è¯çš„å‡ºç°æ¬¡æ•°
    # print(f"extract_superidentify ä¸­æ¯ä¸ªå•è¯å‡ºç°æ¬¡æ•°: {word_counts}")
    if cfg['dataset_name'] == 'pet':  # å¦‚æœæ˜¯å® ç‰©æ•°æ®é›†
        return [super_name for super_name, _ in word_counts.most_common(2)]  # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„2ä¸ªè¶…ç±»
    else:  # å…¶ä»–æ•°æ®é›†
        return [super_name for super_name, _ in word_counts.most_common(1)]  # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„1ä¸ªè¶…ç±»


def get_dataset_mapping():
    """è·å–æ•°æ®é›†åç§°æ˜ å°„å’Œå¯¹åº”çš„å®éªŒç›®å½•å"""
    return {
        'pet': {'dataset_dir': 'pet_37', 'exp_dir': 'pet37'},
        'dog': {'dataset_dir': 'dogs_120', 'exp_dir': 'dog120'}, 
        'flower': {'dataset_dir': 'flowers_102', 'exp_dir': 'flower102'},
        'car': {'dataset_dir': 'car_196', 'exp_dir': 'car196'},
        'bird': {'dataset_dir': 'CUB_200_2011', 'exp_dir': 'bird200'}
    }


def load_category_image_paths(dataset_name):
    """
    ä»çŸ¥è¯†åº“åŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„
    
    Args:
        dataset_name: æ•°æ®é›†åç§° (pet, dog, flower, car, bird)
        
    Returns:
        dict: {category: [image_paths]} æˆ– {} å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨
    """
    dataset_mapping = get_dataset_mapping()
    
    if dataset_name not in dataset_mapping:
        print(f"è­¦å‘Š: ä¸æ”¯æŒçš„æ•°æ®é›† {dataset_name}")
        return {}
    
    exp_dir = dataset_mapping[dataset_name]['exp_dir']
    category_paths_file = f"./experiments/{exp_dir}/knowledge_base/category_image_paths.json"
    
    if os.path.exists(category_paths_file):
        try:
            category_paths = load_json(category_paths_file)
            print(f"âœ… ä»çŸ¥è¯†åº“åŠ è½½äº† {len(category_paths)} ä¸ªç±»åˆ«çš„å›¾åƒè·¯å¾„: {category_paths_file}")
            return category_paths
        except Exception as e:
            print(f"âŒ åŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„å¤±è´¥ {category_paths_file}: {e}")
            return {}
    else:
        print(f"âš ï¸  ç±»åˆ«å›¾åƒè·¯å¾„æ–‡ä»¶ä¸å­˜åœ¨: {category_paths_file}")
        return {}


def get_category_image_from_paths(category, category_paths, max_images=1):
    """
    ä»ç±»åˆ«å›¾åƒè·¯å¾„ä¸­è·å–æŒ‡å®šæ•°é‡çš„å›¾åƒ
    
    Args:
        category: ç±»åˆ«åç§°
        category_paths: ç±»åˆ«å›¾åƒè·¯å¾„å­—å…¸
        max_images: æœ€å¤§å›¾åƒæ•°é‡
        
    Returns:
        list: å›¾åƒè·¯å¾„åˆ—è¡¨
    """
    if category not in category_paths:
        return []
    
    paths = category_paths[category]
    # è¿”å›æŒ‡å®šæ•°é‡çš„å›¾åƒï¼Œå¦‚æœä¸å¤Ÿåˆ™è¿”å›æ‰€æœ‰
    return paths[:max_images] if len(paths) >= max_images else paths



def extract_python_list(text):
    """ä»æ–‡æœ¬ä¸­æå–Pythonåˆ—è¡¨æ ¼å¼çš„å†…å®¹"""
    pattern = r"\[(.*?)\]"  # å®šä¹‰åŒ¹é…æ–¹æ‹¬å·å†…å®¹çš„æ­£åˆ™è¡¨è¾¾å¼
    matches = re.findall(pattern, text)  # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„å†…å®¹
    return matches  # è¿”å›åŒ¹é…ç»“æœåˆ—è¡¨


def trim_result2json(raw_reply: str):
    """
    the raw_answer is a dirty output from LLM following our template.
    this function helps to extract the target JSON content contained in the
    output.
    """
    # ä»LLMçš„åŸå§‹è¾“å‡ºä¸­æå–JSONæ ¼å¼çš„å†…å®¹
    if raw_reply.find("Output JSON:") >= 0:  # å¦‚æœåŒ…å«"Output JSON:"æ ‡è®°
        answer = raw_reply.split("Output JSON:")[1].strip()  # æå–æ ‡è®°åçš„å†…å®¹
    else:  # å¦åˆ™ç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹
        answer = raw_reply.strip()  # å»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦

    if not answer.startswith('{'): answer = '{' + answer  # å¦‚æœå¼€å¤´ä¸æ˜¯{ï¼Œåˆ™æ·»åŠ 

    if not answer.endswith('}'): answer = answer + '}'  # å¦‚æœç»“å°¾ä¸æ˜¯}ï¼Œåˆ™æ·»åŠ 

    # json_answer = json.loads(answer)  # æ³¨é‡Šæ‰çš„JSONè§£æä»£ç 
    return answer  # è¿”å›å¤„ç†åçš„JSONå­—ç¬¦ä¸²


def clean_name(name: str):
    """æ¸…ç†ç±»åˆ«åç§°ï¼Œç»Ÿä¸€æ ¼å¼"""
    name = name.title() 
    name = name.replace("-", " ")  
    name = name.replace("'s", "") 
    return name  


def extract_names(gussed_names, clean=True):
    """ä»çŒœæµ‹çš„åç§°åˆ—è¡¨ä¸­æå–å’Œæ¸…ç†åç§°"""
    gussed_names = [name.strip() for name in gussed_names]
    if clean:  # å¦‚æœéœ€è¦æ¸…ç†
        gussed_names = [clean_name(name) for name in gussed_names]  
    gussed_names = list(set(gussed_names))  # å»é‡å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
    return gussed_names  # è¿”å›å¤„ç†åçš„åç§°åˆ—è¡¨


def how_to_distinguish(bot, prompt):
    """è¯¢é—®LLMå¦‚ä½•åŒºåˆ†ä¸åŒç±»åˆ«"""
    reply = bot.infer(prompt, temperature=0.1) 
    used_tokens = bot.get_used_tokens()  
    print(f"llm used_tokens: {used_tokens},")
    print(20*"=")  
    print(reply)  #
    print(20*"=") 

    return reply  

def main_identify(cfg, bot, data_disco):
    """è¯†åˆ«å›¾åƒçš„è¶…ç±»"""
    json_super_classes = {}             # img: [attr1, attr2, ..., attrN] - åˆå§‹åŒ–è¶…ç±»ç»“æœå­—å…¸

    # print(f"ç°åœ¨å¼€å§‹éå†å‘ç°é›†data_disco: {data_disco}")
    for idx, (img, label) in tqdm(enumerate(data_disco)):  # éå†å‘ç°æ•°æ®é›†ä¸­çš„å›¾åƒå’Œæ ‡ç­¾
        # prompt_identify = "Question: What is the main object in this image (choose from: Car, Flower, or Pokemon)? Answer:"
        
        prompt_identify = "Question: What is the category (car, bird, flower, dog, cat, or Pokemon) of the main object in this image? Answer:" 

        reply, trimmed_reply = bot.describe_attribute(img, prompt_identify) 
        trimmed_reply = trimmed_reply.lower()  
        json_super_classes[str(idx)] = trimmed_reply 

        # DEBUG mode - è°ƒè¯•æ¨¡å¼
        if DEBUG and idx >= 2: 
            break  
    # print(f"main_identify è¯†åˆ«ç»“æœ: {json_super_classes}")
    return json_super_classes  # è¿”å›è¶…ç±»è¯†åˆ«ç»“æœ


def main_describe(cfg, bot, data_disco, prompter, cname_sheet):
    """
    1.è°ƒç”¨VQAæ¨¡å‹ä¸ºæ¯ä¸ªå±æ€§ç”Ÿæˆå¯¹åº”çš„æè¿°
    2.ç”ŸæˆLLMpromotæè¿°
    """
    json_attrs = {}             # img: [attr1, attr2, ..., attrN] - åˆå§‹åŒ–å±æ€§ç»“æœå­—å…¸
    json_llm_prompts = {}       # img: LLM-prompt (has all attrs) - åˆå§‹åŒ–LLMæç¤ºå­—å…¸

    # è¿™é‡Œæ˜¯è®­ç»ƒé›†ï¼Œé¢„å…ˆå®šä¹‰å¥½çš„
    for idx, (img, label) in tqdm(enumerate(data_disco)): 
        if cfg['dataset_name'] == 'pet': 
            # first check what is the animal
            pet_prompt = "Questions: What is the animal in this photo (dog or car)? Answer:"
            pet_re, pet_trimmed_re = bot.describe_attribute(img, pet_prompt) 
            pet_trimmed_re = pet_trimmed_re.lower() 
            # print(pet_trimmed_re)
            if 'dog' in pet_trimmed_re:
                prompter.set_superclass('dog')
            else:
                prompter.set_superclass('cat')

        # generate attributes and per-attribute prompts for VQA bot  è·å¾—å±æ€§åˆ—è¡¨
        attrs = prompter.get_attributes()
        # ç”Ÿæˆå¯¹åº”å±æ€§çš„promotæè¿°ï¼Œè®©LLMè¿›è¡Œæè¿°
        attr_prompts = prompter.get_attribute_prompt() 
        if len(attrs) != len(attr_prompts):  # æ£€æŸ¥å±æ€§åˆ—è¡¨å’Œæç¤ºåˆ—è¡¨é•¿åº¦æ˜¯å¦ä¸€è‡´
            raise IndexError("Attribute list should have the same length as attribute prompts")

        print(f"å½“å‰idx:{idx}: label={label}")

        iname = cint2cname(label, cname_sheet)
        iname += f"_{idx}"  # å¯¹åº”ç”¨å¤šå°‘ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†
        json_attrs[iname] = []  # åˆå§‹åŒ–è¯¥å›¾åƒçš„å±æ€§åˆ—è¡¨

        # describe each attrs - æè¿°æ¯ä¸ªå±æ€§
        pair_attr_reply = []    # (attr1: prompt) - åˆå§‹åŒ–å±æ€§-å€¼å¯¹åˆ—è¡¨
        for attr, p_attr in zip(attrs, attr_prompts):  # éå†å±æ€§å’Œå¯¹åº”çš„prompt
            re_attr, trimmed_re_attr = bot.describe_attribute(img, p_attr) 
            # print(f"è°ƒç”¨bot.describe_attributeå¾—åˆ°çš„reply:{re_attr} \n tritrimmed_re_attr:{trimmed_re_attr}")
            pair_attr_reply.append([attr, trimmed_re_attr])
            json_attrs[iname].append(trimmed_re_attr)  # å°†å±æ€§å€¼æ·»åŠ åˆ°å¯¹åº”çš„ç±»åˆ«æè¿°ä¸­
        
        print(f'è·å¾—çš„VQA pair_attr_reply: {pair_attr_reply}\n json_attrs: {json_attrs}')
        # generate LLM prompt - ç”ŸæˆLLMæç¤º
        llm_prompt = prompter.get_llm_prompt(pair_attr_reply)  # æ ¹æ®å±æ€§-å€¼å¯¹ç”ŸæˆLLMæç¤º
        json_llm_prompts[iname] = llm_prompt 
        print(f'json_llm_prompts: {json_llm_prompts}')
        print(30 * '=')
        print(iname + f" with label {label}") 
        print(30 * '=')
        # print()  # æ‰“å°ç©ºè¡Œ
        # print(f"llm_prompt: {llm_prompt}")  # æ‰“å°LLMæç¤º
        # print()  # æ‰“å°ç©ºè¡Œ
        # print('END' + 30 * '=')  # æ‰“å°ç»“æŸåˆ†éš”çº¿
        # print()  # æ‰“å°ç©ºè¡Œ

        # DEBUG mode - è°ƒè¯•æ¨¡å¼
        if DEBUG and idx >= 2:  # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ä¸”å¤„ç†äº†2ä¸ªä»¥ä¸Šæ ·æœ¬
            break  # è·³å‡ºå¾ªç¯

    return json_attrs, json_llm_prompts  # è¿”å›å±æ€§ç»“æœå’ŒLLMæç¤º


def main_guess(cfg, bot, reasoning_prompts):
    """ä¸»è¦çŒœæµ‹å‡½æ•°ï¼šåŸºäºå±æ€§æè¿°æ¨ç†ç±»åˆ«åç§°"""
    prompt_list = reasoning_prompts  
    replies_raw = {}  
    replies_json_to_save = {}  

    # LLM inferring - LLMæ¨ç†
    for i, (key, prompt) in tqdm(enumerate(prompt_list.items())):  
        raw_reply = bot.infer(prompt, temperature=0.9)  # use a high temperature for better diversity
        used_tokens = bot.get_used_tokens()  # è·å–ä½¿ç”¨çš„tokenæ•°é‡

        replies_raw[key] = raw_reply  # å°†åŸå§‹å›å¤å­˜å‚¨åˆ°å­—å…¸

        print(30 * '=')  # æ‰“å°åˆ†éš”çº¿
        print(f"\t\tinferring [{i}] for {key} used tokens = {used_tokens}") 
        print(30 * '=')  
        print("Raw----")  
        print(raw_reply)  
        print()  

        jsoned_reply = trim_result2json(raw_reply=raw_reply) 

        replies_json_to_save[key] = jsoned_reply  

        print("Trimed----")  
        print(jsoned_reply)
        print()  # æ‰“å°ç©ºè¡Œ
        print('END' + 30 * '=')  
        print()  

        # DEBUG - è°ƒè¯•
        if DEBUG and i >= 2:  # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ä¸”å¤„ç†äº†2ä¸ªä»¥ä¸Šæ ·æœ¬
            break 

    print(30 * '=')  
    print(f"\t\t Finish Discovering, token consumed {bot.get_used_tokens()}"  
          f" = ${bot.get_used_tokens()*0.001*0.002}") 
    print(30 * '=')  
    print('END' + 30 * '=')  
    print()  
    return replies_raw, replies_json_to_save 


def post_process(cfg, jsoned_replies):
    """åå¤„ç†å‡½æ•°ï¼šæ¸…ç†å’Œæ•´ç†LLMæ¨ç†ç»“æœ"""
    reply_list = []  
    num_of_failures = 0  
    # duplicated dict - é‡å¤å­—å…¸
    for k, v in jsoned_replies.items():  # éå†JSONå›å¤å­—å…¸
        print(k)  
        print(v) 
        print()
        print() 
        try:  
            v_json = json.loads(v)  
            reply_list.append(v_json)
        except json.JSONDecodeError:  
            print(f"Failed to decode JSON for key: {k}") 
            num_of_failures += 1  
            continue  

        # v_json = json.loads(v) 
        # reply_list.append(v_json) 

    guessed_names = [] 
    for item in reply_list: 
        guessed_names.extend(list(item.keys()))  

    guessed_names = extract_names(guessed_names, clean=False) 

    if cfg['dataset_name'] in ['pet', 'dog']: 
        clean_gussed_names = []  
        for aitem in guessed_names:
            clean_gussed_names.extend(aitem.split(','))  
        clean_gussed_names = [name.strip() for name in clean_gussed_names]  
        guessed_names = clean_gussed_names  

    print(30 * '=') 
    print(f"\t\t Finished Post-processing")  
    print(30 * '=')  

    print(f"\t\t ---> total discovered names = {len(guessed_names)}")  
    print(guessed_names)  
    print()  
    print(f"\t\t ---> total discovered names = {len(guessed_names)}")  
    print(f"\t\t ---> number of failure entries = {num_of_failures}") 

    print('END' + 30 * '=')  
    print()  
    return guessed_names 


def load_train_samples(cfg, kshot=None):
    """åŠ è½½K-shotè®­ç»ƒæ ·æœ¬ï¼Œè¿”å› {category: [image_paths]}ã€‚
    ä¼˜å…ˆä» cfg['path_train_samples'] (JSON) è¯»å–ï¼›å¦åˆ™ä» cfg['train_root'] ç›®å½•æ‰«æã€‚
    """
    samples = {}
    if 'path_train_samples' in cfg and os.path.exists(cfg['path_train_samples']):
        try:
            samples = load_json(cfg['path_train_samples'])
        except Exception as e:
            print(f"failed to load path_train_samples: {cfg['path_train_samples']}, err={e}")
            samples = {}
    elif 'train_root' in cfg and os.path.isdir(cfg['train_root']):
        train_root = cfg['train_root']
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        for cname in sorted(os.listdir(train_root)):
            cdir = os.path.join(train_root, cname)
            if not os.path.isdir(cdir):
                continue
            imgs = []
            for fname in sorted(os.listdir(cdir)):
                fpath = os.path.join(cdir, fname)
                ext = os.path.splitext(fname)[1].lower()
                if os.path.isfile(fpath) and ext in valid_exts:
                    imgs.append(fpath)
            if imgs:
                samples[cname] = imgs
    else:
        raise FileNotFoundError("Neither cfg['path_train_samples'] nor cfg['train_root'] is valid.")

    if kshot is not None:
        trimmed = {}
        for cat, paths in samples.items():
            trimmed[cat] = paths[:kshot]
        return trimmed
    return samples



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Discovery', formatter_class=argparse.ArgumentDefaultsHelpFormatter) 

    parser.add_argument('--mode',  
                        type=str, 
                        default='describe', 
                        choices=['identify', 'howto', 'describe', 'guess', 'postprocess', 'build_knowledge_base', 'classify', 'evaluate', 'fastonly', 'slowonly', 'fast_slow', 'fast_slow_infer', 'fast_slow_classify', 'fast_classify', 'slow_classify', 'terminal_decision', 'fast_classify_enhanced', 'slow_classify_enhanced', 'terminal_decision_enhanced'],  # å¯é€‰å€¼åˆ—è¡¨
                        help='operating mode for each stage')  
    parser.add_argument('--config_file_env',  
                        type=str,  
                        default='./configs/env_machine.yml',  # é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
                        help='location of host environment related config file')  
    parser.add_argument('--config_file_expt',  # æ·»åŠ å®éªŒé…ç½®æ–‡ä»¶å‚æ•°
                        type=str,  
                        default='./configs/expts/bird200_all.yml', 
                        help='location of host experiment related config file') 
    # arguments for control experiments - æ§åˆ¶å®éªŒçš„å‚æ•°
    parser.add_argument('--num_per_category',  # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡å‚æ•°
                        type=str, 
                        default='3',  
                        choices=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'random'], 
                        )
    
    # å¿«æ…¢æ€è€ƒç³»ç»Ÿç›¸å…³å‚æ•°
    parser.add_argument('--knowledge_base_dir', type=str, default='./knowledge_base', help='knowledge base directory')
    parser.add_argument('--query_image', type=str, default=None, help='query image path for classification')
    parser.add_argument('--test_data_dir', type=str, default=None, help='test data directory for evaluation')
    parser.add_argument('--results_out', type=str, default='./results.json', help='output path for results')
    parser.add_argument('--use_slow_thinking', type=bool, default=None, help='force use slow thinking (None for auto)')
    parser.add_argument('--confidence_threshold', type=float, default=0.8, help='confidence threshold for fast thinking')
    parser.add_argument('--similarity_threshold', type=float, default=0.7, help='similarity threshold for trigger mechanism')
    parser.add_argument('--enable_mllm_intermediate_judge', action='store_true', default=False, help='enable MLLM intermediate judge between fast and slow thinking (for ablation studies)')
    
    # å¿«æ…¢æ€è€ƒæ¨ç†ä¸åˆ†ç±»åˆ†ç¦»ç›¸å…³å‚æ•°
    parser.add_argument('--infer_dir', type=str, default=None, help='directory to save inference results (for fast_slow_infer mode)')
    parser.add_argument('--classify_dir', type=str, default=None, help='directory to save classification results (for fast_slow_classify mode)')

    args = parser.parse_args()  
    print(colored(args, 'blue'))  

    cfg = setup_config(args.config_file_env, args.config_file_expt)  
    print(colored(cfg, 'yellow')) 

    # drop the seed - è®¾ç½®éšæœºç§å­
    seed_everything(cfg['seed']) 

    expt_id_suffix = f"_{args.num_per_category}"  # åˆ›å»ºå®éªŒIDåç¼€

    import time
    start_time = time.time()

    if args.mode == 'build_knowledge_base':
        """
        æ„å»ºå¿«æ…¢æ€è€ƒç³»ç»Ÿçš„çŸ¥è¯†åº“
        CUDA_VISIBLE_DEVICES=3 python discovering.py --mode=build_knowledge_base --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --num_per_category=10 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base 2>&1 | tee ./logs/build_knowledge_base_dog120.log
        """
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½è®­ç»ƒæ ·æœ¬
        data_discovery = DATA_DISCOVERY[cfg['dataset_name']](cfg, folder_suffix=expt_id_suffix)
        train_samples = defaultdict(list)
        # {"Chihuaha": "./datasets/dogs_120/images_discovery_all_3/000.Chihuaha_000000.jpg", "Poodle": "./datasets/dogs_120/images_discovery_all_3/001.Poodle_000000.jpg", ...}
        for name, path in data_discovery.subcat_to_sample.items():
            for p in path:
                train_samples[name].append(p)
        
        print(f"æ„å»ºçŸ¥è¯†åº“ï¼ŒåŒ…å« {len(train_samples)} ä¸ªç±»åˆ«, dog datasets:{len(DATA_STATS[cfg['dataset_name']]['class_names'])}")
        
        # æ„å»ºçŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir) # æ–¹ä¾¿æ„å»ºstats
        image_kb, text_kb = system.build_knowledge_base(
            train_samples, 
            save_dir=args.knowledge_base_dir,
            augmentation=True
        )
        
        # ä¿å­˜æ¯ä¸ªç±»åˆ«çš„å›¾åƒè·¯å¾„åˆ°JSONæ–‡ä»¶
        category_images_path_file = os.path.join(args.knowledge_base_dir, "category_image_paths.json")
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®ï¼š{category: [image_paths]}
        category_paths_data = {}
        for category, paths in train_samples.items():
            category_paths_data[category] = paths
        
        # ä½¿ç”¨dump_json_overrideç¡®ä¿æ–‡ä»¶ä¿å­˜æˆåŠŸ
        try:
            dump_json_override(category_images_path_file, category_paths_data)
            print(f"ç±»åˆ«å›¾åƒè·¯å¾„å·²ä¿å­˜åˆ°: {category_images_path_file}")
            print(f"ä¿å­˜äº† {len(category_paths_data)} ä¸ªç±»åˆ«çš„å›¾åƒè·¯å¾„")
        except Exception as e:
            print(f"ä¿å­˜ç±»åˆ«å›¾åƒè·¯å¾„å¤±è´¥: {e}")
            # å°è¯•åˆ›å»ºçŸ¥è¯†åº“ç›®å½•å¹¶é‡æ–°ä¿å­˜
            try:
                os.makedirs(args.knowledge_base_dir, exist_ok=True)
                dump_json_override(category_images_path_file, category_paths_data)
                print(f"é‡è¯•æˆåŠŸï¼Œç±»åˆ«å›¾åƒè·¯å¾„å·²ä¿å­˜åˆ°: {category_images_path_file}")
            except Exception as e2:
                print(f"é‡è¯•ä¿å­˜ç±»åˆ«å›¾åƒè·¯å¾„ä»ç„¶å¤±è´¥: {e2}")
        
        print(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œä¿å­˜åˆ°: {args.knowledge_base_dir}")
    
    elif args.mode == 'classify':
        """
        ä½¿ç”¨å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œå•å¼ å›¾åƒåˆ†ç±»
        CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --query_image=./test_image.jpg --knowledge_base_dir=/data/yjx/MLLM/Try/experiments/dog120/knowledge_base 2>&1 | tee ././logs/testfast.log
        """
        if args.query_image is None:
            raise ValueError("è¯·æä¾›æŸ¥è¯¢å›¾åƒè·¯å¾„ --query_image")
        
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)
        
        # åˆ†ç±»å›¾åƒ
        result = system.classify_single_image(
            args.query_image,
            use_slow_thinking=args.use_slow_thinking
        )
        
        # ä¿å­˜ç»“æœ
        system.save_results([result], args.results_out)
        
        print(f"åˆ†ç±»ç»“æœ: {result['final_prediction']} (ç½®ä¿¡åº¦: {result['final_confidence']:.4f})")
        print(f"ä½¿ç”¨æ…¢æ€è€ƒ: {result.get('used_slow_thinking', False)}")
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.results_out}")

    elif args.mode == 'evaluate':
        """
        åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=evaluate --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=./test_data --knowledge_base_dir=./knowledge_base_dog120 --results_out=./evaluation_results.json
        """
        if args.test_data_dir is None:
            raise ValueError("è¯·æä¾›æµ‹è¯•æ•°æ®ç›®å½• --test_data_dir")
        
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)
        
        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = defaultdict(list)
        for class_name in os.listdir(args.test_data_dir):
            class_dir = os.path.join(args.test_data_dir, class_name)
            if os.path.isdir(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                        img_path = os.path.join(class_dir, img_name)
                        test_samples[class_name].append(img_path)
        
        print(f"æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # è¯„ä¼°ç³»ç»Ÿ
        evaluation_result = system.evaluate_on_dataset(
            test_samples,
            use_slow_thinking=args.use_slow_thinking
        )
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        system.save_results([evaluation_result], args.results_out)
        
        print(f"è¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: {evaluation_result['accuracy']:.4f}")
        print(f"å¿«æ€è€ƒæ¯”ä¾‹: {evaluation_result['fast_thinking_ratio']:.4f}")
        print(f"æ…¢æ€è€ƒæ¯”ä¾‹: {evaluation_result['slow_thinking_ratio']:.4f}")
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.results_out}")
    
    elif args.mode == 'fastonly':
        """
        CUDA_VISIBLE_DEVICES=2 python discovering.py --mode=fastonly --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_10 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base --results_out=./logs/fastonly_eval.json 2>&1 | tee ./logs/fastonly_eval_lcb.log
        """

        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆä»…ç”¨äºåŠ è½½ç»„ä»¶ï¼‰ï¼Œéšååªç”¨fastæ¨¡å—
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            # print(f'cat name:{cat_name}')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            # print(f'img_path:{img_path}\tfilename:{file_names}')
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[fastonly] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        # ä»…ä½¿ç”¨å¿«æ€è€ƒè¯„ä¼°
        fast_module = system.fast_thinking
        correct = 0
        total = 0
        correct_slow_true = 0    # æ­£ç¡®ä¸”éœ€è¦ slow thinking
        correct_slow_false = 0   # æ­£ç¡®ä½†ä¸éœ€è¦ slow thinking é¢„æœŸ
        error_slow_true = 0      # é”™è¯¯ä¸”éœ€è¦ slow thinking é¢„æœŸ
        error_slow_false = 0     # é”™è¯¯ä½†ä¸éœ€è¦ slow thinking
        for true_cat, paths in test_samples.items():
            for path in paths:
                try:
                    fast_res = fast_module.fast_thinking_pipeline(path, top_k=5)
                    # ä½¿ç”¨èåˆTop-1ä½œä¸ºfast-onlyé¢„æµ‹ï¼Œå…¼å®¹æ—§é€»è¾‘å…œåº•
                    pred = fast_res.get('predicted_fast') or fast_res.get('fused_top1') or fast_res.get('predicted_category') or fast_res.get('img_category', 'unknown')
                    ok = is_similar(pred, true_cat, threshold=0.5)
                    if ok:
                        print(f"succ. pred cate:{pred}, true cate:{true_cat}, need_slow_thinking:{fast_res['need_slow_thinking']}")
                        if fast_res['need_slow_thinking']:
                            correct_slow_true+=1
                        else:
                            correct_slow_false+=1
                        correct += 1
                    else:
                        print(f"failed. pred cate:{pred}, true cate:{true_cat}, need_slow_thinking:{fast_res['need_slow_thinking']}")
                        if fast_res['need_slow_thinking']:
                            error_slow_true += 1
                        else:
                            error_slow_false += 1
                    total += 1

                except Exception as e:
                    print(f'Exception:{e}')
                    total += 1


        acc = correct / total if total > 0 else 0.0
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­éœ€è¦ slow thinking: {correct_slow_true}")
        print(f"  - å…¶ä¸­ä¸éœ€è¦ slow thinking: {correct_slow_false}")

        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"  - å…¶ä¸­éœ€è¦ slow thinking: {error_slow_true}")
        print(f"  - å…¶ä¸­ä¸éœ€è¦ slow thinking: {error_slow_false}")
        print(f"[fastonly] å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
    elif args.mode == 'slowonly':
        """
        CUDA_VISIBLE_DEVICES=3 python discovering.py --mode=slowonly --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_10 --knowledge_base_dir=/data/yjx/MLLM/Try/experiments/dog120/knowledge_base --results_out=./logs/slowonly_eval.json 2>&1 | tee ./logs/slowonly_eval.log
        """

        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆä»…ç”¨äºåŠ è½½ç»„ä»¶ï¼‰ï¼Œéšååªç”¨slowæ¨¡å—
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[slowonly] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # ä»…ä½¿ç”¨æ…¢æ€è€ƒè¯„ä¼°
        slow_module = system.slow_thinking
        fast_module = system.fast_thinking  # æ…¢æ€è€ƒéœ€è¦å¿«æ€è€ƒç»“æœä½œä¸ºè¾“å…¥
        correct = 0
        total = 0
        
        for true_cat, paths in test_samples.items():
            for path in paths:
                try:
                    # å…ˆæ‰§è¡Œå¿«æ€è€ƒè·å–ç»“æœï¼ˆæ…¢æ€è€ƒéœ€è¦è¿™ä¸ªè¾“å…¥ï¼‰
                    fast_res = fast_module.fast_thinking_pipeline(path, top_k=5)
                    
                    # æ‰§è¡Œæ…¢æ€è€ƒ
                    slow_res = slow_module.slow_thinking_pipeline(path, fast_res, top_k=5)
                     
                    # ä½¿ç”¨æ…¢æ€è€ƒçš„æœ€ç»ˆé¢„æµ‹
                    pred = slow_res.get('predicted_category', 'unknown')
                    ok = is_similar(pred, true_cat, threshold=0.5)
                    
                    if ok:
                        print(f"succ. pred cate:{pred}, true cate:{true_cat}, confidence:{slow_res.get('confidence', 0):.4f}")
                        correct += 1
                    else:
                        print(f"failed. pred cate:{pred}, true cate:{true_cat}, confidence:{slow_res.get('confidence', 0):.4f}")
                    
                    total += 1

                except Exception as e:
                    print(f'Exception:{e}')
                    total += 1

        acc = correct / total if total > 0 else 0.0
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"[slowonly] å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        
    # fast_slow æ¨¡å¼ï¼šå¯¹æµ‹è¯•é›†æ‰§è¡Œâ€œå¿«æ€è€ƒâ†’å¿…è¦æ—¶æ…¢æ€è€ƒâ†’æœ€ç»ˆèåˆâ€çš„æ•´ä½“éªŒè¯
    elif args.mode == 'fast_slow':  # è¿›å…¥ fast_slow è¯„ä¼°åˆ†æ”¯
        """
        CUDA_VISIBLE_DEVICES=2 python discovering.py --mode=fast_slow --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_1 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base --results_out=./logs/fast_and_slow_eval.json 2>&1 | tee ./logs/fast_and_slow_update_lcb_1_context256.log
        """  # ç”¨æ³•ç¤ºä¾‹ï¼šæ¼”ç¤ºå¦‚ä½•ä»å‘½ä»¤è¡Œå¯åŠ¨è¯¥æ¨¡å¼

        # åˆå§‹åŒ–å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿï¼ˆå†…éƒ¨ä¼šåˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨ã€å¿«/æ…¢æ€è€ƒæ¨¡å—ã€MLLMç­‰ï¼‰
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],  # ä½¿ç”¨é…ç½®ä¸­çš„å¤šæ¨¡æ€å¤§æ¨¡å‹æ ‡è¯†
            model_name=cfg['model_size_mllm'], # æ¨¡å‹åç§°ï¼ˆä¸ tag ä¸€è‡´ï¼‰
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',  # æŒ‰ä¸»æœºé…ç½®é€‰æ‹©è®¾å¤‡
            cfg=cfg,  # ä¼ é€’å®Œæ•´å®éªŒé…ç½®
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge  # æ˜¯å¦å¯ç”¨MLLMä¸­é—´åˆ¤åˆ«ï¼ˆå¯åšæ¶ˆèï¼‰
        )
        # åŠ è½½å·²æ„å»ºå¥½çš„çŸ¥è¯†åº“ï¼ˆå›¾åƒ/æ–‡æœ¬å‘é‡ã€ç»Ÿè®¡ä¿¡æ¯ç­‰ï¼‰ï¼Œä¾›æ£€ç´¢ä¸åˆ¤åˆ«ä½¿ç”¨
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬æ˜ å°„ï¼š{ çœŸå€¼ç±»åˆ«: [å›¾åƒè·¯å¾„, ...] }
        test_samples = {}  # ç”¨äºä¿å­˜æ¯ä¸ªç±»åˆ«å¯¹åº”çš„æ‰€æœ‰æµ‹è¯•å›¾ç‰‡
        img_root = args.test_data_dir  # æµ‹è¯•é›†æ ¹ç›®å½•
        class_folders = os.listdir(args.test_data_dir)  # åˆ—å‡ºç±»åˆ«å­ç›®å½•
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')  # ä»ç›®å½•åè§£æç±»åˆ«åï¼ˆçº¦å®šï¼šç”¨ '-' åˆ†å‰²å¹¶æ›¿æ¢ '_' ä¸ºç©ºæ ¼ï¼‰
            img_path = os.path.join(img_root, class_folders[i])  # é¡¶å±‚ç±»åˆ«ç›®å½•è·¯å¾„
            file_names = os.listdir(img_path)  # è·å–è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å
            for name in file_names:
                path = os.path.join(img_path,name)  # ç»„æˆå•å¼ å›¾ç‰‡çš„è·¯å¾„
                if cat_name not in test_samples:
                    test_samples[cat_name] = []  # é¦–æ¬¡å‡ºç°è¯¥ç±»åˆ«æ—¶åˆå§‹åŒ–åˆ—è¡¨
                test_samples[cat_name].append(path)  # åŠ å…¥è¯¥ç±»åˆ«çš„æµ‹è¯•å›¾ç‰‡

        print(f'test sample:{test_samples}')  # æ‰“å°æµ‹è¯•æ ·æœ¬æ˜ å°„ï¼Œä¾¿äºè°ƒè¯•æ ¸å¯¹
        print(f"[fast and slow] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")  # æ‰“å°ç±»åˆ«æ€»æ•°
        
        # ä½¿ç”¨å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œè¯„ä¼°ï¼ˆç»Ÿè®¡å¤šé¡¹æŒ‡æ ‡ï¼‰
        correct = 0  # é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        total = 0    # è¯„ä¼°çš„æ ·æœ¬æ€»æ•°
        fast_only_correct = 0    # æœªè§¦å‘æ…¢æ€è€ƒä¸”é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        slow_triggered = 0       # è§¦å‘è¿‡æ…¢æ€è€ƒçš„æ ·æœ¬æ•°
        slow_triggered_correct = 0  # è§¦å‘æ…¢æ€è€ƒä¸”æœ€ç»ˆé¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        
        # é€ç±»åˆ«éå†ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡
        from tqdm import tqdm  # å¼•å…¥è¿›åº¦æ¡åº“
        
        # è®¡ç®—æ€»å›¾ç‰‡æ•°é‡ç”¨äºè¿›åº¦æ˜¾ç¤º
        total_images = sum(len(paths) for paths in test_samples.values())
        current_image = 0
        current_category = 0
        total_categories = len(test_samples)
        
        for true_cat, paths in test_samples.items():  # true_cat ä¸ºçœŸå€¼ç±»åˆ«å
            current_category += 1
            category_correct = 0  # å½“å‰ç±»åˆ«æ­£ç¡®æ•°
            category_total = 0    # å½“å‰ç±»åˆ«æ€»æ•°
            
            print(f"\nğŸ”„ å¤„ç†ç±»åˆ« [{current_category}/{total_categories}]: {true_cat} ({len(paths)} å¼ å›¾ç‰‡)")
            
            for img_idx, path in enumerate(paths, 1):  # éå†è¯¥ç±»åˆ«ä¸‹çš„æ¯ä¸€å¼ å›¾ç‰‡
                current_image += 1
                
                # ä½¿ç”¨å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œå•å¼ å›¾ç‰‡åˆ†ç±»ï¼ˆè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦è¿›å…¥æ…¢æ€è€ƒï¼‰
                result = system.classify_single_image(path, use_slow_thinking=None, top_k=5)
                
                pred = result.get('final_prediction', 'unknown')  # å–å¾—æœ€ç»ˆç±»åˆ«é¢„æµ‹
                ok = is_similar(pred, true_cat, threshold=0.5)    # ä¸çœŸå€¼è¿›è¡Œç›¸ä¼¼åŒ¹é…ï¼ˆå¤§å°å†™/ç©ºæ ¼ç­‰é²æ£’ï¼‰
                used_slow = result.get('used_slow_thinking', False)  # è®°å½•æ˜¯å¦è§¦å‘æ…¢æ€è€ƒ
                
                if ok:
                    # é¢„æµ‹æ­£ç¡®ï¼šæ‰“å°è¯¦æƒ…å¹¶ç´¯åŠ è®¡æ•°
                    correct += 1  # æ€»æ­£ç¡®æ•° +1
                    category_correct += 1  # ç±»åˆ«æ­£ç¡®æ•° +1
                    if not used_slow:
                        fast_only_correct += 1  # ä»…å¿«æ€è€ƒå°±æ­£ç¡®çš„æ•°é‡ +1
                    if used_slow:
                        slow_triggered_correct += 1  # è§¦å‘æ…¢æ€è€ƒä¸”æ­£ç¡®çš„æ•°é‡ +1
                    
                    status = "âœ… æ­£ç¡®"
                else:
                    # é¢„æµ‹å¤±è´¥
                    status = "âŒ é”™è¯¯"
                
                if used_slow:
                    slow_triggered += 1  # æ ·æœ¬è¿›å…¥è¿‡æ…¢æ€è€ƒï¼Œç´¯åŠ è§¦å‘æ•°
                
                total += 1  # æ ·æœ¬æ€»æ•° +1ï¼ˆä¸è®ºæˆåŠŸä¸å¦ï¼‰
                category_total += 1
                
                # è®¡ç®—ç´¯ç§¯å‡†ç¡®ç‡
                current_acc = correct / total if total > 0 else 0.0
                category_acc = category_correct / category_total if category_total > 0 else 0.0
                
                # è¯¦ç»†è¿›åº¦æ˜¾ç¤º
                print(f"  ğŸ“¸ [{img_idx}/{len(paths)}] {status} | "
                      f"é¢„æµ‹: {pred} | çœŸå€¼: {true_cat} | "
                      f"æ…¢æ€è€ƒ: {'æ˜¯' if used_slow else 'å¦'} | "
                      f"ç½®ä¿¡åº¦: {result.get('final_confidence', 0):.3f}")
                print(f"     ğŸ“Š å›¾ç‰‡è¿›åº¦: {current_image}/{total_images} | "
                      f"ç´¯ç§¯å‡†ç¡®ç‡: {current_acc:.3f} ({correct}/{total}) | "
                      f"ç±»åˆ«å‡†ç¡®ç‡: {category_acc:.3f} ({category_correct}/{category_total})")
            
            # ç±»åˆ«å¤„ç†å®Œæˆæ€»ç»“
            print(f"âœ¨ ç±»åˆ« {true_cat} å®Œæˆ: {category_correct}/{category_total} = {category_acc:.3f}")
            print(f"ğŸ“ˆ å½“å‰æ€»ä½“è¿›åº¦: {current_image}/{total_images} | ç´¯ç§¯å‡†ç¡®ç‡: {correct/total:.3f} ({correct}/{total})")
            print("-" * 80)
        
        # æ±‡æ€»è¯„ä¼°æŒ‡æ ‡
        acc = correct / total if total > 0 else 0.0  # æ€»ä½“å‡†ç¡®ç‡
        fast_only_acc = fast_only_correct / (total-slow_triggered) if total > 0 else 0.0  # ä»…å¿«æ€è€ƒéƒ¨åˆ†çš„å‡†ç¡®ç‡ï¼ˆæ³¨æ„ï¼šè‹¥åˆ†æ¯ä¸º0ä¼šæŠ¥é”™ï¼Œæ­¤å¤„ä¿æŒåŸé€»è¾‘ï¼‰
        slow_trigger_ratio = slow_triggered / total if total > 0 else 0.0  # æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0  # è§¦å‘æ…¢æ€è€ƒæ ·æœ¬çš„å‡†ç¡®ç‡
        
        # æ‰“å°è¯„ä¼°ç»“æœ
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[fast and slow] æ€»ä½“å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        print(f"[fast and slow] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[fast and slow] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[fast and slow] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
    
    elif args.mode == 'fast_slow_infer':
        """
        å¿«æ…¢æ€è€ƒæ¨ç†æ¨¡å¼ï¼šä¿å­˜å¿«æ€è€ƒå’Œæ…¢æ€è€ƒçš„æ¨ç†ç»“æœï¼Œä¸è¿›è¡Œæœ€ç»ˆåˆ†ç±»
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_slow_infer --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=./datasets/dogs_120/images_discovery_all_1 --knowledge_base_dir=./experiments/dog120/knowledge_base --infer_dir=./experiments/dog120/infer
        """
        if args.test_data_dir is None:
            raise ValueError("è¯·æä¾›æµ‹è¯•æ•°æ®ç›®å½• --test_data_dir")
        
        # è‡ªåŠ¨ç”Ÿæˆæ¨ç†ç»“æœä¿å­˜ç›®å½•ï¼ˆåŸºäºæ•°æ®é›†åç§°ï¼‰
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        print(f"æ¨ç†ç»“æœå°†ä¿å­˜åˆ°: {args.infer_dir}")
        os.makedirs(args.infer_dir, exist_ok=True)
        
        # åˆå§‹åŒ–å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f"[fast_slow_infer] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # æ‰§è¡Œæ¨ç†å¹¶ä¿å­˜ç»“æœ
        total_processed = 0
        from tqdm import tqdm
        
        # è®¡ç®—æ€»å›¾ç‰‡æ•°é‡ç”¨äºè¿›åº¦æ˜¾ç¤º
        total_images = sum(len(paths) for paths in test_samples.values())
        current_image = 0
        current_category = 0
        total_categories = len(test_samples)
        
        for true_cat, paths in test_samples.items():
            current_category += 1
            print(f"\nğŸ”„ æ¨ç†ç±»åˆ« [{current_category}/{total_categories}]: {true_cat} ({len(paths)} å¼ å›¾ç‰‡)")
            
            for img_idx, path in enumerate(paths, 1):
                try:
                    # æ‰§è¡Œå¿«æ€è€ƒ
                    fast_result = system.fast_thinking.fast_thinking_pipeline(path, top_k=5)
                    
                    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ…¢æ€è€ƒï¼ˆå¤åˆ¶classify_single_imageçš„é€»è¾‘ï¼‰
                    mllm_judge_result = None
                    if system.enable_mllm_intermediate_judge:
                        # å¯ç”¨MLLMä¸­é—´åˆ¤æ–­
                        mllm_need_slow, mllm_predicted, mllm_confidence = system.mllm_intermediate_judge(path, fast_result, top_k=5)
                        need_slow_thinking = mllm_need_slow
                        mllm_judge_result = {
                            "predicted_category": mllm_predicted,
                            "confidence": mllm_confidence,
                            "need_slow_thinking": mllm_need_slow
                        }
                    else:
                        # ä½¿ç”¨ä¼ ç»Ÿçš„å¿«æ€è€ƒè§¦å‘æœºåˆ¶
                        need_slow_thinking = fast_result["need_slow_thinking"]
                    
                    inference_data = {
                        "query_image": path,
                        "true_category": true_cat,
                        "fast_result": fast_result,
                        "need_slow_thinking": need_slow_thinking,
                        "slow_result": None,
                        "mllm_judge_result": mllm_judge_result,  # ä¿å­˜MLLMä¸­é—´åˆ¤æ–­ç»“æœ
                        # ä¿å­˜åˆ†ç±»å‰å¿…é¡»çš„æ‰€æœ‰ä¿¡æ¯
                        "fast_top_k": fast_result.get("img_results", [])[:5] + fast_result.get("text_results", [])[:5],  # å¿«æ€è€ƒTop-Kå€™é€‰
                        "fast_fused_results": fast_result.get("fused_results", [])[:5],  # èåˆåçš„Top-K
                        "timestamp": time.time()
                    }
                    
                    # å¦‚æœéœ€è¦æ…¢æ€è€ƒï¼Œæ‰§è¡Œæ…¢æ€è€ƒ
                    if need_slow_thinking:
                        slow_result = system.slow_thinking.slow_thinking_pipeline_update(path, fast_result, top_k=5)
                        inference_data["slow_result"] = slow_result
                        # ä¿å­˜æ…¢æ€è€ƒçš„Top-Kå€™é€‰ä¿¡æ¯
                        inference_data["slow_top_k"] = slow_result.get("enhanced_results", [])[:5] if slow_result else []
                    
                    # ä¿å­˜æ¨ç†ç»“æœ
                    base_name = os.path.splitext(os.path.basename(path))[0]
                    safe_cat_name = true_cat.replace(' ', '_').replace('/', '_')
                    infer_file = os.path.join(args.infer_dir, f"{safe_cat_name}_{base_name}.json")
                    
                    # ä½¿ç”¨dump_json_overrideç›´æ¥ä¿å­˜å¯¹è±¡ï¼Œé¿å…æ•°ç»„åŒ…è£…
                    from utils.fileios import dump_json_override
                    dump_json_override(infer_file, inference_data)
                    total_processed += 1
                    current_image += 1
                    
                    # è¯¦ç»†è¿›åº¦æ˜¾ç¤º
                    slow_status = "éœ€è¦æ…¢æ€è€ƒ" if need_slow_thinking else "ä»…å¿«æ€è€ƒ"
                    fast_pred = fast_result.get("predicted_category", "unknown")
                    fast_conf = fast_result.get("confidence", 0.0)
                    
                    print(f"  ğŸ“¸ [{img_idx}/{len(paths)}] æ¨ç†å®Œæˆ | "
                          f"å¿«æ€è€ƒé¢„æµ‹: {fast_pred} | ç½®ä¿¡åº¦: {fast_conf:.3f} | {slow_status}")
                    print(f"     ğŸ“Š å›¾ç‰‡è¿›åº¦: {current_image}/{total_images} | "
                          f"å·²å¤„ç†: {total_processed} ä¸ªæ ·æœ¬")
                    
                    if total_processed % 50 == 0:
                        print(f"ğŸ“ˆ é˜¶æ®µæ€§è¿›åº¦: å·²å®Œæˆ {total_processed}/{total_images} ä¸ªæ ·æœ¬")
                        
                except Exception as e:
                    print(f"âŒ å¤„ç†å¤±è´¥ {path}: {e}")
                    continue
            
            # ç±»åˆ«æ¨ç†å®Œæˆæ€»ç»“
            category_processed = len(paths)
            print(f"âœ¨ ç±»åˆ« {true_cat} æ¨ç†å®Œæˆ: {category_processed} å¼ å›¾ç‰‡")
            print(f"ğŸ“ˆ å½“å‰æ€»ä½“è¿›åº¦: {current_image}/{total_images} | å·²å¤„ç†: {total_processed} ä¸ªæ ·æœ¬")
            print("-" * 80)
        
        print(f"æ¨ç†å®Œæˆï¼å…±å¤„ç† {total_processed} ä¸ªæ ·æœ¬")
        print(f"æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {args.infer_dir}")
    
    elif args.mode == 'fast_slow_classify':
        """
        å¿«æ…¢æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼šåŠ è½½æ¨ç†ç»“æœï¼Œæ‰§è¡Œåˆ†ç±»é€»è¾‘å¹¶ç»Ÿè®¡æŒ‡æ ‡
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_slow_classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --infer_dir=./experiments/dog120/infer --classify_dir=./experiments/dog120/classify
        """
        # è‡ªåŠ¨ç”Ÿæˆæ¨ç†ç»“æœåŠ è½½ç›®å½•å’Œåˆ†ç±»ç»“æœä¿å­˜ç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        if not os.path.exists(args.infer_dir):
            raise ValueError(f"æ¨ç†ç»“æœç›®å½•ä¸å­˜åœ¨: {args.infer_dir}")
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"åˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆç”¨äºæœ€ç»ˆå†³ç­–ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼‰
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“ï¼ˆä¸fast_slowæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
        # è‡ªåŠ¨æ¨æ–­çŸ¥è¯†åº“ç›®å½•
        if args.knowledge_base_dir == './knowledge_base':
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            knowledge_base_dir = f"./experiments/{dataset_name}{dataset_num}/knowledge_base"
        else:
            knowledge_base_dir = args.knowledge_base_dir
        
        if os.path.exists(knowledge_base_dir):
            system.load_knowledge_base(knowledge_base_dir)
            print(f"å·²åŠ è½½çŸ¥è¯†åº“: {knowledge_base_dir}")
        else:
            print(f"è­¦å‘Š: çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨ {knowledge_base_dir}ï¼Œ_final_decisionå¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        
        # åŠ è½½æ‰€æœ‰æ¨ç†ç»“æœæ–‡ä»¶
        infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
        print(f"æ‰¾åˆ° {len(infer_files)} ä¸ªæ¨ç†ç»“æœæ–‡ä»¶")
        
        # ç»Ÿè®¡æŒ‡æ ‡
        correct = 0
        total = 0
        fast_only_correct = 0
        slow_triggered = 0
        slow_triggered_correct = 0
        
        classification_results = []
        
        from tqdm import tqdm
        for infer_file in tqdm(infer_files, desc="Processing classification"):
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                loaded_data = load_json(infer_path)
                
                # å¤„ç†æ•°ç»„æ ¼å¼çš„æ¨ç†ç»“æœï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                if isinstance(loaded_data, list):
                    if len(loaded_data) > 0:
                        inference_data = loaded_data[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                    else:
                        print(f"è­¦å‘Š: {infer_file} åŒ…å«ç©ºæ•°ç»„")
                        continue
                else:
                    inference_data = loaded_data  # ç›´æ¥ä½¿ç”¨å¯¹è±¡æ ¼å¼
                
                query_image = inference_data["query_image"]
                true_cat = inference_data["true_category"]
                fast_result = inference_data["fast_result"]
                need_slow_thinking = inference_data["need_slow_thinking"]
                slow_result = inference_data.get("slow_result")
                
                # æ‰§è¡Œåˆ†ç±»é€»è¾‘ï¼ˆå®Œå…¨å¤åˆ¶classify_single_imageçš„é€»è¾‘ï¼‰
                mllm_judge_result = inference_data.get("mllm_judge_result")
                
                if not need_slow_thinking:
                    # è·¯å¾„1: ä»…å¿«æ€è€ƒåˆ†ç±»ï¼ˆæˆ–MLLMä¸­é—´åˆ¤æ–­ï¼‰
                    if mllm_judge_result is not None and not mllm_judge_result["need_slow_thinking"]:
                        # MLLMä¸­é—´åˆ¤æ–­æœ‰ä¿¡å¿ƒï¼Œä½¿ç”¨MLLMç»“æœ
                        final_prediction = mllm_judge_result["predicted_category"]
                        final_confidence = mllm_judge_result["confidence"]
                        decision_path = "mllm_judge"
                    else:
                        # ä½¿ç”¨å¿«æ€è€ƒç»“æœ
                        final_prediction = fast_result["predicted_category"]
                        final_confidence = fast_result["confidence"]
                        decision_path = "fast_only"
                    
                    used_slow_thinking = False
                    fast_slow_consistent = True
                else:
                    # ä½¿ç”¨æ…¢æ€è€ƒç»“æœ
                    if slow_result is None:
                        print(f"è­¦å‘Š: {infer_file} éœ€è¦æ…¢æ€è€ƒä½†æ²¡æœ‰æ…¢æ€è€ƒç»“æœ")
                        continue
                    
                    # è·å–å¿«æ€è€ƒé¢„æµ‹ï¼ˆä¸classify_single_imageä¸€è‡´ï¼‰
                    fast_pred = fast_result.get("fused_top1", fast_result.get("predicted_category", "unknown"))
                    slow_pred = slow_result["predicted_category"]
                    used_slow_thinking = True
                    
                    # æ£€æŸ¥å¿«æ…¢æ€è€ƒæ˜¯å¦ä¸€è‡´
                    if fast_pred != slow_pred and not is_similar(fast_pred, slow_pred, threshold=0.5):
                        # è·¯å¾„3: å¿«æ…¢ä¸ä¸€è‡´ï¼Œéœ€è¦æœ€ç»ˆè£å†³
                        fast_slow_consistent = False
                        decision_path = "final_arbitration"
                        
                        # è°ƒç”¨ç³»ç»Ÿçš„æœ€ç»ˆå†³ç­–å‡½æ•°ï¼ˆä¸fast_slowæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
                        if system and hasattr(system, '_final_decision'):
                            final_prediction, final_confidence, _ = system._final_decision(
                                query_image, fast_result, slow_result, 5
                            )
                        else:
                            # å…œåº•ç­–ç•¥: ç›´æ¥ç”¨æ…¢æ€è€ƒç»“æœ
                            final_prediction = slow_pred
                            final_confidence = slow_result["confidence"]
                        
                        print(f"å¿«æ…¢ä¸ä¸€è‡´: fast={fast_pred}, slow={slow_pred}, è£å†³ç»“æœ={final_prediction}")
                    else:
                        # è·¯å¾„2: å¿«æ…¢æ€è€ƒä¸€è‡´ï¼Œç›´æ¥ç”¨æ…¢æ€è€ƒç»“æœ
                        final_prediction = slow_pred
                        final_confidence = slow_result["confidence"]
                        fast_slow_consistent = True
                        decision_path = "slow_consistent"
                
                # è¯„ä¼°é¢„æµ‹ç»“æœ
                is_correct = is_similar(final_prediction, true_cat, threshold=0.5)
                
                if is_correct:
                    correct += 1
                    if not used_slow_thinking:
                        fast_only_correct += 1
                    if used_slow_thinking:
                        slow_triggered_correct += 1
                        
                if used_slow_thinking:
                    slow_triggered += 1
                
                total += 1
                
                # ä¿å­˜åˆ†ç±»ç»“æœ
                result = {
                    "query_image": query_image,
                    "true_category": true_cat,
                    "final_prediction": final_prediction,
                    "final_confidence": final_confidence,
                    "used_slow_thinking": used_slow_thinking,
                    "fast_slow_consistent": fast_slow_consistent,
                    "decision_path": decision_path,  # è®°å½•å†³ç­–è·¯å¾„
                    "is_correct": is_correct,
                    "fast_prediction": fast_result.get("predicted_category", "unknown"),
                    "fast_confidence": fast_result.get("confidence", 0.0),
                    "slow_prediction": slow_result["predicted_category"] if slow_result else None,
                    "slow_confidence": slow_result["confidence"] if slow_result else None
                }
                
                classification_results.append(result)
                
            except Exception as e:
                print(f"å¤„ç†åˆ†ç±»å¤±è´¥ {infer_file}: {e}")
                continue
        
        # è®¡ç®—å¹¶æ‰“å°æŒ‡æ ‡
        acc = correct / total if total > 0 else 0.0
        fast_only_acc = fast_only_correct / (total-slow_triggered) if (total-slow_triggered) > 0 else 0.0
        slow_trigger_ratio = slow_triggered / total if total > 0 else 0.0
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0
        
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[fast_slow_classify] æ€»ä½“å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        print(f"[fast_slow_classify] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[fast_slow_classify] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[fast_slow_classify] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
        
        # ä¿å­˜åˆ†ç±»ç»“æœ
        results_file = os.path.join(args.classify_dir, "classification_results.json")
        dump_json(results_file, {
            "summary": {
                "total_samples": total,
                "correct_predictions": correct,
                "accuracy": acc,
                "fast_only_correct": fast_only_correct,
                "fast_only_accuracy": fast_only_acc,
                "slow_triggered": slow_triggered,
                "slow_trigger_ratio": slow_trigger_ratio,
                "slow_triggered_correct": slow_triggered_correct,
                "slow_trigger_accuracy": slow_trigger_acc
            },
            "detailed_results": classification_results
        })
        
        print(f"åˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    elif args.mode == 'fast_classify':
        """
        å¿«æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼šåªå¤„ç†ä¸éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬ï¼Œæ‰§è¡Œå¿«æ€è€ƒåˆ†ç±»
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/pet37_all.yml --infer_dir=./experiments/pet37/infer --classify_dir=./experiments/pet37/classify
        """
        # è‡ªåŠ¨ç”Ÿæˆç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        if not os.path.exists(args.infer_dir):
            raise ValueError(f"æ¨ç†ç»“æœç›®å½•ä¸å­˜åœ¨: {args.infer_dir}")
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"å¿«æ€è€ƒåˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # ä¸éœ€è¦MLLMï¼Œè·³è¿‡æ¨¡å‹åˆå§‹åŒ–ä»¥èŠ‚çœèµ„æº
        print("å¿«æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼Œè·³è¿‡MLLMæ¨¡å‹åŠ è½½")
        
        # åŠ è½½æ‰€æœ‰æ¨ç†ç»“æœæ–‡ä»¶
        infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
        print(f"æ‰¾åˆ° {len(infer_files)} ä¸ªæ¨ç†ç»“æœæ–‡ä»¶")
        
        # ç»Ÿè®¡æŒ‡æ ‡
        fast_correct = 0
        fast_total = 0
        fast_classification_results = []
        
        from tqdm import tqdm
        for infer_file in tqdm(infer_files, desc="Processing fast classification"):
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                loaded_data = load_json(infer_path)
                
                # å¤„ç†æ•°ç»„æ ¼å¼çš„æ¨ç†ç»“æœï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                if isinstance(loaded_data, list):
                    if len(loaded_data) > 0:
                        inference_data = loaded_data[0]
                    else:
                        continue
                else:
                    inference_data = loaded_data
                
                query_image = inference_data["query_image"]
                true_cat = inference_data["true_category"]
                fast_result = inference_data["fast_result"]
                need_slow_thinking = inference_data["need_slow_thinking"]
                mllm_judge_result = inference_data.get("mllm_judge_result")
                
                # åªå¤„ç†ä¸éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬
                if not need_slow_thinking:
                    # æ‰§è¡Œå¿«æ€è€ƒåˆ†ç±»é€»è¾‘
                    if mllm_judge_result is not None and not mllm_judge_result["need_slow_thinking"]:
                        # MLLMä¸­é—´åˆ¤æ–­æœ‰ä¿¡å¿ƒï¼Œä½¿ç”¨MLLMç»“æœ
                        final_prediction = mllm_judge_result["predicted_category"]
                        final_confidence = mllm_judge_result["confidence"]
                        decision_path = "mllm_judge"
                    else:
                        # ä½¿ç”¨å¿«æ€è€ƒç»“æœ
                        final_prediction = fast_result["predicted_category"]
                        final_confidence = fast_result["confidence"]
                        decision_path = "fast_only"
                    
                    used_slow_thinking = False
                    fast_slow_consistent = True
                    
                    # è¯„ä¼°é¢„æµ‹ç»“æœ
                    is_correct = is_similar(final_prediction, true_cat, threshold=0.5)
                    
                    if is_correct:
                        fast_correct += 1
                    
                    fast_total += 1
                    
                    # ä¿å­˜åˆ†ç±»ç»“æœ
                    result = {
                        "query_image": query_image,
                        "true_category": true_cat,
                        "final_prediction": final_prediction,
                        "final_confidence": final_confidence,
                        "used_slow_thinking": used_slow_thinking,
                        "fast_slow_consistent": fast_slow_consistent,
                        "decision_path": decision_path,
                        "is_correct": is_correct,
                        "fast_prediction": fast_result.get("predicted_category", "unknown"),
                        "fast_confidence": fast_result.get("confidence", 0.0)
                    }
                    
                    fast_classification_results.append(result)
                
            except Exception as e:
                print(f"å¤„ç†å¿«æ€è€ƒåˆ†ç±»å¤±è´¥ {infer_file}: {e}")
                continue
        
        # è®¡ç®—å¹¶æ‰“å°æŒ‡æ ‡
        fast_acc = fast_correct / fast_total if fast_total > 0 else 0.0
        
        print(f"âœ… å¿«æ€è€ƒæ­£ç¡®é¢„æµ‹æ•°: {fast_correct}")
        print(f"ğŸ“Š å¿«æ€è€ƒæ€»æ ·æœ¬æ•°: {fast_total}")
        print(f"[fast_classify] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_acc:.4f} ({fast_correct}/{fast_total})")
        
        # ä¿å­˜å¿«æ€è€ƒåˆ†ç±»ç»“æœ
        fast_results_file = os.path.join(args.classify_dir, "fast_classification_results.json")
        dump_json(fast_results_file, {
            "summary": {
                "total_samples": fast_total,
                "correct_predictions": fast_correct,
                "accuracy": fast_acc
            },
            "detailed_results": fast_classification_results
        })
        
        print(f"å¿«æ€è€ƒåˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {fast_results_file}")
    
    elif args.mode == 'slow_classify':
        """
        æ…¢æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼šåªå¤„ç†éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬ï¼Œæ‰§è¡Œæ…¢æ€è€ƒåˆ†ç±»
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=slow_classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/pet37_all.yml --infer_dir=./experiments/pet37/infer --classify_dir=./experiments/pet37/classify
        """
        # è‡ªåŠ¨ç”Ÿæˆç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        if not os.path.exists(args.infer_dir):
            raise ValueError(f"æ¨ç†ç»“æœç›®å½•ä¸å­˜åœ¨: {args.infer_dir}")
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"æ…¢æ€è€ƒåˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŠ è½½MLLMæ¨¡å‹ï¼ˆæœ‰æ…¢æ€è€ƒæ ·æœ¬æ‰éœ€è¦ï¼‰
        infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
        need_mllm = False
        
        # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬
        for infer_file in infer_files[:min(10, len(infer_files))]:  # åªæ£€æŸ¥å‰10ä¸ªæ–‡ä»¶
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                loaded_data = load_json(infer_path)
                if isinstance(loaded_data, list):
                    if len(loaded_data) > 0:
                        inference_data = loaded_data[0]
                    else:
                        continue
                else:
                    inference_data = loaded_data
                
                if inference_data.get("need_slow_thinking", False):
                    need_mllm = True
                    break
            except:
                continue
        
        if not need_mllm:
            print("æ…¢æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼Œä½†æ²¡æœ‰éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬ï¼Œè·³è¿‡MLLMæ¨¡å‹åŠ è½½")
        else:
            print("æ…¢æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼Œå‘ç°éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬ï¼Œè·³è¿‡MLLMæ¨¡å‹åŠ è½½ï¼ˆå·²åœ¨æ¨ç†é˜¶æ®µå®Œæˆï¼‰")
        
        # ç»Ÿè®¡æŒ‡æ ‡
        slow_correct = 0
        slow_total = 0
        slow_classification_results = []
        
        from tqdm import tqdm
        for infer_file in tqdm(infer_files, desc="Processing slow classification"):
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                loaded_data = load_json(infer_path)
                
                # å¤„ç†æ•°ç»„æ ¼å¼çš„æ¨ç†ç»“æœï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                if isinstance(loaded_data, list):
                    if len(loaded_data) > 0:
                        inference_data = loaded_data[0]
                    else:
                        continue
                else:
                    inference_data = loaded_data
                
                query_image = inference_data["query_image"]
                true_cat = inference_data["true_category"]
                fast_result = inference_data["fast_result"]
                need_slow_thinking = inference_data["need_slow_thinking"]
                slow_result = inference_data.get("slow_result")
                
                # åªå¤„ç†éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬
                if need_slow_thinking and slow_result is not None:
                    # è·å–å¿«æ…¢é¢„æµ‹ç”¨äºä¸€è‡´æ€§æ£€æŸ¥
                    fast_pred = fast_result.get("fused_top1", fast_result.get("predicted_category", "unknown"))
                    slow_pred = slow_result["predicted_category"]
                    used_slow_thinking = True
                    
                    # æ£€æŸ¥å¿«æ…¢æ€è€ƒæ˜¯å¦ä¸€è‡´
                    if fast_pred == slow_pred or is_similar(fast_pred, slow_pred, threshold=0.5):
                        # å¿«æ…¢æ€è€ƒä¸€è‡´ï¼Œä½¿ç”¨æ…¢æ€è€ƒç»“æœ
                        final_prediction = slow_pred
                        final_confidence = slow_result["confidence"]
                        fast_slow_consistent = True
                        decision_path = "slow_consistent"
                        # è¯„ä¼°é¢„æµ‹ç»“æœ
                        is_correct = is_similar(final_prediction, true_cat, threshold=0.5)
                    else:
                        # å¿«æ…¢æ€è€ƒä¸ä¸€è‡´ï¼Œæ ‡è®°ä¸ºéœ€è¦ç»ˆç«¯å†³ç­–
                        final_prediction = "conflict"  # æ ‡è®°ä¸ºå†²çªï¼Œç­‰å¾…ç»ˆç«¯å†³ç­–
                        final_confidence = slow_result["confidence"]
                        fast_slow_consistent = False
                        decision_path = "need_terminal_decision"
                        # ä¸åœ¨æ­¤é˜¶æ®µè¯„ä¼°å‡†ç¡®ç‡ï¼Œç­‰å¾…ç»ˆç«¯å†³ç­–
                        is_correct = False  # ä¸´æ—¶æ ‡è®°ä¸ºFalseï¼Œå°†åœ¨terminal_decisionä¸­é‡æ–°è¯„ä¼°
                    
                    # åªæœ‰ä¸€è‡´çš„æ ·æœ¬æ‰è®¡å…¥å‡†ç¡®ç‡ç»Ÿè®¡ï¼Œä¸ä¸€è‡´çš„ç­‰å¾…ç»ˆç«¯å†³ç­–
                    if decision_path == "slow_consistent" and is_correct:
                        slow_correct += 1
                    
                    # æ‰€æœ‰æ…¢æ€è€ƒæ ·æœ¬éƒ½è®¡å…¥æ€»æ•°
                    slow_total += 1
                    
                    # ä¿å­˜åˆ†ç±»ç»“æœ
                    result = {
                        "query_image": query_image,
                        "true_category": true_cat,
                        "final_prediction": final_prediction,
                        "final_confidence": final_confidence,
                        "used_slow_thinking": used_slow_thinking,
                        "fast_slow_consistent": fast_slow_consistent,
                        "decision_path": decision_path,
                        "is_correct": is_correct,
                        "fast_prediction": fast_result.get("predicted_category", "unknown"),
                        "fast_confidence": fast_result.get("confidence", 0.0),
                        "slow_prediction": slow_result["predicted_category"],
                        "slow_confidence": slow_result["confidence"]
                    }
                    
                    slow_classification_results.append(result)
                
            except Exception as e:
                print(f"å¤„ç†æ…¢æ€è€ƒåˆ†ç±»å¤±è´¥ {infer_file}: {e}")
                continue
        
        # è®¡ç®—å¹¶æ‰“å°æŒ‡æ ‡
        slow_acc = slow_correct / slow_total if slow_total > 0 else 0.0
        
        print(f"âœ… æ…¢æ€è€ƒæ­£ç¡®é¢„æµ‹æ•°: {slow_correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒæ€»æ ·æœ¬æ•°: {slow_total}")
        print(f"[slow_classify] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_acc:.4f} ({slow_correct}/{slow_total})")
        
        # ä¿å­˜æ…¢æ€è€ƒåˆ†ç±»ç»“æœ
        slow_results_file = os.path.join(args.classify_dir, "slow_classification_results.json")
        dump_json(slow_results_file, {
            "summary": {
                "total_samples": slow_total,
                "correct_predictions": slow_correct,
                "accuracy": slow_acc
            },
            "detailed_results": slow_classification_results
        })
        
        print(f"æ…¢æ€è€ƒåˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {slow_results_file}")
    
    elif args.mode == 'terminal_decision':
        """
        ç»ˆç«¯å†³ç­–æ¨¡å¼ï¼šå¤„ç†å¿«æ…¢ä¸ä¸€è‡´çš„æ ·æœ¬ï¼Œåšæœ€ç»ˆå†³ç­–ï¼Œå¹¶æ•´åˆæ‰€æœ‰ç»“æœ
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=terminal_decision --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/pet37_all.yml --infer_dir=./experiments/pet37/infer --classify_dir=./experiments/pet37/classify
        """
        # è‡ªåŠ¨ç”Ÿæˆç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"ç»ˆç«¯å†³ç­–ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # æ£€æŸ¥å¿«æ…¢æ€è€ƒåˆ†ç±»ç»“æœæ˜¯å¦å­˜åœ¨
        fast_results_file = os.path.join(args.classify_dir, "fast_classification_results.json")
        slow_results_file = os.path.join(args.classify_dir, "slow_classification_results.json")
        
        if not os.path.exists(fast_results_file):
            raise FileNotFoundError(f"å¿«æ€è€ƒåˆ†ç±»ç»“æœä¸å­˜åœ¨: {fast_results_file}")
        if not os.path.exists(slow_results_file):
            raise FileNotFoundError(f"æ…¢æ€è€ƒåˆ†ç±»ç»“æœä¸å­˜åœ¨: {slow_results_file}")
        
        # åŠ è½½å¿«æ…¢æ€è€ƒåˆ†ç±»ç»“æœ
        fast_data = load_json(fast_results_file)
        slow_data = load_json(slow_results_file)
        
        # å¤„ç†æ•°æ®æ ¼å¼ï¼šå¦‚æœæ˜¯æ•°ç»„å½¢å¼ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
        if isinstance(fast_data, list) and len(fast_data) > 0:
            fast_data = fast_data[0]
        if isinstance(slow_data, list) and len(slow_data) > 0:
            slow_data = slow_data[0]
            
        fast_results = fast_data["detailed_results"]
        slow_results = slow_data["detailed_results"]
        
        print(f"åŠ è½½äº† {len(fast_results)} ä¸ªå¿«æ€è€ƒåˆ†ç±»ç»“æœ")
        print(f"åŠ è½½äº† {len(slow_results)} ä¸ªæ…¢æ€è€ƒåˆ†ç±»ç»“æœ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
        need_terminal_samples = [r for r in slow_results if r.get("decision_path") == "need_terminal_decision"]
        
        if len(need_terminal_samples) > 0:
            print(f"å‘ç° {len(need_terminal_samples)} ä¸ªéœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬ï¼Œåˆå§‹åŒ–ç³»ç»Ÿ...")
            
            # åˆå§‹åŒ–ç³»ç»Ÿç”¨äºæœ€ç»ˆå†³ç­–
            system = FastSlowThinkingSystem(
                model_tag=cfg['model_size_mllm'],
                model_name=cfg['model_size_mllm'],
                device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
                cfg=cfg,
                enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
            )
            
            # åŠ è½½çŸ¥è¯†åº“
            if args.knowledge_base_dir == './knowledge_base':
                dataset_name = cfg['dataset_name']
                dataset_num = len(DATA_STATS[dataset_name]['class_names'])
                knowledge_base_dir = f"./experiments/{dataset_name}{dataset_num}/knowledge_base"
            else:
                knowledge_base_dir = args.knowledge_base_dir
            
            if os.path.exists(knowledge_base_dir):
                system.load_knowledge_base(knowledge_base_dir)
                print(f"å·²åŠ è½½çŸ¥è¯†åº“: {knowledge_base_dir}")
            else:
                print(f"è­¦å‘Š: çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨ {knowledge_base_dir}")
            
            # åŠ è½½æ¨ç†ç»“æœç”¨äºç»ˆç«¯å†³ç­–
            infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
            
            # å¤„ç†éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
            for i, result in enumerate(need_terminal_samples):
                query_image = result["query_image"]
                
                # æ‰¾åˆ°å¯¹åº”çš„æ¨ç†ç»“æœ
                base_name = os.path.splitext(os.path.basename(query_image))[0]
                true_cat = result["true_category"]
                safe_cat_name = true_cat.replace(' ', '_').replace('/', '_')
                infer_file_pattern = f"{safe_cat_name}_{base_name}.json"
                
                infer_file_path = None
                for infer_file in infer_files:
                    if infer_file == infer_file_pattern:
                        infer_file_path = os.path.join(args.infer_dir, infer_file)
                        break
                
                if infer_file_path and os.path.exists(infer_file_path):
                    try:
                        loaded_data = load_json(infer_file_path)
                        if isinstance(loaded_data, list):
                            inference_data = loaded_data[0] if len(loaded_data) > 0 else None
                        else:
                            inference_data = loaded_data
                        
                        if inference_data:
                            fast_result = inference_data["fast_result"]
                            slow_result = inference_data["slow_result"]
                            
                            # è°ƒç”¨ç³»ç»Ÿçš„æœ€ç»ˆå†³ç­–å‡½æ•°
                            if system and hasattr(system, '_final_decision'):
                                final_prediction, final_confidence, _ = system._final_decision(
                                    query_image, fast_result, slow_result, 5
                                )
                                
                                # æ›´æ–°need_terminal_samplesä¸­çš„ç»“æœ
                                result["final_prediction"] = final_prediction
                                result["final_confidence"] = final_confidence
                                result["decision_path"] = "final_arbitration"
                                result["is_correct"] = is_similar(final_prediction, true_cat, threshold=0.5)
                                
                                # é‡è¦ï¼šåŒæ­¥æ›´æ–°slow_resultsä¸­å¯¹åº”çš„ç»“æœ
                                for j, slow_result_item in enumerate(slow_results):
                                    if slow_result_item["query_image"] == query_image:
                                        slow_results[j]["final_prediction"] = final_prediction
                                        slow_results[j]["final_confidence"] = final_confidence
                                        slow_results[j]["decision_path"] = "final_arbitration"
                                        slow_results[j]["is_correct"] = is_similar(final_prediction, true_cat, threshold=0.5)
                                        break
                                
                                print(f"ç»ˆç«¯å†³ç­–: {query_image} -> {final_prediction} (ç½®ä¿¡åº¦: {final_confidence:.4f}) æ­£ç¡®: {result['is_correct']}")
                            
                    except Exception as e:
                        print(f"ç»ˆç«¯å†³ç­–å¤±è´¥ {query_image}: {e}")
        else:
            print("æ²¡æœ‰éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬")
        
        # æ•´åˆæ‰€æœ‰ç»“æœ
        all_results = fast_results + slow_results
        
        # é‡æ–°è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ - éœ€è¦ç‰¹åˆ«å¤„ç†ç»è¿‡ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
        total_samples = len(all_results)
        
        # é‡æ–°è®¡ç®—correct_predictionsï¼Œæ‰€æœ‰æ ·æœ¬çš„is_correctéƒ½å·²ç»æ˜¯æœ€æ–°çš„
        correct_predictions = sum(1 for r in all_results if r.get("is_correct", False))
        
        fast_only_correct = sum(1 for r in fast_results if r.get("is_correct", False))
        slow_triggered = len(slow_results)
        
        # é‡æ–°è®¡ç®—slow_triggered_correctï¼ŒåŒ…å«ç»ˆç«¯å†³ç­–çš„ç»“æœ
        slow_triggered_correct = 0
        for r in slow_results:
            if r.get("decision_path") == "slow_consistent":
                # ä¸€è‡´çš„æ…¢æ€è€ƒæ ·æœ¬
                slow_triggered_correct += 1 if r.get("is_correct", False) else 0
            elif r.get("decision_path") == "final_arbitration":
                # ç»è¿‡ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
                slow_triggered_correct += 1 if r.get("is_correct", False) else 0
        
        accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0
        fast_only_acc = fast_only_correct / len(fast_results) if len(fast_results) > 0 else 0.0
        slow_trigger_ratio = slow_triggered / total_samples if total_samples > 0 else 0.0
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0
        
        print(f"âœ… æ€»æ­£ç¡®é¢„æµ‹æ•°: {correct_predictions}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ æ€»é”™è¯¯é¢„æµ‹æ•°: {total_samples - correct_predictions}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[terminal_decision] æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({correct_predictions}/{total_samples})")
        print(f"[terminal_decision] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[terminal_decision] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[terminal_decision] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
        
        # ä¿å­˜æ•´åˆåçš„åˆ†ç±»ç»“æœ
        final_results_file = os.path.join(args.classify_dir, "terminal_decision_results.json")
        dump_json(final_results_file, {
            "summary": {
                "total_samples": total_samples,
                "correct_predictions": correct_predictions,
                "accuracy": accuracy,
                "fast_only_correct": fast_only_correct,
                "fast_only_accuracy": fast_only_acc,
                "slow_triggered": slow_triggered,
                "slow_trigger_ratio": slow_trigger_ratio,
                "slow_triggered_correct": slow_triggered_correct,
                "slow_trigger_accuracy": slow_trigger_acc
            },
            "detailed_results": all_results
        })
        
        print(f"ç»ˆç«¯å†³ç­–ç»“æœå·²ä¿å­˜åˆ°: {final_results_file}")
    
    elif args.mode == 'fast_classify_enhanced':
        """
        å¿«æ€è€ƒå¤šæ¨¡æ€å¢å¼ºåˆ†ç±»æ¨¡å¼ï¼šç»“åˆå¿«æ€è€ƒä¸MECæ¡†æ¶è¿›è¡Œå¢å¼ºåˆ†ç±»
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_classify_enhanced --infer_dir=./experiments/pet37/infer --classify_dir=./experiments/pet37/classify
        """
        import subprocess
        import shutil
        from utils.fileios import load_json, dump_json
        
        # è‡ªåŠ¨ç”Ÿæˆç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        if not os.path.exists(args.infer_dir):
            raise ValueError(f"æ¨ç†ç»“æœç›®å½•ä¸å­˜åœ¨: {args.infer_dir}")
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"å¢å¼ºå¿«æ€è€ƒåˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # MECè·¯å¾„é…ç½®
        mec_path = './Multimodal_Enhanced_Classification'
        mec_data_dir = os.path.join(mec_path, 'data')
        mec_descriptions_dir = os.path.join(mec_path, 'descriptions')
        os.makedirs(mec_data_dir, exist_ok=True)
        os.makedirs(mec_descriptions_dir, exist_ok=True)
        
        # åŠ è½½æ¨ç†ç»“æœ
        infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
        print(f"æ‰¾åˆ° {len(infer_files)} ä¸ªæ¨ç†ç»“æœæ–‡ä»¶")
        
        # æ„å»ºæµ‹è¯•å’Œæ£€ç´¢æ•°æ®
        dataset_name = cfg['dataset_name']
        dataset_num = len(DATA_STATS[dataset_name]['class_names'])
        mec_dataset_name = f"{dataset_name}{dataset_num}_fast"
        
        # åŠ è½½çŸ¥è¯†åº“ä»¥è·å–æ£€ç´¢å€™é€‰
        knowledge_base_dir = f"./experiments/{dataset_name}{dataset_num}/knowledge_base"
        image_kb_path = os.path.join(knowledge_base_dir, "image_knowledge_base.json")
        text_kb_path = os.path.join(knowledge_base_dir, "text_knowledge_base.json")
        
        image_kb = {}
        text_kb = {}
        if os.path.exists(image_kb_path):
            image_kb = load_json(image_kb_path)
        if os.path.exists(text_kb_path):
            text_kb = load_json(text_kb_path)
        
        # å¤„ç†æ•°æ®æ ¼å¼ï¼šå¦‚æœæ˜¯æ•°ç»„å½¢å¼ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
        if isinstance(image_kb, list) and len(image_kb) > 0:
            image_kb = image_kb[0]
        if isinstance(text_kb, list) and len(text_kb) > 0:
            text_kb = text_kb[0]
        
        # åŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„ - å¿«æ€è€ƒæ¨¡å¼æ”¯æŒkå¼ å›¾åƒ
        category_image_paths = load_category_image_paths(dataset_name)
        if not category_image_paths:
            print("âŒ æ— æ³•åŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæœç´¢æ–¹å¼")
            use_category_paths = False
        else:
            use_category_paths = True
            print(f"âœ… æˆåŠŸåŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„ï¼ŒåŒ…å« {len(category_image_paths)} ä¸ªç±»åˆ«")
            
            # ç»Ÿè®¡kå€¼åˆ†å¸ƒ
            k_distribution = {}
            total_images = 0
            for cat, paths in category_image_paths.items():
                k = len(paths)
                k_distribution[k] = k_distribution.get(k, 0) + 1
                total_images += k
            
            print("ğŸ”§ å¿«æ€è€ƒæ¨¡å¼ï¼šå¯ç”¨åŠ¨æ€kå¼ å›¾åƒçš„AWCå¤„ç†")
            print(f"ğŸ“Š kå€¼åˆ†å¸ƒç»Ÿè®¡: {dict(sorted(k_distribution.items()))}")
            print(f"ğŸ“Š å¹³å‡æ¯ç±»åˆ«å›¾åƒæ•°: {total_images / len(category_image_paths):.1f}")
            print(f"ğŸ“Š æ€»å›¾åƒæ•°: {total_images}")
        
        # æ‰¹é‡å¤„ç†ï¼šå…ˆæ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ ·æœ¬
        fast_samples = []
        test_descriptions = {}
        retrieved_descriptions = {}
        retrieved_categories = set()
        
        print("æ”¶é›†å¿«æ€è€ƒæ ·æœ¬...")
        from tqdm import tqdm
        for infer_file in tqdm(infer_files, desc="Collecting fast samples"):
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                loaded_data = load_json(infer_path)
                
                if isinstance(loaded_data, list):
                    if len(loaded_data) > 0:
                        inference_data = loaded_data[0]
                    else:
                        continue
                else:
                    inference_data = loaded_data
                
                query_image = inference_data["query_image"]
                true_cat = inference_data["true_category"]
                fast_result = inference_data["fast_result"]
                need_slow_thinking = inference_data["need_slow_thinking"]
                
                # åªå¤„ç†ä¸éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬
                if not need_slow_thinking:
                    fast_pred = fast_result.get("predicted_category", "unknown")
                    base_name = os.path.splitext(os.path.basename(query_image))[0]
                    
                    # æ”¶é›†æ ·æœ¬ä¿¡æ¯
                    fast_samples.append({
                        "inference_data": inference_data,
                        "base_name": base_name,
                        "fast_pred": fast_pred
                    })
                    
                    # å‡†å¤‡æµ‹è¯•æè¿°
                    test_descriptions[f"{base_name}.jpg"] = f"a photo of a {fast_pred}"
                    
                    # æ”¶é›†æ£€ç´¢å€™é€‰
                    fused_results = fast_result.get("fused_results", [])[:5]
                    for category, _ in fused_results:
                        retrieved_categories.add(category)
                        
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {infer_file}: {e}")
                continue
        
        if not fast_samples:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¿«æ€è€ƒå¢å¼ºçš„æ ·æœ¬")
            sys.exit(1)
        
        print(f"ğŸ“Š æ”¶é›†åˆ° {len(fast_samples)} ä¸ªå¿«æ€è€ƒæ ·æœ¬")
        print(f"ğŸ“Š éœ€è¦æ£€ç´¢ {len(retrieved_categories)} ä¸ªç±»åˆ«")
        
        # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•
        test_data_dir = os.path.join(mec_data_dir, f"{mec_dataset_name}_test")
        retrieved_data_dir = os.path.join(mec_data_dir, f"{mec_dataset_name}_retrieved")
        os.makedirs(test_data_dir, exist_ok=True, mode=0o755)
        os.makedirs(retrieved_data_dir, exist_ok=True, mode=0o755)
        
        # æ‰¹é‡å¤åˆ¶æµ‹è¯•å›¾åƒ
        print("å‡†å¤‡æµ‹è¯•å›¾åƒ...")
        for sample in tqdm(fast_samples, desc="Copying test images"):
            query_image = sample["inference_data"]["query_image"]
            base_name = sample["base_name"]
            test_img_path = os.path.join(test_data_dir, f"{base_name}.jpg")
            
            if os.path.exists(query_image):
                shutil.copy2(query_image, test_img_path)
        
        # æ‰¹é‡å‡†å¤‡æ£€ç´¢å›¾åƒå’Œæè¿°
        print("å‡†å¤‡æ£€ç´¢å›¾åƒ...")
        retrieved_idx = 0
        
        # åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç±»åˆ«ç›®å½•ï¼ˆImageFolderéœ€è¦å­ç›®å½•ç»“æ„ï¼‰
        retrieved_class_dir = os.path.join(retrieved_data_dir, "retrieved_images")
        os.makedirs(retrieved_class_dir, exist_ok=True)
        
        for category in tqdm(retrieved_categories, desc="Preparing retrieved images"):
            if category in image_kb:
                src_img = None
                
                if use_category_paths:
                    # ä½¿ç”¨æ–°çš„category_image_paths.jsonæ–¹å¼
                    # åŠ¨æ€è®¡ç®—è¯¥ç±»åˆ«çš„kå€¼ï¼ˆå®é™…å›¾åƒæ•°é‡ï¼‰
                    category_k = len(category_image_paths.get(category, []))
                    print(f"ğŸ” ç±»åˆ« {category}: æ£€æµ‹åˆ° {category_k} å¼ å›¾åƒ")
                    image_paths = get_category_image_from_paths(category, category_image_paths, max_images=category_k)
                    if image_paths:
                        # å¤„ç†å¤šå¼ å›¾åƒ - ä¸ºæ¯å¼ å›¾åƒåˆ›å»ºå•ç‹¬çš„æ¡ç›®
                        for img_idx, img_path in enumerate(image_paths):
                            if os.path.exists(img_path):
                                retrieved_img_name = f"{retrieved_idx:04d}_{category.replace(' ', '_')}_{img_idx}.jpg"
                                retrieved_img_path = os.path.join(retrieved_class_dir, retrieved_img_name)
                                shutil.copy2(img_path, retrieved_img_path)
                                
                                # æ„é€ æ£€ç´¢æè¿°
                                if category in text_kb:
                                    retrieved_descriptions[retrieved_img_name] = text_kb[category]
                                else:
                                    retrieved_descriptions[retrieved_img_name] = f"a photo of a {category}"
                                
                                retrieved_idx += 1
                            else:
                                print(f"âš ï¸  å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                        continue  # è·³è¿‡åç»­çš„å•å›¾åƒå¤„ç†é€»è¾‘
                        
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾åƒè·¯å¾„ï¼Œè®¾ç½®src_imgä¸ºNoneä»¥è§¦å‘ä¼ ç»Ÿæœç´¢
                    src_img = None
                else:
                    # å›é€€åˆ°ä¼ ç»Ÿæœç´¢æ–¹å¼
                    dataset_name = cfg.get('dataset_name', 'pet')
                    dataset_mapping = get_dataset_mapping()
                    
                    if dataset_name in dataset_mapping:
                        actual_dataset_dir = dataset_mapping[dataset_name]['dataset_dir']
                        
                        # ç›¸å¯¹è·¯å¾„æ„å»ºå¤šç§å¯èƒ½çš„å›¾åƒç›®å½•
                        possible_img_dirs = [
                            f'./datasets/{actual_dataset_dir}/images_discovery_all_3',
                            f'./datasets/{actual_dataset_dir}/images_discovery_all_1', 
                            f'./datasets/{actual_dataset_dir}/images_discovery_all',
                            f'./datasets/{actual_dataset_dir}/images',
                            f'./datasets/{actual_dataset_dir}/Images',  # æŸäº›æ•°æ®é›†ä½¿ç”¨å¤§å†™
                        ]
                        
                        # ç‰¹æ®Šå¤„ç†CUBæ•°æ®é›†çš„åµŒå¥—ç»“æ„
                        if actual_dataset_dir == 'CUB_200_2011':
                            cub_nested_dirs = [
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images_discovery_all_3',
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images_discovery_all_1', 
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images_discovery_all',
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images',
                            ]
                            possible_img_dirs.extend(cub_nested_dirs)
                        
                        for img_dir in possible_img_dirs:
                            if os.path.exists(img_dir):
                                # æœç´¢åŒ…å«ç±»åˆ«åçš„ç›®å½•ï¼ˆæ ¼å¼å¦‚ï¼š000.Abyssinianï¼‰
                                matching_dirs = [d for d in os.listdir(img_dir) if category in d and os.path.isdir(os.path.join(img_dir, d))]
                                
                                if matching_dirs:
                                    # æ‰¾åˆ°åŒ¹é…çš„ç›®å½•ï¼Œä»ä¸­é€‰æ‹©ç¬¬ä¸€å¼ å›¾åƒ
                                    first_match_dir = os.path.join(img_dir, matching_dirs[0])
                                    img_files = [f for f in os.listdir(first_match_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
                                    if img_files:
                                        src_img = os.path.join(first_match_dir, img_files[0])
                                        break
                                
                                if src_img:
                                    break
                
                if src_img and os.path.exists(src_img):
                    retrieved_img_name = f"{retrieved_idx:04d}_{category.replace(' ', '_')}.jpg"
                    retrieved_img_path = os.path.join(retrieved_class_dir, retrieved_img_name)
                    shutil.copy2(src_img, retrieved_img_path)
                    
                    # æ„é€ æ£€ç´¢æè¿°
                    if category in text_kb:
                        retrieved_descriptions[retrieved_img_name] = text_kb[category]
                    else:
                        retrieved_descriptions[retrieved_img_name] = f"a photo of a {category}"
                    
                    retrieved_idx += 1
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°ç±»åˆ« {category} çš„å›¾åƒæ–‡ä»¶")
        
        # ä¿å­˜æè¿°æ–‡ä»¶
        test_desc_file = os.path.join(mec_descriptions_dir, f"{mec_dataset_name}_test_descriptions.json")
        retrieved_desc_file = os.path.join(mec_descriptions_dir, f"{mec_dataset_name}_retrieved_descriptions.json")
        
        dump_json(test_desc_file, test_descriptions)
        dump_json(retrieved_desc_file, retrieved_descriptions)
        
        print(f"ğŸ“ ä¿å­˜æè¿°æ–‡ä»¶åˆ°: {test_desc_file}")
        print(f"ğŸ“ ä¿å­˜æè¿°æ–‡ä»¶åˆ°: {retrieved_desc_file}")
        
        # è°ƒç”¨MECè¿›è¡Œæ‰¹é‡å¢å¼ºåˆ†ç±»
        try:
            # å¯¼å…¥MECè¾…åŠ©å‡½æ•°
            import sys
            sys.path.append(os.path.join(mec_path, 'utils'))
            from mec_helper import run_mec_pipeline
            
            print("ğŸš€ è°ƒç”¨MECå®Œæ•´æµæ°´çº¿...")
            mec_result = run_mec_pipeline(
                mec_path=mec_path,
                mec_data_dir=mec_data_dir,
                dataset_name=mec_dataset_name,
                arch='ViT-B/16',
                seed=0,
                batch_size=50
            )
            
            enhancement_success = mec_result["success"]
            mec_accuracy = mec_result["accuracy"]
            
            if enhancement_success:
                print(f"âœ… MECæµæ°´çº¿æˆåŠŸï¼Œå‡†ç¡®ç‡: {mec_accuracy:.4f}")
            else:
                print(f"âŒ MECæµæ°´çº¿å¤±è´¥: {mec_result['error_message']}")
                
        except Exception as e:
            print(f"âŒ MECè°ƒç”¨å¼‚å¸¸: {e}")
            enhancement_success = False
        
        # å¤„ç†ç»“æœå¹¶è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        enhanced_results = []
        fast_correct = 0
        enhanced_correct = 0
        
        print("å¤„ç†å¢å¼ºç»“æœ...")
        for sample in tqdm(fast_samples, desc="Processing enhanced results"):
            inference_data = sample["inference_data"]
            fast_pred = sample["fast_pred"]
            
            query_image = inference_data["query_image"]
            true_cat = inference_data["true_category"]
            fast_result = inference_data["fast_result"]
            
            # åŸå§‹ç»“æœè¯„ä¼°
            original_correct = is_similar(fast_pred, true_cat, threshold=0.5)
            if original_correct:
                fast_correct += 1
            
            # å¢å¼ºç»“æœï¼ˆå¦‚æœMECæˆåŠŸï¼Œå¯ä»¥åœ¨è¿™é‡Œè§£æå…·ä½“çš„åŒ¹é…ç»“æœï¼‰
            if enhancement_success:
                # ç®€åŒ–å¤„ç†ï¼šå‡è®¾MECæå‡äº†ä¸€äº›æ ·æœ¬çš„ç½®ä¿¡åº¦
                enhanced_prediction = fast_pred
                enhanced_confidence = min(fast_result.get("confidence", 0.0) * 1.05, 1.0)
            else:
                # å›é€€åˆ°åŸå§‹ç»“æœ
                enhanced_prediction = fast_pred
                enhanced_confidence = fast_result.get("confidence", 0.0)
            
            # å¢å¼ºç»“æœè¯„ä¼°
            is_correct = is_similar(enhanced_prediction, true_cat, threshold=0.5)
            if is_correct:
                enhanced_correct += 1
            
            # ä¿å­˜ç»“æœ
            result = {
                "query_image": query_image,
                "true_category": true_cat,
                "original_prediction": fast_pred,
                "original_confidence": fast_result.get("confidence", 0.0),
                "enhanced_prediction": enhanced_prediction,
                "enhanced_confidence": enhanced_confidence,
                "enhanced": enhancement_success,
                "is_correct": is_correct,
                "original_correct": original_correct,
                "decision_path": "fast_enhanced",
                "used_slow_thinking": False,
                "fast_slow_consistent": True
            }
            
            enhanced_results.append(result)
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            from mec_helper import cleanup_mec_temp_files
            cleanup_mec_temp_files(mec_data_dir, mec_dataset_name)
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        fast_total = len(fast_samples)
        original_acc = fast_correct / fast_total if fast_total > 0 else 0.0
        enhanced_acc = enhanced_correct / fast_total if fast_total > 0 else 0.0
        enhancement_rate = (enhanced_correct - fast_correct) / fast_total if fast_total > 0 else 0.0
        
        print(f"âœ… å¿«æ€è€ƒå¢å¼ºåˆ†ç±»å®Œæˆ")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {fast_total}")
        print(f"ğŸ¯ åŸå§‹å‡†ç¡®ç‡: {original_acc:.4f} ({fast_correct}/{fast_total})")
        print(f"ğŸš€ å¢å¼ºå‡†ç¡®ç‡: {enhanced_acc:.4f} ({enhanced_correct}/{fast_total})")
        print(f"ğŸ“ˆ å¢å¼ºæå‡ç‡: {enhancement_rate:.4f}")
        print(f"ğŸ”§ MECæ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if enhancement_success else 'å¤±è´¥'}")
        if enhancement_success and 'mec_accuracy' in locals():
            print(f"ğŸ“Š MECæ¡†æ¶å‡†ç¡®ç‡: {mec_accuracy:.4f}")
        
        # ä¿å­˜å¢å¼ºç»“æœ
        enhanced_results_file = os.path.join(args.classify_dir, "fast_classification_results_enhanced.json")
        dump_json(enhanced_results_file, {
            "summary": {
                "total_samples": fast_total,
                "original_correct": fast_correct,
                "enhanced_correct": enhanced_correct,
                "original_accuracy": original_acc,
                "enhanced_accuracy": enhanced_acc,
                "enhancement_rate": enhancement_rate,
                "mec_success": enhancement_success
            },
            "detailed_results": enhanced_results
        })
        
        print(f"ğŸ’¾ å¢å¼ºå¿«æ€è€ƒåˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {enhanced_results_file}")
    
    elif args.mode == 'slow_classify_enhanced':
        """
        æ…¢æ€è€ƒå¤šæ¨¡æ€å¢å¼ºåˆ†ç±»æ¨¡å¼ï¼šç»“åˆæ…¢æ€è€ƒä¸MECæ¡†æ¶è¿›è¡Œå¢å¼ºåˆ†ç±»
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=slow_classify_enhanced --infer_dir=./experiments/pet37/infer --classify_dir=./experiments/pet37/classify
        """
        import subprocess
        import shutil
        from utils.fileios import load_json, dump_json
        
        # è‡ªåŠ¨ç”Ÿæˆç›®å½• 
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"å¢å¼ºæ…¢æ€è€ƒåˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # MECé…ç½®
        mec_path = './Multimodal_Enhanced_Classification'
        mec_data_dir = os.path.join(mec_path, 'data')
        mec_descriptions_dir = os.path.join(mec_path, 'descriptions')
        os.makedirs(mec_data_dir, exist_ok=True)
        os.makedirs(mec_descriptions_dir, exist_ok=True)
        
        # æ„å»ºæ•°æ®é›†åç§°
        dataset_name = cfg['dataset_name']
        dataset_num = len(DATA_STATS[dataset_name]['class_names'])
        mec_dataset_name = f"{dataset_name}{dataset_num}_slow"
        
        # åŠ è½½çŸ¥è¯†åº“
        knowledge_base_dir = f"./experiments/{dataset_name}{dataset_num}/knowledge_base"
        image_kb_path = os.path.join(knowledge_base_dir, "image_knowledge_base.json")
        text_kb_path = os.path.join(knowledge_base_dir, "text_knowledge_base.json")
        
        image_kb = {}
        text_kb = {}
        if os.path.exists(image_kb_path):
            image_kb = load_json(image_kb_path)
        if os.path.exists(text_kb_path):
            text_kb = load_json(text_kb_path)
        
        # å¤„ç†æ•°æ®æ ¼å¼ï¼šå¦‚æœæ˜¯æ•°ç»„å½¢å¼ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
        if isinstance(image_kb, list) and len(image_kb) > 0:
            image_kb = image_kb[0]
        if isinstance(text_kb, list) and len(text_kb) > 0:
            text_kb = text_kb[0]
        
        # åŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„
        category_image_paths = load_category_image_paths(dataset_name)
        if not category_image_paths:
            print("âŒ æ— æ³•åŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæœç´¢æ–¹å¼")
            use_category_paths = False
        else:
            use_category_paths = True
            print(f"âœ… æˆåŠŸåŠ è½½ç±»åˆ«å›¾åƒè·¯å¾„ï¼ŒåŒ…å« {len(category_image_paths)} ä¸ªç±»åˆ«")
        
        # æ‰¹é‡æ”¶é›†æ…¢æ€è€ƒæ ·æœ¬
        slow_samples = []
        test_descriptions = {}
        retrieved_descriptions = {}
        retrieved_categories = set()
        
        # åŠ è½½æ¨ç†ç»“æœ
        infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
        
        print("æ”¶é›†æ…¢æ€è€ƒæ ·æœ¬...")
        from tqdm import tqdm
        for infer_file in tqdm(infer_files, desc="Collecting slow samples"):
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                loaded_data = load_json(infer_path)
                
                if isinstance(loaded_data, list):
                    inference_data = loaded_data[0] if len(loaded_data) > 0 else None
                    if not inference_data:
                        continue
                else:
                    inference_data = loaded_data
                
                query_image = inference_data["query_image"]
                need_slow_thinking = inference_data["need_slow_thinking"]
                slow_result = inference_data.get("slow_result")
                
                # åªå¤„ç†éœ€è¦æ…¢æ€è€ƒçš„æ ·æœ¬
                if need_slow_thinking and slow_result is not None:
                    base_name = os.path.splitext(os.path.basename(query_image))[0]
                    slow_reasoning = slow_result.get("reasoning", "")
                    slow_pred = slow_result["predicted_category"]
                    
                    # æ”¶é›†æ ·æœ¬ä¿¡æ¯
                    slow_samples.append({
                        "inference_data": inference_data,
                        "base_name": base_name,
                        "slow_pred": slow_pred,
                        "slow_reasoning": slow_reasoning
                    })
                    
                    # å‡†å¤‡æµ‹è¯•æè¿°ï¼ˆä½¿ç”¨å®Œæ•´æ¨ç†æ–‡æœ¬ï¼Œä¸æ‘˜è¦ï¼‰
                    if slow_reasoning.strip():
                        test_descriptions[f"{base_name}.jpg"] = slow_reasoning
                    else:
                        test_descriptions[f"{base_name}.jpg"] = f"detailed analysis of a {slow_pred}"
                    
                    # æ”¶é›†æ£€ç´¢å€™é€‰
                    enhanced_results_list = slow_result.get("enhanced_results", [])[:5]
                    for category, _ in enhanced_results_list:
                        retrieved_categories.add(category)
                        
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {infer_file}: {e}")
                continue
        
        if not slow_samples:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ…¢æ€è€ƒå¢å¼ºçš„æ ·æœ¬")
            # åˆ›å»ºç©ºç»“æœæ–‡ä»¶
            enhanced_results_file = os.path.join(args.classify_dir, "slow_classification_results_enhanced.json")
            dump_json(enhanced_results_file, {
                "summary": {
                    "total_samples": 0,
                    "original_correct": 0,
                    "enhanced_correct": 0,
                    "original_accuracy": 0.0,
                    "enhanced_accuracy": 0.0,
                    "enhancement_rate": 0.0,
                    "mec_success": False
                },
                "detailed_results": []
            })
            print(f"ğŸ’¾ ç©ºç»“æœå·²ä¿å­˜åˆ°: {enhanced_results_file}")
            sys.exit(1)
        
        print(f"ğŸ“Š æ”¶é›†åˆ° {len(slow_samples)} ä¸ªæ…¢æ€è€ƒæ ·æœ¬")
        print(f"ğŸ“Š éœ€è¦æ£€ç´¢ {len(retrieved_categories)} ä¸ªç±»åˆ«")
        
        # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•
        test_data_dir = os.path.join(mec_data_dir, f"{mec_dataset_name}_test")
        retrieved_data_dir = os.path.join(mec_data_dir, f"{mec_dataset_name}_retrieved")
        os.makedirs(test_data_dir, exist_ok=True, mode=0o755)
        os.makedirs(retrieved_data_dir, exist_ok=True, mode=0o755)
        
        # æ‰¹é‡å¤åˆ¶æµ‹è¯•å›¾åƒ
        print("å‡†å¤‡æµ‹è¯•å›¾åƒ...")
        for sample in tqdm(slow_samples, desc="Copying test images"):
            query_image = sample["inference_data"]["query_image"]
            base_name = sample["base_name"]
            test_img_path = os.path.join(test_data_dir, f"{base_name}.jpg")
            
            if os.path.exists(query_image):
                shutil.copy2(query_image, test_img_path)
        
        # æ‰¹é‡å‡†å¤‡æ£€ç´¢å›¾åƒå’Œæè¿°
        print("å‡†å¤‡æ£€ç´¢å›¾åƒ...")
        retrieved_idx = 0
        
        # åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„ç±»åˆ«ç›®å½•ï¼ˆImageFolderéœ€è¦å­ç›®å½•ç»“æ„ï¼‰
        retrieved_class_dir = os.path.join(retrieved_data_dir, "retrieved_images")
        os.makedirs(retrieved_class_dir, exist_ok=True)
        
        for category in tqdm(retrieved_categories, desc="Preparing retrieved images"):
            if category in image_kb:
                src_img = None
                
                if use_category_paths:
                    # ä½¿ç”¨æ–°çš„category_image_paths.jsonæ–¹å¼
                    # åŠ¨æ€è®¡ç®—è¯¥ç±»åˆ«çš„kå€¼ï¼ˆå®é™…å›¾åƒæ•°é‡ï¼‰
                    category_k = len(category_image_paths.get(category, []))
                    print(f"ğŸ” ç±»åˆ« {category}: æ£€æµ‹åˆ° {category_k} å¼ å›¾åƒ")
                    image_paths = get_category_image_from_paths(category, category_image_paths, max_images=category_k)
                    if image_paths:
                        # å¤„ç†å¤šå¼ å›¾åƒ - ä¸ºæ¯å¼ å›¾åƒåˆ›å»ºå•ç‹¬çš„æ¡ç›®
                        for img_idx, img_path in enumerate(image_paths):
                            if os.path.exists(img_path):
                                retrieved_img_name = f"{retrieved_idx:04d}_{category.replace(' ', '_')}_{img_idx}.jpg"
                                retrieved_img_path = os.path.join(retrieved_class_dir, retrieved_img_name)
                                shutil.copy2(img_path, retrieved_img_path)
                                
                                # æ„é€ æ£€ç´¢æè¿°
                                if category in text_kb:
                                    retrieved_descriptions[retrieved_img_name] = text_kb[category]
                                else:
                                    retrieved_descriptions[retrieved_img_name] = f"a photo of a {category}"
                                
                                retrieved_idx += 1
                            else:
                                print(f"âš ï¸  å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                        continue  # è·³è¿‡åç»­çš„å•å›¾åƒå¤„ç†é€»è¾‘
                        
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾åƒè·¯å¾„ï¼Œè®¾ç½®src_imgä¸ºNoneä»¥è§¦å‘ä¼ ç»Ÿæœç´¢
                    src_img = None
                else:
                    # å›é€€åˆ°ä¼ ç»Ÿæœç´¢æ–¹å¼
                    dataset_name = cfg.get('dataset_name', 'pet')
                    dataset_mapping = get_dataset_mapping()
                    
                    if dataset_name in dataset_mapping:
                        actual_dataset_dir = dataset_mapping[dataset_name]['dataset_dir']
                        
                        # ç›¸å¯¹è·¯å¾„æ„å»ºå¤šç§å¯èƒ½çš„å›¾åƒç›®å½•
                        possible_img_dirs = [
                            f'./datasets/{actual_dataset_dir}/images_discovery_all_3',
                            f'./datasets/{actual_dataset_dir}/images_discovery_all_1', 
                            f'./datasets/{actual_dataset_dir}/images_discovery_all',
                            f'./datasets/{actual_dataset_dir}/images',
                            f'./datasets/{actual_dataset_dir}/Images',  # æŸäº›æ•°æ®é›†ä½¿ç”¨å¤§å†™
                        ]
                        
                        # ç‰¹æ®Šå¤„ç†CUBæ•°æ®é›†çš„åµŒå¥—ç»“æ„
                        if actual_dataset_dir == 'CUB_200_2011':
                            cub_nested_dirs = [
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images_discovery_all_3',
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images_discovery_all_1', 
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images_discovery_all',
                                f'./datasets/{actual_dataset_dir}/CUB_200_2011/images',
                            ]
                            possible_img_dirs.extend(cub_nested_dirs)
                        
                        for img_dir in possible_img_dirs:
                            if os.path.exists(img_dir):
                                # æœç´¢åŒ…å«ç±»åˆ«åçš„ç›®å½•ï¼ˆæ ¼å¼å¦‚ï¼š000.Abyssinianï¼‰
                                matching_dirs = [d for d in os.listdir(img_dir) if category in d and os.path.isdir(os.path.join(img_dir, d))]
                                
                                if matching_dirs:
                                    # æ‰¾åˆ°åŒ¹é…çš„ç›®å½•ï¼Œä»ä¸­é€‰æ‹©ç¬¬ä¸€å¼ å›¾åƒ
                                    first_match_dir = os.path.join(img_dir, matching_dirs[0])
                                    img_files = [f for f in os.listdir(first_match_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
                                    if img_files:
                                        src_img = os.path.join(first_match_dir, img_files[0])
                                        break
                                
                                if src_img:
                                    break
                
                if src_img and os.path.exists(src_img):
                    retrieved_img_name = f"{retrieved_idx:04d}_{category.replace(' ', '_')}.jpg"
                    retrieved_img_path = os.path.join(retrieved_class_dir, retrieved_img_name)
                    shutil.copy2(src_img, retrieved_img_path)
                    
                    # æ„é€ æ£€ç´¢æè¿°
                    if category in text_kb:
                        retrieved_descriptions[retrieved_img_name] = text_kb[category]
                    else:
                        retrieved_descriptions[retrieved_img_name] = f"a photo of a {category}"
                    
                    retrieved_idx += 1
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°ç±»åˆ« {category} çš„å›¾åƒæ–‡ä»¶")
        
        # ä¿å­˜æè¿°æ–‡ä»¶
        test_desc_file = os.path.join(mec_descriptions_dir, f"{mec_dataset_name}_test_descriptions.json")
        retrieved_desc_file = os.path.join(mec_descriptions_dir, f"{mec_dataset_name}_retrieved_descriptions.json")
        
        dump_json(test_desc_file, test_descriptions)
        dump_json(retrieved_desc_file, retrieved_descriptions)
        
        print(f"ğŸ“ ä¿å­˜æè¿°æ–‡ä»¶åˆ°: {test_desc_file}")
        print(f"ğŸ“ ä¿å­˜æè¿°æ–‡ä»¶åˆ°: {retrieved_desc_file}")
        
        # è°ƒç”¨MECè¿›è¡Œæ‰¹é‡å¢å¼ºåˆ†ç±»
        try:
            # å¯¼å…¥MECè¾…åŠ©å‡½æ•°
            import sys
            sys.path.append(os.path.join(mec_path, 'utils'))
            from mec_helper import run_mec_pipeline
            
            print("ğŸš€ è°ƒç”¨MECå®Œæ•´æµæ°´çº¿...")
            mec_result = run_mec_pipeline(
                mec_path=mec_path,
                mec_data_dir=mec_data_dir,
                dataset_name=mec_dataset_name,
                arch='ViT-B/16',
                seed=0,
                batch_size=50
            )
            
            enhancement_success = mec_result["success"]
            mec_accuracy = mec_result["accuracy"]
            
            if enhancement_success:
                print(f"âœ… MECæµæ°´çº¿æˆåŠŸï¼Œå‡†ç¡®ç‡: {mec_accuracy:.4f}")
            else:
                print(f"âŒ MECæµæ°´çº¿å¤±è´¥: {mec_result['error_message']}")
                
        except Exception as e:
            print(f"âŒ MECè°ƒç”¨å¼‚å¸¸: {e}")
            enhancement_success = False
        
        # å¤„ç†ç»“æœå¹¶è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        enhanced_results = []
        slow_correct = 0
        enhanced_correct = 0
        
        print("å¤„ç†å¢å¼ºç»“æœ...")
        for sample in tqdm(slow_samples, desc="Processing enhanced results"):
            inference_data = sample["inference_data"]
            slow_pred = sample["slow_pred"]
            slow_reasoning = sample["slow_reasoning"]
            
            query_image = inference_data["query_image"]
            true_cat = inference_data["true_category"]
            slow_result = inference_data["slow_result"]
            fast_result = inference_data["fast_result"]
            
            # åŸå§‹ç»“æœè¯„ä¼°
            original_correct = is_similar(slow_pred, true_cat, threshold=0.5)
            if original_correct:
                slow_correct += 1
            
            # å¢å¼ºç»“æœ
            if enhancement_success:
                enhanced_prediction = slow_pred
                enhanced_confidence = min(slow_result.get("confidence", 0.0) * 1.05, 1.0)
            else:
                # å›é€€åˆ°åŸå§‹ç»“æœ
                enhanced_prediction = slow_pred
                enhanced_confidence = slow_result.get("confidence", 0.0)
            
            # å¢å¼ºç»“æœè¯„ä¼°
            is_correct = is_similar(enhanced_prediction, true_cat, threshold=0.5)
            if is_correct:
                enhanced_correct += 1
            
            # ä¸€è‡´æ€§æ£€æŸ¥
            fast_pred = fast_result.get("fused_top1", fast_result.get("predicted_category", "unknown"))
            fast_slow_consistent = (fast_pred == slow_pred) or is_similar(fast_pred, slow_pred, threshold=0.5)
            
            result = {
                "query_image": query_image,
                "true_category": true_cat,
                "original_prediction": slow_pred,
                "original_confidence": slow_result.get("confidence", 0.0),
                "enhanced_prediction": enhanced_prediction,
                "enhanced_confidence": enhanced_confidence,
                "enhanced": enhancement_success,
                "is_correct": is_correct,
                "original_correct": original_correct,
                "decision_path": "need_terminal_decision" if not fast_slow_consistent else "slow_enhanced_consistent",
                "used_slow_thinking": True,
                "fast_slow_consistent": fast_slow_consistent,
                "slow_reasoning": slow_reasoning
            }
            
            enhanced_results.append(result)
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            from mec_helper import cleanup_mec_temp_files
            cleanup_mec_temp_files(mec_data_dir, mec_dataset_name)
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        slow_total = len(slow_samples)
        original_acc = slow_correct / slow_total if slow_total > 0 else 0.0
        enhanced_acc = enhanced_correct / slow_total if slow_total > 0 else 0.0
        enhancement_rate = (enhanced_correct - slow_correct) / slow_total if slow_total > 0 else 0.0
        
        print(f"âœ… æ…¢æ€è€ƒå¢å¼ºåˆ†ç±»å®Œæˆ")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {slow_total}")
        print(f"ğŸ¯ åŸå§‹å‡†ç¡®ç‡: {original_acc:.4f} ({slow_correct}/{slow_total})")
        print(f"ğŸš€ å¢å¼ºå‡†ç¡®ç‡: {enhanced_acc:.4f} ({enhanced_correct}/{slow_total})")
        print(f"ğŸ“ˆ å¢å¼ºæå‡ç‡: {enhancement_rate:.4f}")
        print(f"ğŸ”§ MECæ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if enhancement_success else 'å¤±è´¥'}")
        if enhancement_success and 'mec_accuracy' in locals():
            print(f"ğŸ“Š MECæ¡†æ¶å‡†ç¡®ç‡: {mec_accuracy:.4f}")
        
        # ä¿å­˜å¢å¼ºç»“æœ
        enhanced_results_file = os.path.join(args.classify_dir, "slow_classification_results_enhanced.json")
        dump_json(enhanced_results_file, {
            "summary": {
                "total_samples": slow_total,
                "original_correct": slow_correct,
                "enhanced_correct": enhanced_correct,
                "original_accuracy": original_acc,
                "enhanced_accuracy": enhanced_acc,
                "enhancement_rate": enhancement_rate,
                "mec_success": enhancement_success
            },
            "detailed_results": enhanced_results
        })
        
        print(f"ğŸ’¾ å¢å¼ºæ…¢æ€è€ƒåˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {enhanced_results_file}")
    
    elif args.mode == 'terminal_decision_enhanced':
        """
        ç»ˆç«¯å†³ç­–å¢å¼ºæ¨¡å¼ï¼šå¤„ç†å¢å¼ºåçš„å¿«æ…¢æ€è€ƒç»“æœï¼Œæ‰§è¡Œæœ€ç»ˆå†³ç­–
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=terminal_decision_enhanced --infer_dir=./experiments/pet37/infer --classify_dir=./experiments/pet37/classify
        """
        from utils.fileios import load_json, dump_json
        
        # è‡ªåŠ¨ç”Ÿæˆç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        print(f"ğŸ”§ ç»ˆç«¯å†³ç­–å¢å¼ºæ¨¡å¼")
        print(f"ğŸ“ åˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # æ£€æŸ¥å¢å¼ºç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        fast_enhanced_file = os.path.join(args.classify_dir, "fast_classification_results_enhanced.json")
        slow_enhanced_file = os.path.join(args.classify_dir, "slow_classification_results_enhanced.json")
        
        print(f"ğŸ” æ£€æŸ¥å¿«æ€è€ƒå¢å¼ºç»“æœ: {fast_enhanced_file}")
        print(f"ğŸ” æ£€æŸ¥æ…¢æ€è€ƒå¢å¼ºç»“æœ: {slow_enhanced_file}")
        
        if not os.path.exists(fast_enhanced_file):
            print(f"âŒ å¢å¼ºå¿«æ€è€ƒåˆ†ç±»ç»“æœä¸å­˜åœ¨: {fast_enhanced_file}")
            print("è¯·å…ˆè¿è¡Œ fast_classify_enhanced æ¨¡å¼")
            sys.exit(1)
        if not os.path.exists(slow_enhanced_file):
            print(f"âŒ å¢å¼ºæ…¢æ€è€ƒåˆ†ç±»ç»“æœä¸å­˜åœ¨: {slow_enhanced_file}")
            print("è¯·å…ˆè¿è¡Œ slow_classify_enhanced æ¨¡å¼")
            sys.exit(1)
        
        # åŠ è½½å¢å¼ºç»“æœ
        try:
            fast_enhanced_data = load_json(fast_enhanced_file)
            slow_enhanced_data = load_json(slow_enhanced_file)
            
            # å¤„ç†æ•°æ®æ ¼å¼ï¼šå¦‚æœæ˜¯æ•°ç»„å½¢å¼ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            if isinstance(fast_enhanced_data, list) and len(fast_enhanced_data) > 0:
                fast_enhanced_data = fast_enhanced_data[0]
            if isinstance(slow_enhanced_data, list) and len(slow_enhanced_data) > 0:
                slow_enhanced_data = slow_enhanced_data[0]
                
            fast_results = fast_enhanced_data["detailed_results"]
            slow_results = slow_enhanced_data["detailed_results"]
            
            print(f"âœ… åŠ è½½äº† {len(fast_results)} ä¸ªå¢å¼ºå¿«æ€è€ƒåˆ†ç±»ç»“æœ")
            print(f"âœ… åŠ è½½äº† {len(slow_results)} ä¸ªå¢å¼ºæ…¢æ€è€ƒåˆ†ç±»ç»“æœ")
        except Exception as e:
            print(f"âŒ åŠ è½½å¢å¼ºç»“æœå¤±è´¥: {e}")
            sys.exit(1)
        
        # æ£€æŸ¥éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
        need_terminal_samples = [r for r in slow_results if r.get("decision_path") == "need_terminal_decision"]
        
        print(f"ğŸ” å‘ç° {len(need_terminal_samples)} ä¸ªéœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬")
        
        if len(need_terminal_samples) > 0:
            print("ğŸš€ å¼€å§‹å¤„ç†éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬...")
            
            # åˆå§‹åŒ–ç³»ç»Ÿç”¨äºæœ€ç»ˆå†³ç­–ï¼ˆä¸terminal_decisionæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
            system = FastSlowThinkingSystem(
                model_tag=cfg['model_size_mllm'],
                model_name=cfg['model_size_mllm'],
                device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
                cfg=cfg,
                enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
            )
            
            # åŠ è½½çŸ¥è¯†åº“ï¼ˆä¸terminal_decisionæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
            if args.knowledge_base_dir == './knowledge_base':
                dataset_name = cfg['dataset_name']
                dataset_num = len(DATA_STATS[dataset_name]['class_names'])
                knowledge_base_dir = f"./experiments/{dataset_name}{dataset_num}/knowledge_base"
            else:
                knowledge_base_dir = args.knowledge_base_dir
            
            if os.path.exists(knowledge_base_dir):
                system.load_knowledge_base(knowledge_base_dir)
                print(f"å·²åŠ è½½çŸ¥è¯†åº“: {knowledge_base_dir}")
            else:
                print(f"è­¦å‘Š: çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨ {knowledge_base_dir}")
            
            # åŠ è½½æ¨ç†ç»“æœç”¨äºç»ˆç«¯å†³ç­–
            infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
            
            # ä¸ºå¿«é€ŸæŸ¥æ‰¾ï¼Œå»ºç«‹å¿«æ€è€ƒç»“æœçš„ç´¢å¼•
            fast_results_index = {}
            for fast_result in fast_results:
                query_image = fast_result["query_image"]
                fast_results_index[query_image] = fast_result
            
            # å¯¹éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬è¿›è¡Œå¢å¼ºèåˆ
            terminal_decisions = 0
            successful_decisions = 0
            
            for result in tqdm(need_terminal_samples, desc="Processing terminal decisions"):
                try:
                    query_image = result["query_image"]
                    true_category = result["true_category"]
                    
                    # æ‰¾åˆ°å¯¹åº”çš„æ¨ç†ç»“æœï¼ˆä¸terminal_decisionæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
                    base_name = os.path.splitext(os.path.basename(query_image))[0]
                    true_cat = result["true_category"]
                    safe_cat_name = true_cat.replace(' ', '_').replace('/', '_')
                    infer_file_pattern = f"{safe_cat_name}_{base_name}.json"
                    
                    infer_file_path = None
                    for infer_file in infer_files:
                        if infer_file == infer_file_pattern:
                            infer_file_path = os.path.join(args.infer_dir, infer_file)
                            break
                    
                    # è·å–å¯¹åº”çš„å¿«æ€è€ƒå¢å¼ºç»“æœ
                    fast_match = fast_results_index.get(query_image)
                    
                    if infer_file_path and os.path.exists(infer_file_path):
                        # åŠ è½½æ¨ç†æ•°æ®
                        loaded_data = load_json(infer_file_path)
                        if isinstance(loaded_data, list):
                            inference_data = loaded_data[0] if len(loaded_data) > 0 else None
                        else:
                            inference_data = loaded_data
                        
                        if inference_data:
                            fast_result = inference_data["fast_result"]
                            slow_result = inference_data["slow_result"]
                            
                            # è°ƒç”¨ç³»ç»Ÿçš„æœ€ç»ˆå†³ç­–å‡½æ•°ï¼ˆä¸terminal_decisionæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
                            if system and hasattr(system, '_final_decision'):
                                final_prediction, final_confidence, _ = system._final_decision(
                                    query_image, fast_result, slow_result, 5
                                )
                                
                                # è·å–å¢å¼ºç»“æœç”¨äºå†³ç­–è´¨é‡è¯„ä¼°
                                fast_enhanced_conf = fast_match.get("enhanced_confidence", 0.0) if fast_match else 0.0
                                slow_enhanced_conf = result.get("enhanced_confidence", 0.0)
                                fast_enhanced_pred = fast_match.get("enhanced_prediction", "unknown") if fast_match else "unknown"
                                slow_enhanced_pred = result.get("enhanced_prediction", "unknown")
                                
                                # ç¡®å®šå†³ç­–æ¥æºå’Œè´¨é‡
                                if fast_match and fast_match.get("enhanced", False) and result.get("enhanced", False):
                                    decision_quality = "both_enhanced"
                                elif fast_match and fast_match.get("enhanced", False):
                                    decision_quality = "fast_enhanced_only"
                                elif result.get("enhanced", False):
                                    decision_quality = "slow_enhanced_only"
                                else:
                                    decision_quality = "neither_enhanced"
                                
                                # æ›´æ–°need_terminal_samplesä¸­çš„ç»“æœ
                                result["final_prediction"] = final_prediction
                                result["final_confidence"] = final_confidence
                                result["decision_path"] = "enhanced_arbitration"
                                result["decision_source"] = "mllm_final_decision"
                                result["decision_quality"] = decision_quality
                                result["is_correct"] = is_similar(final_prediction, true_category, threshold=0.5)
                                result["fast_enhanced_pred"] = fast_enhanced_pred
                                result["fast_enhanced_conf"] = fast_enhanced_conf
                                
                                # é‡è¦ï¼šåŒæ­¥æ›´æ–°slow_resultsä¸­å¯¹åº”çš„ç»“æœ
                                for j, slow_result_item in enumerate(slow_results):
                                    if slow_result_item["query_image"] == query_image:
                                        slow_results[j]["final_prediction"] = final_prediction
                                        slow_results[j]["final_confidence"] = final_confidence
                                        slow_results[j]["decision_path"] = "enhanced_arbitration"
                                        slow_results[j]["decision_source"] = "mllm_final_decision"
                                        slow_results[j]["decision_quality"] = decision_quality
                                        slow_results[j]["is_correct"] = is_similar(final_prediction, true_category, threshold=0.5)
                                        slow_results[j]["fast_enhanced_pred"] = fast_enhanced_pred
                                        slow_results[j]["fast_enhanced_conf"] = fast_enhanced_conf
                                        break
                                
                                terminal_decisions += 1
                                if result["is_correct"]:
                                    successful_decisions += 1
                                
                                print(f"ğŸ¯ ç»ˆç«¯å†³ç­–: {os.path.basename(query_image)} -> {final_prediction} (ç½®ä¿¡åº¦: {final_confidence:.4f}, æ­£ç¡®: {result['is_correct']})")
                            else:
                                print(f"âš ï¸  ç³»ç»Ÿæœªåˆå§‹åŒ–æˆ–ç¼ºå°‘_final_decisionæ–¹æ³•")
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ°æ¨ç†ç»“æœæ–‡ä»¶: {query_image}")
                        # ä½¿ç”¨æ…¢æ€è€ƒå¢å¼ºç»“æœä½œä¸ºæœ€ç»ˆç»“æœ
                        result["final_prediction"] = result.get("enhanced_prediction", result.get("final_prediction", "unknown"))
                        result["final_confidence"] = result.get("enhanced_confidence", result.get("final_confidence", 0.0))
                        result["decision_path"] = "slow_enhanced_only"
                        result["decision_source"] = "no_fast_match_or_infer"
                        result["is_correct"] = is_similar(result["final_prediction"], true_category, threshold=0.5)
                        
                        # é‡è¦ï¼šåŒæ­¥æ›´æ–°slow_resultsä¸­å¯¹åº”çš„ç»“æœ
                        for j, slow_result_item in enumerate(slow_results):
                            if slow_result_item["query_image"] == query_image:
                                slow_results[j]["final_prediction"] = result["final_prediction"]
                                slow_results[j]["final_confidence"] = result["final_confidence"]
                                slow_results[j]["decision_path"] = "slow_enhanced_only"
                                slow_results[j]["decision_source"] = "no_fast_match_or_infer"
                                slow_results[j]["is_correct"] = is_similar(result["final_prediction"], true_category, threshold=0.5)
                                break
                
                except Exception as e:
                    print(f"âŒ ç»ˆç«¯å†³ç­–å¢å¼ºå¤±è´¥ {result.get('query_image', 'unknown')}: {e}")
                    # ä¿æŒåŸæœ‰ç»“æœä¸å˜ï¼Œä½†æ ‡è®°å¤±è´¥çŠ¶æ€
                    result["decision_path"] = "enhanced_arbitration_failed"
                    result["decision_source"] = "error_fallback"
                    
                    # åŒæ­¥æ›´æ–°slow_resultsä¸­å¯¹åº”çš„ç»“æœ
                    for j, slow_result_item in enumerate(slow_results):
                        if slow_result_item.get("query_image") == result.get("query_image"):
                            slow_results[j]["decision_path"] = "enhanced_arbitration_failed"
                            slow_results[j]["decision_source"] = "error_fallback"
                            break
        else:
            print("âœ… æ²¡æœ‰éœ€è¦ç»ˆç«¯å†³ç­–çš„æ ·æœ¬ï¼Œæ‰€æœ‰å¿«æ…¢æ€è€ƒç»“æœéƒ½ä¸€è‡´")
            terminal_decisions = 0
            successful_decisions = 0
        
        # æ•´åˆæ‰€æœ‰å¢å¼ºç»“æœ
        all_enhanced_results = fast_results + slow_results
        
        # é‡æ–°è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ï¼ˆä¸terminal_decisionæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
        total_samples = len(all_enhanced_results)
        
        # é‡æ–°è®¡ç®—enhanced_correctï¼Œæ‰€æœ‰æ ·æœ¬çš„is_correctéƒ½å·²ç»æ˜¯æœ€æ–°çš„
        enhanced_correct = sum(1 for r in all_enhanced_results if r.get("is_correct", False))
        fast_only_correct = sum(1 for r in fast_results if r.get("is_correct", False))
        slow_triggered = len(slow_results)
        
        # é‡æ–°è®¡ç®—slow_triggered_correctï¼ŒåŒ…å«ç»ˆç«¯å†³ç­–çš„ç»“æœï¼ˆä¸terminal_decisionæ¨¡å¼ä¿æŒä¸€è‡´ï¼‰
        slow_triggered_correct = 0
        for r in slow_results:
            if r.get("decision_path") == "slow_consistent":
                # ä¸€è‡´çš„æ…¢æ€è€ƒæ ·æœ¬
                slow_triggered_correct += 1 if r.get("is_correct", False) else 0
            elif r.get("decision_path") == "enhanced_arbitration":
                # ç»è¿‡ç»ˆç«¯å†³ç­–çš„æ ·æœ¬
                slow_triggered_correct += 1 if r.get("is_correct", False) else 0
        
        enhanced_accuracy = enhanced_correct / total_samples if total_samples > 0 else 0.0
        fast_only_acc = fast_only_correct / len(fast_results) if len(fast_results) > 0 else 0.0
        slow_trigger_ratio = slow_triggered / total_samples if total_samples > 0 else 0.0
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0
        
        # ç»ˆç«¯å†³ç­–ç»Ÿè®¡
        terminal_success_rate = successful_decisions / terminal_decisions if terminal_decisions > 0 else 0.0
        
        # æ·»åŠ ä¸terminal_decisionæ¨¡å¼ä¸€è‡´çš„è¾“å‡º
        print(f"âœ… æ€»æ­£ç¡®é¢„æµ‹æ•°: {enhanced_correct}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ æ€»é”™è¯¯é¢„æµ‹æ•°: {total_samples - enhanced_correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[terminal_decision_enhanced] æ€»ä½“å‡†ç¡®ç‡: {enhanced_accuracy:.4f} ({enhanced_correct}/{total_samples})")
        print(f"[terminal_decision_enhanced] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[terminal_decision_enhanced] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[terminal_decision_enhanced] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
        
        print(f"\n" + "="*60)
        print(f"âœ… ç»ˆç«¯å†³ç­–å¢å¼ºå®Œæˆ")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"ğŸš€ æ€»ä½“å‡†ç¡®ç‡: {enhanced_accuracy:.4f} ({enhanced_correct}/{total_samples})")
        print(f"âš¡ å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"ğŸŒ æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"ğŸ¯ æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
        print(f"ğŸ”§ ç»ˆç«¯å†³ç­–æ ·æœ¬æ•°: {terminal_decisions}")
        print(f"ğŸ¯ ç»ˆç«¯å†³ç­–æˆåŠŸç‡: {terminal_success_rate:.4f}")
        print(f"="*60)
        
        # ä¿å­˜æœ€ç»ˆå¢å¼ºç»“æœ
        final_enhanced_results_file = os.path.join(args.classify_dir, "terminal_decision_results_enhanced.json")
        dump_json(final_enhanced_results_file, {
            "summary": {
                # åŸºç¡€ç»Ÿè®¡ï¼ˆä¸terminal_decisionä¿æŒä¸€è‡´ï¼‰
                "total_samples": total_samples,
                "correct_predictions": enhanced_correct,  # ä¸terminal_decisionä¿æŒä¸€è‡´çš„å‘½å
                "accuracy": enhanced_accuracy,           # ä¸terminal_decisionä¿æŒä¸€è‡´çš„å‘½å
                "fast_only_correct": fast_only_correct,
                "fast_only_accuracy": fast_only_acc,
                "slow_triggered": slow_triggered,
                "slow_trigger_ratio": slow_trigger_ratio,
                "slow_triggered_correct": slow_triggered_correct,
                "slow_trigger_accuracy": slow_trigger_acc,
                # å¢å¼ºç‰ˆç‰¹æœ‰çš„ç»Ÿè®¡
                "terminal_decisions": terminal_decisions,
                "terminal_success_rate": terminal_success_rate,
                "fast_enhanced_success": fast_enhanced_data.get("summary", {}).get("mec_success", False),
                "slow_enhanced_success": slow_enhanced_data.get("summary", {}).get("mec_success", False)
            },
            "detailed_results": all_enhanced_results
        })
        
        print(f"ğŸ’¾ ç»ˆç«¯å†³ç­–å¢å¼ºç»“æœå·²ä¿å­˜åˆ°: {final_enhanced_results_file}")
    
    else:
        raise NotImplementedError 

    end_time = time.time()
    total_time = end_time - start_time
    formatted_time = time.strftime("%H:%M:%S", time.gmtime(total_time))
    print(f"æ€»è€—æ—¶: {formatted_time}")
