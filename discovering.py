import torch 
import os 
import argparse 
import json 
from tqdm import tqdm  
from termcolor import colored  
from collections import Counter 
from utils.configuration import setup_config, seed_everything 
from utils.fileios import dump_json, load_json, dump_txt  

from data import DATA_STATS, PROMPTERS, DATA_DISCOVERY  
from data.prompt_identify import prompts_howto  
from agents.vqa_bot import VQABot  
from agents.llm_bot import LLMBot 
from agents.mllm_bot import MLLMBot
from cvd.cdv_captioner import CDVCaptioner  
from retrieval.multimodal_retrieval import MultimodalRetrieval 
from fast_slow_thinking_system import FastSlowThinkingSystem
from utils.util import is_similar
import re 
import hashlib
import time
from collections import defaultdict
import numpy as np


DEBUG = False  # è®¾ç½®è°ƒè¯•æ¨¡å¼ä¸ºå…³é—­çŠ¶æ€


def cint2cname(label: int, cname_sheet: list):
    """å°†ç±»åˆ«æ•´æ•°ç´¢å¼•è½¬æ¢ä¸ºç±»åˆ«åç§°"""
    return cname_sheet[label]


def extract_superidentify(cfg, individual_results):
    """ä»ä¸ªä½“è¯†åˆ«ç»“æœä¸­æå–è¶…ç±»è¯†åˆ«ç»“æœ"""
    words = []  # åˆå§‹åŒ–å•è¯åˆ—è¡¨
    for v in individual_results.values():  # éå†æ‰€æœ‰ä¸ªä½“è¯†åˆ«ç»“æœ
        this_word = v.split(' ')[-1]  # å–æœ€åä¸€ä¸ªå•è¯ä½œä¸ºç±»åˆ«æ ‡è¯†
        words.append(this_word.lower())  # è½¬æ¢ä¸ºå°å†™å¹¶æ·»åŠ åˆ°åˆ—è¡¨
    word_counts = Counter(words)  # ç»Ÿè®¡æ¯ä¸ªå•è¯çš„å‡ºç°æ¬¡æ•°
    # print(f"extract_superidentify ä¸­æ¯ä¸ªå•è¯å‡ºç°æ¬¡æ•°: {word_counts}")
    if cfg['dataset_name'] == 'pet':  # å¦‚æœæ˜¯å® ç‰©æ•°æ®é›†
        return [super_name for super_name, _ in word_counts.most_common(2)]  # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„2ä¸ªè¶…ç±»
    else:  # å…¶ä»–æ•°æ®é›†
        return [super_name for super_name, _ in word_counts.most_common(1)]  # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„1ä¸ªè¶…ç±»



def extract_python_list(text):
    """ä»æ–‡æœ¬ä¸­æå–Pythonåˆ—è¡¨æ ¼å¼çš„å†…å®¹"""
    pattern = r"\[(.*?)\]"  # å®šä¹‰åŒ¹é…æ–¹æ‹¬å·å†…å®¹çš„æ­£åˆ™è¡¨è¾¾å¼
    matches = re.findall(pattern, text)  # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„å†…å®¹
    return matches  # è¿”å›åŒ¹é…ç»“æœåˆ—è¡¨


def trim_result2json(raw_reply: str):
    """
    the raw_answer is a dirty output from LLM following our template.
    this function helps to extract the target JSON content contained in the
    output.
    """
    # ä»LLMçš„åŸå§‹è¾“å‡ºä¸­æå–JSONæ ¼å¼çš„å†…å®¹
    if raw_reply.find("Output JSON:") >= 0:  # å¦‚æœåŒ…å«"Output JSON:"æ ‡è®°
        answer = raw_reply.split("Output JSON:")[1].strip()  # æå–æ ‡è®°åçš„å†…å®¹
    else:  # å¦åˆ™ç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹
        answer = raw_reply.strip()  # å»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦

    if not answer.startswith('{'): answer = '{' + answer  # å¦‚æœå¼€å¤´ä¸æ˜¯{ï¼Œåˆ™æ·»åŠ 

    if not answer.endswith('}'): answer = answer + '}'  # å¦‚æœç»“å°¾ä¸æ˜¯}ï¼Œåˆ™æ·»åŠ 

    # json_answer = json.loads(answer)  # æ³¨é‡Šæ‰çš„JSONè§£æä»£ç 
    return answer  # è¿”å›å¤„ç†åçš„JSONå­—ç¬¦ä¸²


def clean_name(name: str):
    """æ¸…ç†ç±»åˆ«åç§°ï¼Œç»Ÿä¸€æ ¼å¼"""
    name = name.title() 
    name = name.replace("-", " ")  
    name = name.replace("'s", "") 
    return name  


def extract_names(gussed_names, clean=True):
    """ä»çŒœæµ‹çš„åç§°åˆ—è¡¨ä¸­æå–å’Œæ¸…ç†åç§°"""
    gussed_names = [name.strip() for name in gussed_names]
    if clean:  # å¦‚æœéœ€è¦æ¸…ç†
        gussed_names = [clean_name(name) for name in gussed_names]  
    gussed_names = list(set(gussed_names))  # å»é‡å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
    return gussed_names  # è¿”å›å¤„ç†åçš„åç§°åˆ—è¡¨


def how_to_distinguish(bot, prompt):
    """è¯¢é—®LLMå¦‚ä½•åŒºåˆ†ä¸åŒç±»åˆ«"""
    reply = bot.infer(prompt, temperature=0.1) 
    used_tokens = bot.get_used_tokens()  
    print(f"llm used_tokens: {used_tokens},")
    print(20*"=")  
    print(reply)  #
    print(20*"=") 

    return reply  

def main_identify(cfg, bot, data_disco):
    """è¯†åˆ«å›¾åƒçš„è¶…ç±»"""
    json_super_classes = {}             # img: [attr1, attr2, ..., attrN] - åˆå§‹åŒ–è¶…ç±»ç»“æœå­—å…¸

    # print(f"ç°åœ¨å¼€å§‹éå†å‘ç°é›†data_disco: {data_disco}")
    for idx, (img, label) in tqdm(enumerate(data_disco)):  # éå†å‘ç°æ•°æ®é›†ä¸­çš„å›¾åƒå’Œæ ‡ç­¾
        # prompt_identify = "Question: What is the main object in this image (choose from: Car, Flower, or Pokemon)? Answer:"
        
        prompt_identify = "Question: What is the category (car, bird, flower, dog, cat, or Pokemon) of the main object in this image? Answer:" 

        reply, trimmed_reply = bot.describe_attribute(img, prompt_identify) 
        trimmed_reply = trimmed_reply.lower()  
        json_super_classes[str(idx)] = trimmed_reply 

        # DEBUG mode - è°ƒè¯•æ¨¡å¼
        if DEBUG and idx >= 2: 
            break  
    # print(f"main_identify è¯†åˆ«ç»“æœ: {json_super_classes}")
    return json_super_classes  # è¿”å›è¶…ç±»è¯†åˆ«ç»“æœ


def main_describe(cfg, bot, data_disco, prompter, cname_sheet):
    """
    1.è°ƒç”¨VQAæ¨¡å‹ä¸ºæ¯ä¸ªå±æ€§ç”Ÿæˆå¯¹åº”çš„æè¿°
    2.ç”ŸæˆLLMpromotæè¿°
    """
    json_attrs = {}             # img: [attr1, attr2, ..., attrN] - åˆå§‹åŒ–å±æ€§ç»“æœå­—å…¸
    json_llm_prompts = {}       # img: LLM-prompt (has all attrs) - åˆå§‹åŒ–LLMæç¤ºå­—å…¸

    # è¿™é‡Œæ˜¯è®­ç»ƒé›†ï¼Œé¢„å…ˆå®šä¹‰å¥½çš„
    for idx, (img, label) in tqdm(enumerate(data_disco)): 
        if cfg['dataset_name'] == 'pet': 
            # first check what is the animal
            pet_prompt = "Questions: What is the animal in this photo (dog or car)? Answer:"
            pet_re, pet_trimmed_re = bot.describe_attribute(img, pet_prompt) 
            pet_trimmed_re = pet_trimmed_re.lower() 
            # print(pet_trimmed_re)
            if 'dog' in pet_trimmed_re:
                prompter.set_superclass('dog')
            else:
                prompter.set_superclass('cat')

        # generate attributes and per-attribute prompts for VQA bot  è·å¾—å±æ€§åˆ—è¡¨
        attrs = prompter.get_attributes()
        # ç”Ÿæˆå¯¹åº”å±æ€§çš„promotæè¿°ï¼Œè®©LLMè¿›è¡Œæè¿°
        attr_prompts = prompter.get_attribute_prompt() 
        if len(attrs) != len(attr_prompts):  # æ£€æŸ¥å±æ€§åˆ—è¡¨å’Œæç¤ºåˆ—è¡¨é•¿åº¦æ˜¯å¦ä¸€è‡´
            raise IndexError("Attribute list should have the same length as attribute prompts")

        print(f"å½“å‰idx:{idx}: label={label}")

        iname = cint2cname(label, cname_sheet)
        iname += f"_{idx}"  # å¯¹åº”ç”¨å¤šå°‘ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†
        json_attrs[iname] = []  # åˆå§‹åŒ–è¯¥å›¾åƒçš„å±æ€§åˆ—è¡¨

        # describe each attrs - æè¿°æ¯ä¸ªå±æ€§
        pair_attr_reply = []    # (attr1: prompt) - åˆå§‹åŒ–å±æ€§-å€¼å¯¹åˆ—è¡¨
        for attr, p_attr in zip(attrs, attr_prompts):  # éå†å±æ€§å’Œå¯¹åº”çš„prompt
            re_attr, trimmed_re_attr = bot.describe_attribute(img, p_attr) 
            # print(f"è°ƒç”¨bot.describe_attributeå¾—åˆ°çš„reply:{re_attr} \n tritrimmed_re_attr:{trimmed_re_attr}")
            pair_attr_reply.append([attr, trimmed_re_attr])
            json_attrs[iname].append(trimmed_re_attr)  # å°†å±æ€§å€¼æ·»åŠ åˆ°å¯¹åº”çš„ç±»åˆ«æè¿°ä¸­
        
        print(f'è·å¾—çš„VQA pair_attr_reply: {pair_attr_reply}\n json_attrs: {json_attrs}')
        # generate LLM prompt - ç”ŸæˆLLMæç¤º
        llm_prompt = prompter.get_llm_prompt(pair_attr_reply)  # æ ¹æ®å±æ€§-å€¼å¯¹ç”ŸæˆLLMæç¤º
        json_llm_prompts[iname] = llm_prompt 
        print(f'json_llm_prompts: {json_llm_prompts}')
        print(30 * '=')
        print(iname + f" with label {label}") 
        print(30 * '=')
        # print()  # æ‰“å°ç©ºè¡Œ
        # print(f"llm_prompt: {llm_prompt}")  # æ‰“å°LLMæç¤º
        # print()  # æ‰“å°ç©ºè¡Œ
        # print('END' + 30 * '=')  # æ‰“å°ç»“æŸåˆ†éš”çº¿
        # print()  # æ‰“å°ç©ºè¡Œ

        # DEBUG mode - è°ƒè¯•æ¨¡å¼
        if DEBUG and idx >= 2:  # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ä¸”å¤„ç†äº†2ä¸ªä»¥ä¸Šæ ·æœ¬
            break  # è·³å‡ºå¾ªç¯

    return json_attrs, json_llm_prompts  # è¿”å›å±æ€§ç»“æœå’ŒLLMæç¤º


def main_guess(cfg, bot, reasoning_prompts):
    """ä¸»è¦çŒœæµ‹å‡½æ•°ï¼šåŸºäºå±æ€§æè¿°æ¨ç†ç±»åˆ«åç§°"""
    prompt_list = reasoning_prompts  
    replies_raw = {}  
    replies_json_to_save = {}  

    # LLM inferring - LLMæ¨ç†
    for i, (key, prompt) in tqdm(enumerate(prompt_list.items())):  
        raw_reply = bot.infer(prompt, temperature=0.9)  # use a high temperature for better diversity
        used_tokens = bot.get_used_tokens()  # è·å–ä½¿ç”¨çš„tokenæ•°é‡

        replies_raw[key] = raw_reply  # å°†åŸå§‹å›å¤å­˜å‚¨åˆ°å­—å…¸

        print(30 * '=')  # æ‰“å°åˆ†éš”çº¿
        print(f"\t\tinferring [{i}] for {key} used tokens = {used_tokens}") 
        print(30 * '=')  
        print("Raw----")  
        print(raw_reply)  
        print()  

        jsoned_reply = trim_result2json(raw_reply=raw_reply) 

        replies_json_to_save[key] = jsoned_reply  

        print("Trimed----")  
        print(jsoned_reply)
        print()  # æ‰“å°ç©ºè¡Œ
        print('END' + 30 * '=')  
        print()  

        # DEBUG - è°ƒè¯•
        if DEBUG and i >= 2:  # å¦‚æœå¼€å¯è°ƒè¯•æ¨¡å¼ä¸”å¤„ç†äº†2ä¸ªä»¥ä¸Šæ ·æœ¬
            break 

    print(30 * '=')  
    print(f"\t\t Finish Discovering, token consumed {bot.get_used_tokens()}"  
          f" = ${bot.get_used_tokens()*0.001*0.002}") 
    print(30 * '=')  
    print('END' + 30 * '=')  
    print()  
    return replies_raw, replies_json_to_save 


def post_process(cfg, jsoned_replies):
    """åå¤„ç†å‡½æ•°ï¼šæ¸…ç†å’Œæ•´ç†LLMæ¨ç†ç»“æœ"""
    reply_list = []  
    num_of_failures = 0  
    # duplicated dict - é‡å¤å­—å…¸
    for k, v in jsoned_replies.items():  # éå†JSONå›å¤å­—å…¸
        print(k)  
        print(v) 
        print()
        print() 
        try:  
            v_json = json.loads(v)  
            reply_list.append(v_json)
        except json.JSONDecodeError:  
            print(f"Failed to decode JSON for key: {k}") 
            num_of_failures += 1  
            continue  

        # v_json = json.loads(v) 
        # reply_list.append(v_json) 

    guessed_names = [] 
    for item in reply_list: 
        guessed_names.extend(list(item.keys()))  

    guessed_names = extract_names(guessed_names, clean=False) 

    if cfg['dataset_name'] in ['pet', 'dog']: 
        clean_gussed_names = []  
        for aitem in guessed_names:
            clean_gussed_names.extend(aitem.split(','))  
        clean_gussed_names = [name.strip() for name in clean_gussed_names]  
        guessed_names = clean_gussed_names  

    print(30 * '=') 
    print(f"\t\t Finished Post-processing")  
    print(30 * '=')  

    print(f"\t\t ---> total discovered names = {len(guessed_names)}")  
    print(guessed_names)  
    print()  
    print(f"\t\t ---> total discovered names = {len(guessed_names)}")  
    print(f"\t\t ---> number of failure entries = {num_of_failures}") 

    print('END' + 30 * '=')  
    print()  
    return guessed_names 


def load_train_samples(cfg, kshot=None):
    """åŠ è½½K-shotè®­ç»ƒæ ·æœ¬ï¼Œè¿”å› {category: [image_paths]}ã€‚
    ä¼˜å…ˆä» cfg['path_train_samples'] (JSON) è¯»å–ï¼›å¦åˆ™ä» cfg['train_root'] ç›®å½•æ‰«æã€‚
    """
    samples = {}
    if 'path_train_samples' in cfg and os.path.exists(cfg['path_train_samples']):
        try:
            samples = load_json(cfg['path_train_samples'])
        except Exception as e:
            print(f"failed to load path_train_samples: {cfg['path_train_samples']}, err={e}")
            samples = {}
    elif 'train_root' in cfg and os.path.isdir(cfg['train_root']):
        train_root = cfg['train_root']
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        for cname in sorted(os.listdir(train_root)):
            cdir = os.path.join(train_root, cname)
            if not os.path.isdir(cdir):
                continue
            imgs = []
            for fname in sorted(os.listdir(cdir)):
                fpath = os.path.join(cdir, fname)
                ext = os.path.splitext(fname)[1].lower()
                if os.path.isfile(fpath) and ext in valid_exts:
                    imgs.append(fpath)
            if imgs:
                samples[cname] = imgs
    else:
        raise FileNotFoundError("Neither cfg['path_train_samples'] nor cfg['train_root'] is valid.")

    if kshot is not None:
        trimmed = {}
        for cat, paths in samples.items():
            trimmed[cat] = paths[:kshot]
        return trimmed
    return samples


def build_gallery(cfg, mllm_bot, captioner, retrieval, kshot=5,region_num=3, superclass=None, data_discovery=None):
    """æ„å»ºå¤šæ¨¡æ€ç±»åˆ«æ¨¡æ¿åº“å¹¶ä¿å­˜åˆ°JSON(å‘é‡è½¬list)ã€‚"""

    # è¯»å–è®­ç»ƒæ ·æœ¬
    k = kshot if kshot is not None else int(str(cfg.get('k_shot', '3')))
    # train_samples = load_train_samples(cfg, kshot=k)
    train_samples = defaultdict(list)
    for name, path in data_discovery.subcat_to_sample.items():
        train_samples[name].append(path)
    print(f"loaded train samples for {len(train_samples)} classes, kshot={k}")
    print(f"train_samples: {train_samples}") 

    # æ„å»ºæ¨¡æ¿åº“
    gallery = retrieval.build_template_gallery(mllm_bot, train_samples, captioner, superclass, kshot, region_num)
    
    return gallery

if __name__ == "__main__":
    """
    CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=build_gallery --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --kshot=5 --region_num=3 --superclass=dog  --gallery_out=./experiments/dog120/gallery/dog120_gallery_concat_atten.json --fusion_method=concat 2>&1 | tee ./logs/build_gallery_dog_concat_atten.log
    """
    parser = argparse.ArgumentParser(description='Discovery', formatter_class=argparse.ArgumentDefaultsHelpFormatter) 

    parser.add_argument('--mode',  
                        type=str, 
                        default='describe', 
                        choices=['identify', 'howto', 'describe', 'guess', 'postprocess', 'build_gallery', 'build_knowledge_base', 'classify', 'evaluate', 'fastonly', 'slowonly', 'fast_slow', 'fast_slow_infer', 'fast_slow_classify'],  # å¯é€‰å€¼åˆ—è¡¨
                        help='operating mode for each stage')  
    parser.add_argument('--config_file_env',  
                        type=str,  
                        default='./configs/env_machine.yml',  # é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
                        help='location of host environment related config file')  
    parser.add_argument('--config_file_expt',  # æ·»åŠ å®éªŒé…ç½®æ–‡ä»¶å‚æ•°
                        type=str,  
                        default='./configs/expts/bird200_all.yml', 
                        help='location of host experiment related config file') 
    # arguments for control experiments - æ§åˆ¶å®éªŒçš„å‚æ•°
    parser.add_argument('--num_per_category',  # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡å‚æ•°
                        type=str, 
                        default='3',  
                        choices=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'random'], 
                        )
    # build_gallery ç›¸å…³
    parser.add_argument('--kshot', type=int, default=None, help='shots per class when building gallery (override cfg)')
    parser.add_argument('--region_num', type=int, default=None, help='region selelct per class when building gallery (override cfg)')
    parser.add_argument('--superclass', type=str, default=None, help='superclass for CDV prompts (override cfg)')
    parser.add_argument('--gallery_out', type=str, default=None, help='path to save built gallery json')
    parser.add_argument('--fusion_method', type=str, default='concat', help='fusion method')
    
    # å¿«æ…¢æ€è€ƒç³»ç»Ÿç›¸å…³å‚æ•°
    parser.add_argument('--knowledge_base_dir', type=str, default='./knowledge_base', help='knowledge base directory')
    parser.add_argument('--query_image', type=str, default=None, help='query image path for classification')
    parser.add_argument('--test_data_dir', type=str, default=None, help='test data directory for evaluation')
    parser.add_argument('--results_out', type=str, default='./results.json', help='output path for results')
    parser.add_argument('--use_slow_thinking', type=bool, default=None, help='force use slow thinking (None for auto)')
    parser.add_argument('--confidence_threshold', type=float, default=0.8, help='confidence threshold for fast thinking')
    parser.add_argument('--similarity_threshold', type=float, default=0.7, help='similarity threshold for trigger mechanism')
    parser.add_argument('--enable_mllm_intermediate_judge', action='store_true', default=False, help='enable MLLM intermediate judge between fast and slow thinking (for ablation studies)')
    
    # å¿«æ…¢æ€è€ƒæ¨ç†ä¸åˆ†ç±»åˆ†ç¦»ç›¸å…³å‚æ•°
    parser.add_argument('--infer_dir', type=str, default=None, help='directory to save inference results (for fast_slow_infer mode)')
    parser.add_argument('--classify_dir', type=str, default=None, help='directory to save classification results (for fast_slow_classify mode)')

    args = parser.parse_args()  
    print(colored(args, 'blue'))  

    cfg = setup_config(args.config_file_env, args.config_file_expt)  
    print(colored(cfg, 'yellow')) 

    # drop the seed - è®¾ç½®éšæœºç§å­
    seed_everything(cfg['seed']) 

    expt_id_suffix = f"_{args.num_per_category}"  # åˆ›å»ºå®éªŒIDåç¼€

    if args.mode == 'build_knowledge_base':
        """
        æ„å»ºå¿«æ…¢æ€è€ƒç³»ç»Ÿçš„çŸ¥è¯†åº“
        CUDA_VISIBLE_DEVICES=3 python discovering.py --mode=build_knowledge_base --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --num_per_category=10 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base 2>&1 | tee ./logs/build_knowledge_base_dog120.log
        """
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½è®­ç»ƒæ ·æœ¬
        data_discovery = DATA_DISCOVERY[cfg['dataset_name']](cfg, folder_suffix=expt_id_suffix)
        train_samples = defaultdict(list)
        # {"Chihuaha": "./datasets/dogs_120/images_discovery_all_3/000.Chihuaha_000000.jpg", "Poodle": "./datasets/dogs_120/images_discovery_all_3/001.Poodle_000000.jpg", ...}
        for name, path in data_discovery.subcat_to_sample.items():
            for p in path:
                train_samples[name].append(p)
        
        print(f"æ„å»ºçŸ¥è¯†åº“ï¼ŒåŒ…å« {len(train_samples)} ä¸ªç±»åˆ«, dog datasets:{len(DATA_STATS[cfg['dataset_name']]['class_names'])}")
        
        # æ„å»ºçŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir) # æ–¹ä¾¿æ„å»ºstats
        image_kb, text_kb = system.build_knowledge_base(
            train_samples, 
            save_dir=args.knowledge_base_dir,
            augmentation=True
        )
        
        print(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œä¿å­˜åˆ°: {args.knowledge_base_dir}")
    
    elif args.mode == 'classify':
        """
        ä½¿ç”¨å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œå•å¼ å›¾åƒåˆ†ç±»
        CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --query_image=./test_image.jpg --knowledge_base_dir=/data/yjx/MLLM/Try/experiments/dog120/knowledge_base 2>&1 | tee ././logs/testfast.log
        """
        if args.query_image is None:
            raise ValueError("è¯·æä¾›æŸ¥è¯¢å›¾åƒè·¯å¾„ --query_image")
        
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)
        
        # åˆ†ç±»å›¾åƒ
        result = system.classify_single_image(
            args.query_image,
            use_slow_thinking=args.use_slow_thinking
        )
        
        # ä¿å­˜ç»“æœ
        system.save_results([result], args.results_out)
        
        print(f"åˆ†ç±»ç»“æœ: {result['final_prediction']} (ç½®ä¿¡åº¦: {result['final_confidence']:.4f})")
        print(f"ä½¿ç”¨æ…¢æ€è€ƒ: {result.get('used_slow_thinking', False)}")
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.results_out}")

    elif args.mode == 'evaluate':
        """
        åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        CUDA_VISIBLE_DEVICES=1 python discovering.py --mode=evaluate --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=./test_data --knowledge_base_dir=./knowledge_base_dog120 --results_out=./evaluation_results.json
        """
        if args.test_data_dir is None:
            raise ValueError("è¯·æä¾›æµ‹è¯•æ•°æ®ç›®å½• --test_data_dir")
        
        # åˆå§‹åŒ–å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)
        
        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = defaultdict(list)
        for class_name in os.listdir(args.test_data_dir):
            class_dir = os.path.join(args.test_data_dir, class_name)
            if os.path.isdir(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                        img_path = os.path.join(class_dir, img_name)
                        test_samples[class_name].append(img_path)
        
        print(f"æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # è¯„ä¼°ç³»ç»Ÿ
        evaluation_result = system.evaluate_on_dataset(
            test_samples,
            use_slow_thinking=args.use_slow_thinking
        )
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        system.save_results([evaluation_result], args.results_out)
        
        print(f"è¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: {evaluation_result['accuracy']:.4f}")
        print(f"å¿«æ€è€ƒæ¯”ä¾‹: {evaluation_result['fast_thinking_ratio']:.4f}")
        print(f"æ…¢æ€è€ƒæ¯”ä¾‹: {evaluation_result['slow_thinking_ratio']:.4f}")
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.results_out}")
    
    elif args.mode == 'fastonly':
        """
        CUDA_VISIBLE_DEVICES=2 python discovering.py --mode=fastonly --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_10 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base --results_out=./logs/fastonly_eval.json 2>&1 | tee ./logs/fastonly_eval_lcb.log
        """

        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆä»…ç”¨äºåŠ è½½ç»„ä»¶ï¼‰ï¼Œéšååªç”¨fastæ¨¡å—
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            # print(f'cat name:{cat_name}')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            # print(f'img_path:{img_path}\tfilename:{file_names}')
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[fastonly] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        # ä»…ä½¿ç”¨å¿«æ€è€ƒè¯„ä¼°
        fast_module = system.fast_thinking
        correct = 0
        total = 0
        correct_slow_true = 0    # æ­£ç¡®ä¸”éœ€è¦ slow thinking
        correct_slow_false = 0   # æ­£ç¡®ä½†ä¸éœ€è¦ slow thinking é¢„æœŸ
        error_slow_true = 0      # é”™è¯¯ä¸”éœ€è¦ slow thinking é¢„æœŸ
        error_slow_false = 0     # é”™è¯¯ä½†ä¸éœ€è¦ slow thinking
        for true_cat, paths in test_samples.items():
            for path in paths:
                try:
                    fast_res = fast_module.fast_thinking_pipeline(path, top_k=5)
                    # ä½¿ç”¨èåˆTop-1ä½œä¸ºfast-onlyé¢„æµ‹ï¼Œå…¼å®¹æ—§é€»è¾‘å…œåº•
                    pred = fast_res.get('predicted_fast') or fast_res.get('fused_top1') or fast_res.get('predicted_category') or fast_res.get('img_category', 'unknown')
                    ok = is_similar(pred, true_cat, threshold=0.5)
                    if ok:
                        print(f"succ. pred cate:{pred}, true cate:{true_cat}, need_slow_thinking:{fast_res['need_slow_thinking']}")
                        if fast_res['need_slow_thinking']:
                            correct_slow_true+=1
                        else:
                            correct_slow_false+=1
                        correct += 1
                    else:
                        print(f"failed. pred cate:{pred}, true cate:{true_cat}, need_slow_thinking:{fast_res['need_slow_thinking']}")
                        if fast_res['need_slow_thinking']:
                            error_slow_true += 1
                        else:
                            error_slow_false += 1
                    total += 1

                except Exception as e:
                    print(f'Exception:{e}')
                    total += 1


        acc = correct / total if total > 0 else 0.0
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­éœ€è¦ slow thinking: {correct_slow_true}")
        print(f"  - å…¶ä¸­ä¸éœ€è¦ slow thinking: {correct_slow_false}")

        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"  - å…¶ä¸­éœ€è¦ slow thinking: {error_slow_true}")
        print(f"  - å…¶ä¸­ä¸éœ€è¦ slow thinking: {error_slow_false}")
        print(f"[fastonly] å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
    elif args.mode == 'slowonly':
        """
        CUDA_VISIBLE_DEVICES=3 python discovering.py --mode=slowonly --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_10 --knowledge_base_dir=/data/yjx/MLLM/Try/experiments/dog120/knowledge_base --results_out=./logs/slowonly_eval.json 2>&1 | tee ./logs/slowonly_eval.log
        """

        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆä»…ç”¨äºåŠ è½½ç»„ä»¶ï¼‰ï¼Œéšååªç”¨slowæ¨¡å—
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f'test sample:{test_samples}')
        print(f"[slowonly] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # ä»…ä½¿ç”¨æ…¢æ€è€ƒè¯„ä¼°
        slow_module = system.slow_thinking
        fast_module = system.fast_thinking  # æ…¢æ€è€ƒéœ€è¦å¿«æ€è€ƒç»“æœä½œä¸ºè¾“å…¥
        correct = 0
        total = 0
        
        for true_cat, paths in test_samples.items():
            for path in paths:
                try:
                    # å…ˆæ‰§è¡Œå¿«æ€è€ƒè·å–ç»“æœï¼ˆæ…¢æ€è€ƒéœ€è¦è¿™ä¸ªè¾“å…¥ï¼‰
                    fast_res = fast_module.fast_thinking_pipeline(path, top_k=5)
                    
                    # æ‰§è¡Œæ…¢æ€è€ƒ
                    slow_res = slow_module.slow_thinking_pipeline(path, fast_res, top_k=5)
                     
                    # ä½¿ç”¨æ…¢æ€è€ƒçš„æœ€ç»ˆé¢„æµ‹
                    pred = slow_res.get('predicted_category', 'unknown')
                    ok = is_similar(pred, true_cat, threshold=0.5)
                    
                    if ok:
                        print(f"succ. pred cate:{pred}, true cate:{true_cat}, confidence:{slow_res.get('confidence', 0):.4f}")
                        correct += 1
                    else:
                        print(f"failed. pred cate:{pred}, true cate:{true_cat}, confidence:{slow_res.get('confidence', 0):.4f}")
                    
                    total += 1

                except Exception as e:
                    print(f'Exception:{e}')
                    total += 1

        acc = correct / total if total > 0 else 0.0
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"[slowonly] å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        
    # fast_slow æ¨¡å¼ï¼šå¯¹æµ‹è¯•é›†æ‰§è¡Œâ€œå¿«æ€è€ƒâ†’å¿…è¦æ—¶æ…¢æ€è€ƒâ†’æœ€ç»ˆèåˆâ€çš„æ•´ä½“éªŒè¯
    elif args.mode == 'fast_slow':  # è¿›å…¥ fast_slow è¯„ä¼°åˆ†æ”¯
        """
        CUDA_VISIBLE_DEVICES=2 python discovering.py --mode=fast_slow --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=/data/yjx/MLLM/UniFGVR/datasets/dogs_120/images_discovery_all_1 --knowledge_base_dir=/data/yjx/MLLM/Try_again/experiments/dog120/knowledge_base --results_out=./logs/fast_and_slow_eval.json 2>&1 | tee ./logs/fast_and_slow_update_lcb_1_context256.log
        """  # ç”¨æ³•ç¤ºä¾‹ï¼šæ¼”ç¤ºå¦‚ä½•ä»å‘½ä»¤è¡Œå¯åŠ¨è¯¥æ¨¡å¼

        # åˆå§‹åŒ–å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿï¼ˆå†…éƒ¨ä¼šåˆå§‹åŒ–çŸ¥è¯†åº“æ„å»ºå™¨ã€å¿«/æ…¢æ€è€ƒæ¨¡å—ã€MLLMç­‰ï¼‰
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],  # ä½¿ç”¨é…ç½®ä¸­çš„å¤šæ¨¡æ€å¤§æ¨¡å‹æ ‡è¯†
            model_name=cfg['model_size_mllm'], # æ¨¡å‹åç§°ï¼ˆä¸ tag ä¸€è‡´ï¼‰
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',  # æŒ‰ä¸»æœºé…ç½®é€‰æ‹©è®¾å¤‡
            cfg=cfg,  # ä¼ é€’å®Œæ•´å®éªŒé…ç½®
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge  # æ˜¯å¦å¯ç”¨MLLMä¸­é—´åˆ¤åˆ«ï¼ˆå¯åšæ¶ˆèï¼‰
        )
        # åŠ è½½å·²æ„å»ºå¥½çš„çŸ¥è¯†åº“ï¼ˆå›¾åƒ/æ–‡æœ¬å‘é‡ã€ç»Ÿè®¡ä¿¡æ¯ç­‰ï¼‰ï¼Œä¾›æ£€ç´¢ä¸åˆ¤åˆ«ä½¿ç”¨
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬æ˜ å°„ï¼š{ çœŸå€¼ç±»åˆ«: [å›¾åƒè·¯å¾„, ...] }
        test_samples = {}  # ç”¨äºä¿å­˜æ¯ä¸ªç±»åˆ«å¯¹åº”çš„æ‰€æœ‰æµ‹è¯•å›¾ç‰‡
        img_root = args.test_data_dir  # æµ‹è¯•é›†æ ¹ç›®å½•
        class_folders = os.listdir(args.test_data_dir)  # åˆ—å‡ºç±»åˆ«å­ç›®å½•
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')  # ä»ç›®å½•åè§£æç±»åˆ«åï¼ˆçº¦å®šï¼šç”¨ '-' åˆ†å‰²å¹¶æ›¿æ¢ '_' ä¸ºç©ºæ ¼ï¼‰
            img_path = os.path.join(img_root, class_folders[i])  # é¡¶å±‚ç±»åˆ«ç›®å½•è·¯å¾„
            file_names = os.listdir(img_path)  # è·å–è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å
            for name in file_names:
                path = os.path.join(img_path,name)  # ç»„æˆå•å¼ å›¾ç‰‡çš„è·¯å¾„
                if cat_name not in test_samples:
                    test_samples[cat_name] = []  # é¦–æ¬¡å‡ºç°è¯¥ç±»åˆ«æ—¶åˆå§‹åŒ–åˆ—è¡¨
                test_samples[cat_name].append(path)  # åŠ å…¥è¯¥ç±»åˆ«çš„æµ‹è¯•å›¾ç‰‡

        print(f'test sample:{test_samples}')  # æ‰“å°æµ‹è¯•æ ·æœ¬æ˜ å°„ï¼Œä¾¿äºè°ƒè¯•æ ¸å¯¹
        print(f"[fast and slow] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")  # æ‰“å°ç±»åˆ«æ€»æ•°
        
        # ä½¿ç”¨å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œè¯„ä¼°ï¼ˆç»Ÿè®¡å¤šé¡¹æŒ‡æ ‡ï¼‰
        correct = 0  # é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        total = 0    # è¯„ä¼°çš„æ ·æœ¬æ€»æ•°
        fast_only_correct = 0    # æœªè§¦å‘æ…¢æ€è€ƒä¸”é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        slow_triggered = 0       # è§¦å‘è¿‡æ…¢æ€è€ƒçš„æ ·æœ¬æ•°
        slow_triggered_correct = 0  # è§¦å‘æ…¢æ€è€ƒä¸”æœ€ç»ˆé¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        
        # é€ç±»åˆ«éå†ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡
        from tqdm import tqdm  # å¼•å…¥è¿›åº¦æ¡åº“
        for true_cat, paths in tqdm(test_samples.items(), desc="Processing fast and slow thinking"):  # true_cat ä¸ºçœŸå€¼ç±»åˆ«å
            for path in paths:  # éå†è¯¥ç±»åˆ«ä¸‹çš„æ¯ä¸€å¼ å›¾ç‰‡
                # ä½¿ç”¨å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿè¿›è¡Œå•å¼ å›¾ç‰‡åˆ†ç±»ï¼ˆè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦è¿›å…¥æ…¢æ€è€ƒï¼‰
                result = system.classify_single_image(path, use_slow_thinking=None, top_k=5)
                
                pred = result.get('final_prediction', 'unknown')  # å–å¾—æœ€ç»ˆç±»åˆ«é¢„æµ‹
                ok = is_similar(pred, true_cat, threshold=0.5)    # ä¸çœŸå€¼è¿›è¡Œç›¸ä¼¼åŒ¹é…ï¼ˆå¤§å°å†™/ç©ºæ ¼ç­‰é²æ£’ï¼‰
                used_slow = result.get('used_slow_thinking', False)  # è®°å½•æ˜¯å¦è§¦å‘æ…¢æ€è€ƒ
                
                if ok:
                    # é¢„æµ‹æ­£ç¡®ï¼šæ‰“å°è¯¦æƒ…å¹¶ç´¯åŠ è®¡æ•°
                    print(f"succ. pred cate:{pred}, true cate:{true_cat}, used_slow:{used_slow}, confidence:{result.get('final_confidence', 0):.4f}")
                    correct += 1  # æ€»æ­£ç¡®æ•° +1
                    if not used_slow:
                        fast_only_correct += 1  # ä»…å¿«æ€è€ƒå°±æ­£ç¡®çš„æ•°é‡ +1
                    if used_slow:
                        slow_triggered_correct += 1  # è§¦å‘æ…¢æ€è€ƒä¸”æ­£ç¡®çš„æ•°é‡ +1
                else:
                    # é¢„æµ‹å¤±è´¥ï¼šæ‰“å°è¯¦æƒ…
                    print(f"failed. pred cate:{pred}, true cate:{true_cat}, used_slow:{used_slow}, confidence:{result.get('final_confidence', 0):.4f}")
                    # å¦‚æœéœ€è¦ä¹Ÿå¯ä»¥åœ¨æ­¤ç»Ÿè®¡â€œè§¦å‘æ…¢æ€è€ƒä½†å¤±è´¥â€çš„æ•°é‡
                    # if used_slow:
                    #     slow_triggered_correct += 1  # å³ä½¿é”™è¯¯ä¹Ÿç»Ÿè®¡ï¼ˆæ­¤å¤„ä¿æŒå…³é—­ï¼‰
                
                if used_slow:
                    slow_triggered += 1  # æ ·æœ¬è¿›å…¥è¿‡æ…¢æ€è€ƒï¼Œç´¯åŠ è§¦å‘æ•°
                
                total += 1  # æ ·æœ¬æ€»æ•° +1ï¼ˆä¸è®ºæˆåŠŸä¸å¦ï¼‰
        
        # æ±‡æ€»è¯„ä¼°æŒ‡æ ‡
        acc = correct / total if total > 0 else 0.0  # æ€»ä½“å‡†ç¡®ç‡
        fast_only_acc = fast_only_correct / (total-slow_triggered) if total > 0 else 0.0  # ä»…å¿«æ€è€ƒéƒ¨åˆ†çš„å‡†ç¡®ç‡ï¼ˆæ³¨æ„ï¼šè‹¥åˆ†æ¯ä¸º0ä¼šæŠ¥é”™ï¼Œæ­¤å¤„ä¿æŒåŸé€»è¾‘ï¼‰
        slow_trigger_ratio = slow_triggered / total if total > 0 else 0.0  # æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0  # è§¦å‘æ…¢æ€è€ƒæ ·æœ¬çš„å‡†ç¡®ç‡
        
        # æ‰“å°è¯„ä¼°ç»“æœ
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[fast and slow] æ€»ä½“å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        print(f"[fast and slow] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[fast and slow] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[fast and slow] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
    
    elif args.mode == 'build_gallery':
        """
        æ„å»ºå¤šæ¨¡æ€ç±»åˆ«æ¨¡æ¿åº“
        """
        print("è¿›å…¥build_galleryæ¨¡å¼")
        try:
            from agents.mllm_bot import MLLMBot
            from cvd.cdv_captioner import CDVCaptioner
            from retrieval.multimodal_retrieval import MultimodalRetrieval
            print("æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
        except Exception as e:
            print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            raise
        
        # ä½¿ç”¨MLLMå•ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½ï¼ˆæ˜¾å­˜ä¼˜åŒ–ï¼‰
        print("è·å–MLLM Botå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰...")
        from utils.mllm_singleton import get_mllm_bot
        mllm_bot = get_mllm_bot(
            model_tag=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu'
        )
        print("MLLM Botè·å–å®Œæˆ")
        
        print("åˆå§‹åŒ–CDV Captioner...")
        captioner = CDVCaptioner()
        print("CDV Captioneråˆå§‹åŒ–å®Œæˆ")
        
        print("åˆå§‹åŒ–å¤šæ¨¡æ€æ£€ç´¢æ¨¡å—...")
        retrieval = MultimodalRetrieval(
            fusion_method=args.fusion_method,
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu'
        )
        print("å¤šæ¨¡æ€æ£€ç´¢æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        
        # åŠ è½½å‘ç°æ•°æ®é›†
        print("åŠ è½½å‘ç°æ•°æ®é›†...")
        data_discovery = DATA_DISCOVERY[cfg['dataset_name']](cfg, folder_suffix=expt_id_suffix)
        print(f"å‘ç°æ•°æ®é›†åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(data_discovery.samples)} ä¸ªæ ·æœ¬")
        
        # æ„å»ºgallery
        print("å¼€å§‹æ„å»ºgallery...")
        gallery = build_gallery(
            cfg, mllm_bot, captioner, retrieval,
            kshot=args.kshot,
            region_num=args.region_num,
            superclass=args.superclass,
            data_discovery=data_discovery
        )
        print("Galleryæ„å»ºå®Œæˆ")
        
        # ä¿å­˜gallery
        if args.gallery_out:
            import json
            import os
            os.makedirs(os.path.dirname(args.gallery_out), exist_ok=True)
            # å°†numpyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
            gallery_serializable = {}
            for cat, feat in gallery.items():
                gallery_serializable[cat] = feat.tolist()
            
            with open(args.gallery_out, 'w') as f:
                json.dump(gallery_serializable, f, indent=2)
            print(f"Gallery saved to: {args.gallery_out}")
        
        print(f"Gallery built with {len(gallery)} categories")
    
    elif args.mode == 'fast_slow_infer':
        """
        å¿«æ…¢æ€è€ƒæ¨ç†æ¨¡å¼ï¼šä¿å­˜å¿«æ€è€ƒå’Œæ…¢æ€è€ƒçš„æ¨ç†ç»“æœï¼Œä¸è¿›è¡Œæœ€ç»ˆåˆ†ç±»
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_slow_infer --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --test_data_dir=./datasets/dogs_120/images_discovery_all_1 --knowledge_base_dir=./experiments/dog120/knowledge_base --infer_dir=./experiments/dog120/infer
        """
        if args.test_data_dir is None:
            raise ValueError("è¯·æä¾›æµ‹è¯•æ•°æ®ç›®å½• --test_data_dir")
        
        # è‡ªåŠ¨ç”Ÿæˆæ¨ç†ç»“æœä¿å­˜ç›®å½•ï¼ˆåŸºäºæ•°æ®é›†åç§°ï¼‰
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        print(f"æ¨ç†ç»“æœå°†ä¿å­˜åˆ°: {args.infer_dir}")
        os.makedirs(args.infer_dir, exist_ok=True)
        
        # åˆå§‹åŒ–å®Œæ•´çš„å¿«æ…¢æ€è€ƒç³»ç»Ÿ
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        # åŠ è½½çŸ¥è¯†åº“
        system.load_knowledge_base(args.knowledge_base_dir)

        # æ„å»ºæµ‹è¯•æ ·æœ¬
        test_samples = {}
        img_root = args.test_data_dir
        class_folders = os.listdir(args.test_data_dir)
        for i in range(len(class_folders)):
            cat_name = class_folders[i].split('-')[-1].replace('_', ' ')
            img_path = os.path.join(img_root, class_folders[i])
            file_names = os.listdir(img_path)
            for name in file_names:
                path = os.path.join(img_path,name)
                if cat_name not in test_samples:
                    test_samples[cat_name] = []
                test_samples[cat_name].append(path)

        print(f"[fast_slow_infer] æµ‹è¯•æ•°æ®é›†åŒ…å« {len(test_samples)} ä¸ªç±»åˆ«")
        
        # æ‰§è¡Œæ¨ç†å¹¶ä¿å­˜ç»“æœ
        total_processed = 0
        from tqdm import tqdm
        for true_cat, paths in tqdm(test_samples.items(), desc="Processing inference"):
            for path in paths:
                try:
                    # æ‰§è¡Œå¿«æ€è€ƒ
                    fast_result = system.fast_thinking.fast_thinking_pipeline(path, top_k=5)
                    
                    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ…¢æ€è€ƒ
                    need_slow_thinking = fast_result["need_slow_thinking"]
                    
                    inference_data = {
                        "query_image": path,
                        "true_category": true_cat,
                        "fast_result": fast_result,
                        "need_slow_thinking": need_slow_thinking,
                        "slow_result": None,
                        # ä¿å­˜åˆ†ç±»å‰å¿…é¡»çš„æ‰€æœ‰ä¿¡æ¯
                        "fast_top_k": fast_result.get("img_results", [])[:5] + fast_result.get("text_results", [])[:5],  # å¿«æ€è€ƒTop-Kå€™é€‰
                        "fast_fused_results": fast_result.get("fused_results", [])[:5],  # èåˆåçš„Top-K
                        "timestamp": time.time()
                    }
                    
                    # å¦‚æœéœ€è¦æ…¢æ€è€ƒï¼Œæ‰§è¡Œæ…¢æ€è€ƒ
                    if need_slow_thinking:
                        slow_result = system.slow_thinking.slow_thinking_pipeline_update(path, fast_result, top_k=5)
                        inference_data["slow_result"] = slow_result
                        # ä¿å­˜æ…¢æ€è€ƒçš„Top-Kå€™é€‰ä¿¡æ¯
                        inference_data["slow_top_k"] = slow_result.get("enhanced_results", [])[:5] if slow_result else []
                    
                    # ä¿å­˜æ¨ç†ç»“æœ
                    base_name = os.path.splitext(os.path.basename(path))[0]
                    safe_cat_name = true_cat.replace(' ', '_').replace('/', '_')
                    infer_file = os.path.join(args.infer_dir, f"{safe_cat_name}_{base_name}.json")
                    
                    dump_json(infer_file, inference_data)
                    total_processed += 1
                    
                    if total_processed % 100 == 0:
                        print(f"å·²å¤„ç† {total_processed} ä¸ªæ ·æœ¬")
                        
                except Exception as e:
                    print(f"å¤„ç†å¤±è´¥ {path}: {e}")
                    continue
        
        print(f"æ¨ç†å®Œæˆï¼å…±å¤„ç† {total_processed} ä¸ªæ ·æœ¬")
        print(f"æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {args.infer_dir}")
    
    elif args.mode == 'fast_slow_classify':
        """
        å¿«æ…¢æ€è€ƒåˆ†ç±»æ¨¡å¼ï¼šåŠ è½½æ¨ç†ç»“æœï¼Œæ‰§è¡Œåˆ†ç±»é€»è¾‘å¹¶ç»Ÿè®¡æŒ‡æ ‡
        CUDA_VISIBLE_DEVICES=0 python discovering.py --mode=fast_slow_classify --config_file_env=./configs/env_machine.yml --config_file_expt=./configs/expts/dog120_all.yml --infer_dir=./experiments/dog120/infer --classify_dir=./experiments/dog120/classify
        """
        # è‡ªåŠ¨ç”Ÿæˆæ¨ç†ç»“æœåŠ è½½ç›®å½•å’Œåˆ†ç±»ç»“æœä¿å­˜ç›®å½•
        if args.infer_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.infer_dir = f"./experiments/{dataset_name}{dataset_num}/infer"
        
        if args.classify_dir is None:
            dataset_name = cfg['dataset_name']
            dataset_num = len(DATA_STATS[dataset_name]['class_names'])
            args.classify_dir = f"./experiments/{dataset_name}{dataset_num}/classify"
        
        if not os.path.exists(args.infer_dir):
            raise ValueError(f"æ¨ç†ç»“æœç›®å½•ä¸å­˜åœ¨: {args.infer_dir}")
        
        print(f"ä»ç›®å½•åŠ è½½æ¨ç†ç»“æœ: {args.infer_dir}")
        print(f"åˆ†ç±»ç»“æœå°†ä¿å­˜åˆ°: {args.classify_dir}")
        os.makedirs(args.classify_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆç”¨äºæœ€ç»ˆå†³ç­–ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼‰
        system = FastSlowThinkingSystem(
            model_tag=cfg['model_size_mllm'],
            model_name=cfg['model_size_mllm'],
            device='cuda' if cfg['host'] in ["xiao"] else 'cpu',
            cfg=cfg,
            enable_mllm_intermediate_judge=args.enable_mllm_intermediate_judge
        )
        
        # åŠ è½½æ‰€æœ‰æ¨ç†ç»“æœæ–‡ä»¶
        infer_files = [f for f in os.listdir(args.infer_dir) if f.endswith('.json')]
        print(f"æ‰¾åˆ° {len(infer_files)} ä¸ªæ¨ç†ç»“æœæ–‡ä»¶")
        
        # ç»Ÿè®¡æŒ‡æ ‡
        correct = 0
        total = 0
        fast_only_correct = 0
        slow_triggered = 0
        slow_triggered_correct = 0
        
        classification_results = []
        
        from tqdm import tqdm
        for infer_file in tqdm(infer_files, desc="Processing classification"):
            try:
                infer_path = os.path.join(args.infer_dir, infer_file)
                inference_data = load_json(infer_path)
                
                query_image = inference_data["query_image"]
                true_cat = inference_data["true_category"]
                fast_result = inference_data["fast_result"]
                need_slow_thinking = inference_data["need_slow_thinking"]
                slow_result = inference_data.get("slow_result")
                
                # æ‰§è¡Œåˆ†ç±»é€»è¾‘ï¼ˆå®Œæ•´çš„ä¸‰ç§è·¯å¾„ï¼‰
                if not need_slow_thinking:
                    # è·¯å¾„1: ä»…å¿«æ€è€ƒåˆ†ç±»
                    final_prediction = fast_result["predicted_category"]
                    final_confidence = fast_result["confidence"]
                    used_slow_thinking = False
                    fast_slow_consistent = True
                    decision_path = "fast_only"
                else:
                    # ä½¿ç”¨æ…¢æ€è€ƒç»“æœ
                    if slow_result is None:
                        print(f"è­¦å‘Š: {infer_file} éœ€è¦æ…¢æ€è€ƒä½†æ²¡æœ‰æ…¢æ€è€ƒç»“æœ")
                        continue
                    
                    fast_pred = fast_result.get("predicted_category", "unknown")
                    slow_pred = slow_result["predicted_category"]
                    used_slow_thinking = True
                    
                    # æ£€æŸ¥å¿«æ…¢æ€è€ƒæ˜¯å¦ä¸€è‡´
                    if fast_pred != slow_pred and not is_similar(fast_pred, slow_pred, threshold=0.5):
                        # è·¯å¾„3: å¿«æ…¢ä¸ä¸€è‡´ï¼Œéœ€è¦æœ€ç»ˆè£å†³
                        fast_slow_consistent = False
                        decision_path = "final_arbitration"
                        
                        # è¿™é‡Œå¯ä»¥å®ç°ä¸åŒçš„è£å†³ç­–ç•¥ï¼š
                        # ç­–ç•¥1: ç›´æ¥ç”¨æ…¢æ€è€ƒç»“æœï¼ˆå½“å‰é»˜è®¤ï¼‰
                        final_prediction = slow_pred
                        final_confidence = slow_result["confidence"]
                        
                        # ç­–ç•¥2: å¯é€‰MLLMæœ€ç»ˆè£å†³ï¼ˆéœ€è¦æ—¶å¯å¯ç”¨ï¼‰
                        # if system and hasattr(system, 'final_arbitration'):
                        #     final_prediction, final_confidence = system.final_arbitration(
                        #         query_image, fast_result, slow_result
                        #     )
                        
                        print(f"å¿«æ…¢ä¸ä¸€è‡´: fast={fast_pred}, slow={slow_pred}, è£å†³ç»“æœ={final_prediction}")
                    else:
                        # è·¯å¾„2: å¿«æ…¢æ€è€ƒä¸€è‡´ï¼Œç›´æ¥ç”¨æ…¢æ€è€ƒç»“æœ
                        final_prediction = slow_pred
                        final_confidence = slow_result["confidence"]
                        fast_slow_consistent = True
                        decision_path = "slow_consistent"
                
                # è¯„ä¼°é¢„æµ‹ç»“æœ
                is_correct = is_similar(final_prediction, true_cat, threshold=0.5)
                
                if is_correct:
                    correct += 1
                    if not used_slow_thinking:
                        fast_only_correct += 1
                    if used_slow_thinking:
                        slow_triggered_correct += 1
                        
                if used_slow_thinking:
                    slow_triggered += 1
                
                total += 1
                
                # ä¿å­˜åˆ†ç±»ç»“æœ
                result = {
                    "query_image": query_image,
                    "true_category": true_cat,
                    "final_prediction": final_prediction,
                    "final_confidence": final_confidence,
                    "used_slow_thinking": used_slow_thinking,
                    "fast_slow_consistent": fast_slow_consistent,
                    "decision_path": decision_path,  # è®°å½•å†³ç­–è·¯å¾„
                    "is_correct": is_correct,
                    "fast_prediction": fast_result.get("predicted_category", "unknown"),
                    "fast_confidence": fast_result.get("confidence", 0.0),
                    "slow_prediction": slow_result["predicted_category"] if slow_result else None,
                    "slow_confidence": slow_result["confidence"] if slow_result else None
                }
                
                classification_results.append(result)
                
            except Exception as e:
                print(f"å¤„ç†åˆ†ç±»å¤±è´¥ {infer_file}: {e}")
                continue
        
        # è®¡ç®—å¹¶æ‰“å°æŒ‡æ ‡
        acc = correct / total if total > 0 else 0.0
        fast_only_acc = fast_only_correct / (total-slow_triggered) if (total-slow_triggered) > 0 else 0.0
        slow_trigger_ratio = slow_triggered / total if total > 0 else 0.0
        slow_trigger_acc = slow_triggered_correct / slow_triggered if slow_triggered > 0 else 0.0
        
        print(f"âœ… æ­£ç¡®é¢„æµ‹æ€»æ•°: {correct}")
        print(f"  - å…¶ä¸­ä»…å¿«æ€è€ƒæ­£ç¡®: {fast_only_correct}")
        print(f"  - å…¶ä¸­æ…¢æ€è€ƒè§¦å‘ä¸”æ­£ç¡®: {slow_triggered_correct}")
        print(f"âŒ é”™è¯¯é¢„æµ‹æ€»æ•°: {total - correct}")
        print(f"ğŸ“Š æ…¢æ€è€ƒè§¦å‘æ•°é‡: {slow_triggered}")
        print(f"[fast_slow_classify] æ€»ä½“å‡†ç¡®ç‡: {acc:.4f} ({correct}/{total})")
        print(f"[fast_slow_classify] å¿«æ€è€ƒå‡†ç¡®ç‡: {fast_only_acc:.4f}")
        print(f"[fast_slow_classify] æ…¢æ€è€ƒè§¦å‘æ¯”ä¾‹: {slow_trigger_ratio:.4f}")
        print(f"[fast_slow_classify] æ…¢æ€è€ƒå‡†ç¡®ç‡: {slow_trigger_acc:.4f}")
        
        # ä¿å­˜åˆ†ç±»ç»“æœ
        results_file = os.path.join(args.classify_dir, "classification_results.json")
        dump_json(results_file, {
            "summary": {
                "total_samples": total,
                "correct_predictions": correct,
                "accuracy": acc,
                "fast_only_correct": fast_only_correct,
                "fast_only_accuracy": fast_only_acc,
                "slow_triggered": slow_triggered,
                "slow_trigger_ratio": slow_trigger_ratio,
                "slow_triggered_correct": slow_triggered_correct,
                "slow_trigger_accuracy": slow_trigger_acc
            },
            "detailed_results": classification_results
        })
        
        print(f"åˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    else:
        raise NotImplementedError 

