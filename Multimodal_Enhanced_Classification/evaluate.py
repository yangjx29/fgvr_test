# å¯¼å…¥å‘½ä»¤è¡Œå‚æ•°è§£ææ¨¡å—
import argparse
# å¯¼å…¥æ—¶é—´æ¨¡å—
import time
# å¯¼å…¥æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—
import os
# å¯¼å…¥JSONå¤„ç†æ¨¡å—
import json

# å¯¼å…¥PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
import torch
# å¯¼å…¥PyTorchçš„å‡½æ•°å¼æ¥å£
import torch.nn.functional as F

# å¯¼å…¥å·¥å…·å‡½æ•°ï¼šç»Ÿè®¡æ‘˜è¦ã€å¹³å‡å€¼è®¡ç®—å™¨ã€è¿›åº¦æ˜¾ç¤ºå™¨ã€å‡†ç¡®ç‡è®¡ç®—ã€éšæœºç§å­è®¾ç½®
from utils.tools import Summary, AverageMeter, ProgressMeter, accuracy, set_random_seed
# å¯¼å…¥ç±»åˆ«åç§°è·å–å‡½æ•°å’Œè‡ªå®šä¹‰æ¨¡æ¿
from data.cls_to_names import get_classnames, CUSTOM_TEMPLATES

# å¯¼å…¥CLIPæ¨¡å‹
from clip import clip
# åŠ è½½CLIPæ¨¡å‹åˆ°CPU
# å‚æ•°:
#   arch: æ¨¡å‹æ¶æ„åç§°ï¼ˆå¦‚'ViT-B/16'ï¼‰
# è¿”å›:
#   model: åŠ è½½å¥½çš„CLIPæ¨¡å‹
def load_clip_to_cpu(arch):
    # è·å–æ¨¡å‹çš„ä¸‹è½½URL
    url = clip._MODELS[arch]
    # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
    model_path = clip._download(url)
    try:
        # å°è¯•åŠ è½½JITç¼–è¯‘çš„æ¨¡å‹
        model = torch.jit.load(model_path, map_location="cpu").eval()
        state_dict = None
    except RuntimeError:
        # å¦‚æœJITåŠ è½½å¤±è´¥ï¼Œåˆ™åŠ è½½çŠ¶æ€å­—å…¸
        state_dict = torch.load(model_path, map_location="cpu")
    # æ„å»ºCLIPæ¨¡å‹
    model = clip.build_model(state_dict or model.state_dict())
    return model

# è®¡ç®—æ‰¹æ¬¡çš„ç†µå€¼
# å‚æ•°:
#   logits: æ¨¡å‹è¾“å‡ºçš„logitså¼ é‡
# è¿”å›:
#   entropy: ç†µå€¼å¼ é‡
def calculate_batch_entropy(logits):
    # ä½¿ç”¨ç†µçš„å…¬å¼: H = -Î£(p * log(p))
    return -(logits.softmax(-1) * logits.log_softmax(-1)).sum(-1)

# åŸºäºç†µè®¡ç®—å›¾åƒå’Œæ–‡æœ¬çš„æƒé‡
# è¿™æ˜¯AWTæ–¹æ³•çš„æ ¸å¿ƒï¼šä½¿ç”¨ç†µæ¥è¡¡é‡ä¸ç¡®å®šæ€§ï¼Œç†µè¶Šä½è¡¨ç¤ºè¶Šç¡®å®šï¼Œæƒé‡è¶Šé«˜
# å‚æ•°:
#   output: æ¨¡å‹è¾“å‡º shape: (n_views, n_prompts, n_classes)
#   img_t: å›¾åƒæ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼Œé»˜è®¤0.5
#   text_t: æ–‡æœ¬æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼Œé»˜è®¤0.5
# è¿”å›:
#   image_weights: å›¾åƒæƒé‡ shape: (n_views,)
#   text_weights: æ–‡æœ¬æƒé‡ shape: (n_classes, n_descriptors)
@torch.no_grad()
def get_entropy_weight(output, img_t=0.5, text_t=0.5):
    with torch.cuda.amp.autocast():
        # è®¡ç®—å›¾åƒçš„æƒé‡
        # å¯¹æ¯ä¸ªè§†å›¾åœ¨æ‰€æœ‰æè¿°ç¬¦ä¸Šå–å¹³å‡ï¼Œç„¶åè®¡ç®—ç†µ
        image_entropy = calculate_batch_entropy(output.mean(1))
        # ä½¿ç”¨è´Ÿç†µé€šè¿‡softmaxå¾—åˆ°æƒé‡ï¼ˆç†µè¶Šä½ï¼Œæƒé‡è¶Šé«˜ï¼‰
        image_weights = F.softmax(-image_entropy/img_t, dim=-1)

        # è®¡ç®—æè¿°ç¬¦ï¼ˆæ–‡æœ¬ï¼‰çš„æƒé‡
        _, n_des, n_cls = output.shape  # è·å–æè¿°ç¬¦æ•°é‡å’Œç±»åˆ«æ•°é‡
        # åˆ›å»ºé”šç‚¹ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªè§†å›¾çš„å¹³å‡é¢„æµ‹ä½œä¸ºåŸºå‡†
        anchor = output[0].mean(0)[None, None, :].repeat(n_des, n_cls, 1)
        # è·å–æ¯ä¸ªæè¿°ç¬¦çš„è¾“å‡º
        output_des = output[0].unsqueeze(-1)
        # åˆ›å»ºscatterç´¢å¼•
        scatter_indices = torch.arange(n_cls)[None, :, None].repeat(n_des, 1, 1).cuda()
        # å°†æ¯ä¸ªæè¿°ç¬¦çš„é¢„æµ‹æ•£å¸ƒåˆ°å¯¹åº”çš„ç±»åˆ«ä½ç½®
        anchor.scatter_(dim=2, index=scatter_indices, src=output_des) # shape: (n_des, n_cls, n_cls)
        # è®¡ç®—æ–‡æœ¬ç†µ
        text_entropy = calculate_batch_entropy(anchor)
        # ä½¿ç”¨è´Ÿç†µé€šè¿‡softmaxå¾—åˆ°æƒé‡
        text_weights = F.softmax(-text_entropy.t()/text_t, dim=-1) # shape: (n_cls, n_des)

    return image_weights, text_weights

# åŸºäºç†µè®¡ç®—å›¾åƒå’Œæ–‡æœ¬çš„æƒé‡ï¼ˆæµ‹è¯•ç‰ˆæœ¬1ï¼‰
# ä¿®æ”¹ï¼šå…ˆè®¡ç®—æ–‡æœ¬æƒé‡ï¼Œå†ç”¨æ–‡æœ¬æƒé‡åŠ æƒå¹³å‡æ¥è®¡ç®—å›¾åƒæƒé‡
# å‚æ•°:
#   output: æ¨¡å‹è¾“å‡º shape: (n_views, n_prompts, n_classes)
#   img_t: å›¾åƒæ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼Œé»˜è®¤0.5
#   text_t: æ–‡æœ¬æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼Œé»˜è®¤0.5
# è¿”å›:
#   image_weights: å›¾åƒæƒé‡ shape: (n_views,)
#   text_weights: æ–‡æœ¬æƒé‡ shape: (n_classes, n_descriptors)
@torch.no_grad()
def get_entropy_weight_test1(output, img_t=0.5, text_t=0.5):
    with torch.cuda.amp.autocast():
        _, n_des, n_cls = output.shape  # è·å–æè¿°ç¬¦æ•°é‡å’Œç±»åˆ«æ•°é‡
        
        # ç¬¬ä¸€æ­¥ï¼šå…ˆè®¡ç®—æè¿°ç¬¦ï¼ˆæ–‡æœ¬ï¼‰çš„æƒé‡
        # åˆ›å»ºé”šç‚¹ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªè§†å›¾çš„å¹³å‡é¢„æµ‹ä½œä¸ºåŸºå‡†
        anchor = output[0].mean(0)[None, None, :].repeat(n_des, n_cls, 1)
        # è·å–æ¯ä¸ªæè¿°ç¬¦çš„è¾“å‡º
        output_des = output[0].unsqueeze(-1)
        # åˆ›å»ºscatterç´¢å¼•
        scatter_indices = torch.arange(n_cls)[None, :, None].repeat(n_des, 1, 1).cuda()
        # å°†æ¯ä¸ªæè¿°ç¬¦çš„é¢„æµ‹æ•£å¸ƒåˆ°å¯¹åº”çš„ç±»åˆ«ä½ç½®
        anchor.scatter_(dim=2, index=scatter_indices, src=output_des) # shape: (n_des, n_cls, n_cls)
        # è®¡ç®—æ–‡æœ¬ç†µ
        text_entropy = calculate_batch_entropy(anchor)
        # ä½¿ç”¨è´Ÿç†µé€šè¿‡softmaxå¾—åˆ°æƒé‡
        text_weights = F.softmax(-text_entropy.t()/text_t, dim=-1) # shape: (n_cls, n_des)
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨æ–‡æœ¬æƒé‡åŠ æƒå¹³å‡æ¥è®¡ç®—å›¾åƒçš„æƒé‡
        # output shape: (n_views, n_des, n_cls)
        # text_weights shape: (n_cls, n_des)
        # å¯¹æ¯ä¸ªè§†å›¾ï¼Œä½¿ç”¨æ–‡æœ¬æƒé‡å¯¹æè¿°ç¬¦ç»´åº¦è¿›è¡ŒåŠ æƒå¹³å‡
        # éœ€è¦å°†text_weightsè½¬ç½®å¹¶æ‰©å±•ä»¥åŒ¹é…outputçš„å½¢çŠ¶
        text_weights_expanded = text_weights.t().unsqueeze(0)  # shape: (1, n_des, n_cls)
        # å¯¹æ¯ä¸ªç±»åˆ«ä½¿ç”¨å¯¹åº”çš„æ–‡æœ¬æƒé‡è¿›è¡ŒåŠ æƒå¹³å‡
        weighted_output = (output * text_weights_expanded).sum(dim=1)  # shape: (n_views, n_cls)
        # è®¡ç®—å›¾åƒç†µ
        image_entropy = calculate_batch_entropy(weighted_output)
        # ä½¿ç”¨è´Ÿç†µé€šè¿‡softmaxå¾—åˆ°æƒé‡ï¼ˆç†µè¶Šä½ï¼Œæƒé‡è¶Šé«˜ï¼‰
        image_weights = F.softmax(-image_entropy/img_t, dim=-1)

    return image_weights, text_weights

# åŸºäºç½®ä¿¡åº¦è®¡ç®—å›¾åƒå’Œæ–‡æœ¬çš„æƒé‡ï¼ˆæµ‹è¯•ç‰ˆæœ¬2ï¼‰
# ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨softmaxç½®ä¿¡åº¦è€Œä¸æ˜¯ç†µæ¥è®¡ç®—æƒé‡
# å‚æ•°:
#   output: æ¨¡å‹è¾“å‡º shape: (n_views, n_prompts, n_classes)
#   img_t: å›¾åƒæ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼Œé»˜è®¤0.5
#   text_t: æ–‡æœ¬æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æƒé‡åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼Œé»˜è®¤0.5
# è¿”å›:
#   image_weights: å›¾åƒæƒé‡ shape: (n_views,)
#   text_weights: æ–‡æœ¬æƒé‡ shape: (n_classes, n_descriptors)
@torch.no_grad()
def get_entropy_weight_test2(output, img_t=0.5, text_t=0.5):
    with torch.cuda.amp.autocast():
        # è®¡ç®—å›¾åƒçš„æƒé‡
        # å¯¹æ¯ä¸ªè§†å›¾åœ¨æ‰€æœ‰æè¿°ç¬¦ä¸Šå–å¹³å‡ï¼Œç„¶åè®¡ç®—æœ€å¤§ç½®ä¿¡åº¦
        image_confidence = output.mean(1).softmax(-1).max(-1)[0]  # shape: (n_views,)
        # ä½¿ç”¨ç½®ä¿¡åº¦é€šè¿‡softmaxå¾—åˆ°æƒé‡ï¼ˆç½®ä¿¡åº¦è¶Šé«˜ï¼Œæƒé‡è¶Šé«˜ï¼‰
        image_weights = F.softmax(image_confidence/img_t, dim=-1)

        # è®¡ç®—æè¿°ç¬¦ï¼ˆæ–‡æœ¬ï¼‰çš„æƒé‡
        _, n_des, n_cls = output.shape  # è·å–æè¿°ç¬¦æ•°é‡å’Œç±»åˆ«æ•°é‡
        # åˆ›å»ºé”šç‚¹ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªè§†å›¾çš„å¹³å‡é¢„æµ‹ä½œä¸ºåŸºå‡†
        anchor = output[0].mean(0)[None, None, :].repeat(n_des, n_cls, 1)
        # è·å–æ¯ä¸ªæè¿°ç¬¦çš„è¾“å‡º
        output_des = output[0].unsqueeze(-1)
        # åˆ›å»ºscatterç´¢å¼•
        scatter_indices = torch.arange(n_cls)[None, :, None].repeat(n_des, 1, 1).cuda()
        # å°†æ¯ä¸ªæè¿°ç¬¦çš„é¢„æµ‹æ•£å¸ƒåˆ°å¯¹åº”çš„ç±»åˆ«ä½ç½®
        anchor.scatter_(dim=2, index=scatter_indices, src=output_des) # shape: (n_des, n_cls, n_cls)
        # è®¡ç®—æ–‡æœ¬ç½®ä¿¡åº¦ï¼ˆä½¿ç”¨æœ€å¤§softmaxæ¦‚ç‡ï¼‰
        text_confidence = anchor.softmax(-1).max(-1)[0]  # shape: (n_des, n_cls)
        # ä½¿ç”¨ç½®ä¿¡åº¦é€šè¿‡softmaxå¾—åˆ°æƒé‡
        text_weights = F.softmax(text_confidence.t()/text_t, dim=-1) # shape: (n_cls, n_des)

    return image_weights, text_weights

# Sinkhornç®—æ³•ï¼šç”¨äºæ±‚è§£æœ€ä¼˜ä¼ è¾“é—®é¢˜
# è¿™æ˜¯ä¸€ç§è¿­ä»£ç®—æ³•ï¼Œç”¨äºæ‰¾åˆ°ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„æœ€ä¼˜ä¼ è¾“çŸ©é˜µ
# å‚æ•°:
#   K: æ ¸çŸ©é˜µ (kernel matrix)
#   u: æºåˆ†å¸ƒ
#   v: ç›®æ ‡åˆ†å¸ƒ
# è¿”å›:
#   T: æœ€ä¼˜ä¼ è¾“çŸ©é˜µ
def Sinkhorn(K, u, v):
    # åˆå§‹åŒ–è¡Œå’Œåˆ—çš„ç¼©æ”¾å› å­
    r = torch.ones_like(u)
    c = torch.ones_like(v)
    thresh = 1e-2  # æ”¶æ•›é˜ˆå€¼
    # è¿­ä»£æ›´æ–°ï¼Œæœ€å¤š100æ¬¡
    for i in range(100):
        r0 = r  # ä¿å­˜ä¸Šä¸€æ¬¡çš„rå€¼ç”¨äºæ£€æŸ¥æ”¶æ•›
        # æ›´æ–°è¡Œç¼©æ”¾å› å­
        r = u / torch.matmul(K, c.unsqueeze(-1)).squeeze(-1)
        # æ›´æ–°åˆ—ç¼©æ”¾å› å­
        c = v / torch.matmul(K.permute(0, 2, 1).contiguous(), r.unsqueeze(-1)).squeeze(-1)
        # è®¡ç®—è¯¯å·®
        err = (r - r0).abs().mean()
        # å¦‚æœæ”¶æ•›åˆ™æå‰é€€å‡º
        if err.item() < thresh:
            break
    # è®¡ç®—æœ€ä¼˜ä¼ è¾“çŸ©é˜µ
    T = torch.matmul(r.unsqueeze(-1), c.unsqueeze(-2)) * K
    return T

# ä½¿ç”¨æœ€ä¼˜ä¼ è¾“è®¡ç®—åŠ æƒçš„logits
# è¿™æ˜¯AWTæ–¹æ³•çš„Transportationéƒ¨åˆ†
# å‚æ•°:
#   logits: åŸå§‹logits shape: (n_views, n_prompts, n_classes)
#   logit_scale: CLIPçš„logitç¼©æ”¾å‚æ•°
#   image_weights: å›¾åƒæƒé‡
#   text_weights: æ–‡æœ¬æƒé‡
# è¿”å›:
#   weighted_logits: åŠ æƒåçš„logits shape: (1, n_classes)
def optimal_transport(logits, logit_scale, image_weights, text_weights):
    eps = 0.1  # ç†µæ­£åˆ™åŒ–å‚æ•°
    # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå½’ä¸€åŒ–çš„logitsï¼‰
    sim = logits / logit_scale.exp()
    sim = sim.permute(2, 0, 1) # è½¬æ¢ä¸º (n_classes, n_views, n_prompts)

    # è®¡ç®—Wassersteinè·ç¦»
    wdist = 1.0 - sim
    with torch.no_grad():
        # è®¡ç®—æ ¸çŸ©é˜µ
        KK = torch.exp(-wdist / eps)
        # ä½¿ç”¨Sinkhornç®—æ³•æ±‚è§£æœ€ä¼˜ä¼ è¾“çŸ©é˜µ
        T = Sinkhorn(KK, image_weights, text_weights)
        # è½¬æ¢å›åŸå§‹ç»´åº¦é¡ºåº
        T = T.permute(1, 2, 0)
    # ç¡®ä¿ä¼ è¾“çŸ©é˜µæ²¡æœ‰NaNå€¼
    assert not torch.isnan(T).any()

    # ä½¿ç”¨ä¼ è¾“çŸ©é˜µå¯¹logitsè¿›è¡ŒåŠ æƒæ±‚å’Œ
    return torch.sum(T * logits, dim=(0, 1)).unsqueeze(0)


# AWTè¯„ä¼°å‡½æ•°ï¼šä½¿ç”¨å¢å¼ºã€åŠ æƒå’Œä¼ è¾“æ–¹æ³•è¿›è¡Œé›¶æ ·æœ¬åˆ†ç±»è¯„ä¼°
# å‚æ•°:
#   clip_model: CLIPæ¨¡å‹
#   args: å‘½ä»¤è¡Œå‚æ•°
#   order: æ–¹æ³•é€‰æ‹©
#   use_test_weight: æ˜¯å¦ä½¿ç”¨æµ‹è¯•ç‰ˆæœ¬çš„æƒé‡è®¡ç®—æ–¹æ³•
#   weight_method: æƒé‡è®¡ç®—æ–¹æ³•é€‰æ‹© ('original', 'test1', 'test2')
@torch.no_grad()
def AWT_evaluation(clip_model, args , order, use_test_weight=False, weight_method='original'):
    # è·å–æ•°æ®é›†åç§°å’Œç±»åˆ«åç§°
    dataset_name = args.test_set
    print("Evaluating: {}".format(dataset_name))
    # æ‰“å°å½“å‰ä½¿ç”¨çš„æ–¹æ³•
    if weight_method == 'original':
        weight_desc = "ORIGINAL (Entropy-based)"
    elif weight_method == 'test1':
        weight_desc = "TEST1 (Text-first Entropy)"
    elif weight_method == 'test2':
        weight_desc = "TEST2 (Confidence-based)"
    else:
        weight_desc = "UNKNOWN"
    
    if order==0:
        print(f">>> Using ORIGINAL method: Optimal Transport | Weight: {weight_desc}")
    elif order==1:
        print(f">>> Using ABLATION method: Weighted Cosine Similarity | Weight: {weight_desc}")
    elif order==2:
        print(f">>> Using ABLATION method: OptimalWeighted Cosine Similarity | Weight: {weight_desc}")
    elif order==3:
        print(f">>> Using ABLATION method: Euclidean Distance | Weight: {weight_desc}")
    
    classnames = get_classnames(dataset_name)

    # åŠ è½½LLMç”Ÿæˆçš„ç±»åˆ«æè¿°
    # ImageNetçš„å˜ä½“å…±äº«ç›¸åŒçš„æè¿°æ–‡ä»¶
    if dataset_name in ['imagenet', 'imagenet_a', 'imagenetv2']:
        description_file = os.path.join(args.descriptor_path, 'imagenet.json')
    else:
        description_file = os.path.join(args.descriptor_path, f'{dataset_name}.json')
    print(f'Using description file: {description_file}')
    # åŠ è½½JSONæ ¼å¼çš„æè¿°æ–‡ä»¶
    llm_descriptions = json.load(open(description_file))

    # ============== å‡†å¤‡æ–‡æœ¬ç‰¹å¾ ==============
    text_features = []
    # è·å–æ•°æ®é›†å¯¹åº”çš„æç¤ºæ¨¡æ¿
    template = CUSTOM_TEMPLATES[dataset_name]
    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆæ–‡æœ¬ç‰¹å¾
    print(f"Encoding text features for {len(classnames)} classes...")
    for idx, classname in enumerate(classnames):
        prompts = []
        # ä½¿ç”¨æ¨¡æ¿æ ¼å¼åŒ–ç±»åˆ«åç§°ï¼ˆå°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼ï¼‰
        prompt = template.format(classname.replace("_", " "))
        # æ·»åŠ åŸºç¡€æç¤ºï¼ˆä¸å«æè¿°ï¼‰
        prompts.append(prompt + '.')

        # æ·»åŠ LLMç”Ÿæˆçš„æè¿°
        assert len(llm_descriptions[classname]) >= args.num_descriptor
        for i in range(args.num_descriptor):
            # å°†æè¿°é™„åŠ åˆ°åŸºç¡€æç¤ºå
            prompt_desc = prompt + '. ' + llm_descriptions[classname][i]
            prompts.append(prompt_desc)
        # å¯¹æ‰€æœ‰æç¤ºè¿›è¡Œåˆ†è¯å¹¶ç§»åˆ°GPU
        prompts = torch.cat([clip.tokenize(p) for p in prompts]).cuda()

        # ä½¿ç”¨CLIPç¼–ç æ–‡æœ¬
        with torch.cuda.amp.autocast():
            text_features.append(clip_model.encode_text(prompts)) # shape: (n_descriptors, d)
        
        # æ‰“å°è¿›åº¦
        if (idx + 1) % 10 == 0 or (idx + 1) == len(classnames):
            print(f"  Encoded {idx + 1}/{len(classnames)} classes")

    # æ‹¼æ¥æ‰€æœ‰ç±»åˆ«çš„æ–‡æœ¬ç‰¹å¾
    text_features = torch.cat(text_features).float() # shape: (n_classes * n_descriptors, d)
    # L2å½’ä¸€åŒ–
    text_features = text_features / text_features.norm(dim=-1, keepdim=True)

    # ==============  ä¸ºæ¯å¼ å›¾åƒè®¡ç®—logits ==============
    # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
    batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)  # æ—¶é—´ç»Ÿè®¡
    top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)  # Top-1å‡†ç¡®ç‡

    # åŠ è½½é¢„æå–çš„å›¾åƒç‰¹å¾
    pre_features = torch.load(f"./pre_extracted_feat/{args.arch.replace('/', '')}/seed{args.seed}/{dataset_name}.pth")

    print("number of test samples: {}".format(len(pre_features)))
    # åˆå§‹åŒ–è¿›åº¦æ˜¾ç¤ºå™¨
    progress = ProgressMeter(len(pre_features), [batch_time, top1], prefix='Test: ')

    end = time.time()
    # éå†æ‰€æœ‰é¢„æå–çš„å›¾åƒç‰¹å¾
    for i, (image_features, target) in enumerate(pre_features):
        n_views = image_features.size(0)  # å¢å¼ºè§†å›¾çš„æ•°é‡
        n_prompt = args.num_descriptor + 1  # æç¤ºæ•°é‡ï¼ˆ1ä¸ªåŸºç¡€ + Nä¸ªæè¿°ï¼‰

        # è®¡ç®—å›¾åƒ-æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆlogitsï¼‰
        output = clip_model.logit_scale.exp() * image_features @ text_features.t()
        # é‡å¡‘ä¸º (n_views, n_prompts, n_classes)
        output = output.view(n_views, -1, n_prompt).permute(0, 2, 1).contiguous()

        # è®¾ç½®æ¸©åº¦å‚æ•°
        image_temperature = 0.5
        text_temperature = 0.5
        # åŸºäºç†µè®¡ç®—å›¾åƒå’Œæ–‡æœ¬çš„æƒé‡ï¼ˆWeightingæ­¥éª¤ï¼‰
        if weight_method == 'test1':
            # ä½¿ç”¨æµ‹è¯•ç‰ˆæœ¬1ï¼šå…ˆè®¡ç®—æ–‡æœ¬æƒé‡ï¼Œå†ç”¨æ–‡æœ¬æƒé‡åŠ æƒå¹³å‡è®¡ç®—å›¾åƒæƒé‡
            image_weights, text_weights = get_entropy_weight_test1(output, img_t=image_temperature, text_t=text_temperature)
        elif weight_method == 'test2':
            # ä½¿ç”¨æµ‹è¯•ç‰ˆæœ¬2ï¼šç›´æ¥ä½¿ç”¨ç½®ä¿¡åº¦è€Œä¸æ˜¯ç†µ
            image_weights, text_weights = get_entropy_weight_test2(output, img_t=image_temperature, text_t=text_temperature)
        else:
            # ä½¿ç”¨åŸå§‹ç‰ˆæœ¬ï¼šå…ˆè®¡ç®—å›¾åƒæƒé‡ï¼Œæ–‡æœ¬æƒé‡è®¡ç®—ç‹¬ç«‹
            image_weights, text_weights = get_entropy_weight(output, img_t=image_temperature, text_t=text_temperature)
        
        # ========== æ¶ˆèå®éªŒæ§åˆ¶ ==========
        if order==0:
            # åŸå§‹æ–¹æ³•ï¼šä½¿ç”¨æœ€ä¼˜ä¼ è¾“è¿›è¡ŒåŠ æƒèšåˆï¼ˆTransportationæ­¥éª¤ï¼‰
            output_ot = optimal_transport(output, clip_model.logit_scale, image_weights, text_weights)      
        elif order==1:
            # æ¶ˆèæ–¹æ³•ï¼šä½¿ç”¨åŠ æƒç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦
            # 1. å¯¹å›¾åƒè§†å›¾åŠ æƒå¾—åˆ°åŠ æƒå›¾åƒç‰¹å¾ I
            # image_features shape: (n_views, d)
            # image_weights shape: (n_views,)
            weighted_image_features = (image_features * image_weights.unsqueeze(-1)).sum(dim=0)  # shape: (d,)
            weighted_image_features = weighted_image_features / weighted_image_features.norm()  # L2å½’ä¸€åŒ–
            
            # 2. å¯¹æ–‡æœ¬è§†å›¾åŠ æƒå¾—åˆ°åŠ æƒæ–‡æœ¬ç‰¹å¾ T
            # text_features shape: (n_classes * n_prompts, d)
            # text_weights shape: (n_classes, n_prompts)
            # é‡å¡‘text_featuresä¸º (n_classes, n_prompts, d)
            text_features_reshaped = text_features.view(-1, n_prompt, text_features.size(-1))
            # å¯¹æ¯ä¸ªç±»åˆ«çš„æ–‡æœ¬æè¿°åŠ æƒ
            weighted_text_features = (text_features_reshaped * text_weights.unsqueeze(-1)).sum(dim=1)  # shape: (n_classes, d)
            weighted_text_features = weighted_text_features / weighted_text_features.norm(dim=-1, keepdim=True)  # L2å½’ä¸€åŒ–
            
            # 3. è®¡ç®—åŠ æƒå›¾åƒç‰¹å¾å’ŒåŠ æƒæ–‡æœ¬ç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦
            output_ot = clip_model.logit_scale.exp() * (weighted_image_features @ weighted_text_features.t()).unsqueeze(0)  # shape: (1, n_classes)
        elif order==2:
            # ä¼˜åŒ–çš„ä½™å¼¦ç›¸ä¼¼åº¦åšæ³•ï¼šå›¾åŠ æƒ â†’ ä¸æ¯ä¸ªæ–‡æœ¬è®¡ç®—ç›¸ä¼¼åº¦ â†’ æ–‡æƒé‡åŠ æƒæ±‚å’Œ
            # 1. å¯¹å›¾åƒè§†å›¾åŠ æƒå¾—åˆ°åŠ æƒå›¾åƒç‰¹å¾ Ix
            # image_features shape: (n_views, d)
            # image_weights shape: (n_views,)
            weighted_image_features = (image_features * image_weights.unsqueeze(-1)).sum(dim=0)  # shape: (d,)
            weighted_image_features = weighted_image_features / weighted_image_features.norm()  # L2å½’ä¸€åŒ–
            
            # 2. åŠ æƒå›¾åƒç‰¹å¾ Ix ä¸æ¯ä¸ªæ–‡æœ¬ç‰¹å¾ Tj è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            # text_features shape: (n_classes * n_prompts, d)
            # é‡å¡‘ä¸º (n_classes, n_prompts, d)
            text_features_reshaped = text_features.view(-1, n_prompt, text_features.size(-1))
            # è®¡ç®— cos(Ix, Tj) for all j
            # weighted_image_features shape: (d,)
            # text_features_reshaped shape: (n_classes, n_prompts, d)
            similarities = clip_model.logit_scale.exp() * (weighted_image_features @ text_features_reshaped.permute(0, 2, 1))  # shape: (n_classes, n_prompts)
            
            # 3. ä½¿ç”¨æ–‡æœ¬æƒé‡å¯¹ç›¸ä¼¼åº¦è¿›è¡ŒåŠ æƒæ±‚å’Œ: Î£(WTj * cos(Ix, Tj))
            # text_weights shape: (n_classes, n_prompts)
            # similarities shape: (n_classes, n_prompts)
            output_ot = (text_weights * similarities).sum(dim=1).unsqueeze(0)  # shape: (1, n_classes)

        # è®¡ç®—å‡†ç¡®ç‡
        acc1, = accuracy(output_ot, target, topk=(1,))
        top1.update(acc1[0], 1)

        # æ›´æ–°æ—¶é—´ç»Ÿè®¡
        batch_time.update(time.time() - end)
        end = time.time()

        # å®šæœŸæ˜¾ç¤ºè¿›åº¦
        if (i+1) % args.print_freq == 0:
            progress.display(i)

    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print(f'\n *  {dataset_name}')
    progress.display_summary()

    return top1.avg


# ç®€åŒ–çš„å¤šæ¨¡æ€å¢å¼ºåˆ†ç±»è¯„ä¼°å‡½æ•°ï¼Œä¸“ä¸ºdiscovering.pyé›†æˆè®¾è®¡
@torch.no_grad()
def Multimodal_Enhanced_Classification_evaluation(clip_model, args):
    """
    ç®€åŒ–çš„å¤šæ¨¡æ€å¢å¼ºåˆ†ç±»è¯„ä¼°å‡½æ•°
    ä¸“ä¸ºä¸discovering.pyå¿«æ…¢æ€è€ƒç³»ç»Ÿé›†æˆè€Œè®¾è®¡
    """
    dataset_name = args.test_set
    print(f"ğŸ”„ æ‰§è¡ŒMECè¯„ä¼°: {dataset_name}")
    print("ğŸ¯ ç­–ç•¥: [æµ‹è¯•å›¾-æ–‡] vs [æ£€ç´¢å›¾-æ–‡] åŒ¹é…")
    
    # æ„å»ºç‰¹å¾æ–‡ä»¶è·¯å¾„
    save_dir = f"./pre_extracted_feat/{args.arch.replace('/', '')}/seed{args.seed}"
    retrieved_path = os.path.join(save_dir, f"{dataset_name}_retrieved.pth")
    test_path = os.path.join(save_dir, f"{dataset_name}_test.pth")
    
    print(f"ğŸ“ æ£€ç´¢ç‰¹å¾è·¯å¾„: {retrieved_path}")
    print(f"ğŸ“ æµ‹è¯•ç‰¹å¾è·¯å¾„: {test_path}")
    
    # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(retrieved_path):
        print(f"âŒ æ£€ç´¢ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {retrieved_path}")
        return 0.0
    if not os.path.exists(test_path):
        print(f"âŒ æµ‹è¯•ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {test_path}")
        return 0.0
    
    # åŠ è½½é¢„æå–çš„å¤šæ¨¡æ€ç‰¹å¾
    try:
        retrieved_data = torch.load(retrieved_path, map_location='cuda')
        test_data = torch.load(test_path, map_location='cuda')
    except Exception as e:
        print(f"âŒ åŠ è½½ç‰¹å¾æ–‡ä»¶å¤±è´¥: {e}")
        return 0.0
    
    print(f"ğŸ“Š æ£€ç´¢æ ·æœ¬: {len(retrieved_data)} ä¸ª")
    print(f"ğŸ“Š æµ‹è¯•æ ·æœ¬: {len(test_data)} ä¸ª")
    
    if len(retrieved_data) == 0 or len(test_data) == 0:
        print("âŒ ç‰¹å¾æ•°æ®ä¸ºç©º")
        return 0.0
    
    # åˆå§‹åŒ–ç»Ÿè®¡å™¨
    batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
    top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
    progress = ProgressMeter(len(test_data), [batch_time, top1], prefix='MECæµ‹è¯•: ')
    
    start_time = time.time()
    correct_predictions = 0
    total_predictions = 0
    
    # å¯¹æ¯ä¸ªå¾…æµ‹è¯•æ ·æœ¬è¿›è¡ŒåŒ¹é…
    print("ğŸ”„ å¼€å§‹å¤šæ¨¡æ€ç‰¹å¾åŒ¹é…...")
    for i, (test_features, target) in enumerate(test_data):
        try:
            # ç¡®ä¿ç‰¹å¾åœ¨GPUä¸Š
            if not test_features.is_cuda:
                test_features = test_features.cuda()
            if not target.is_cuda:
                target = target.cuda()
            
            # è®¡ç®—ä¸æ‰€æœ‰æ£€ç´¢æ ·æœ¬çš„ç›¸ä¼¼åº¦
            similarities = []
            retrieved_labels = []
            
            for retrieved_features, retrieved_label in retrieved_data:
                try:
                    # ç¡®ä¿æ£€ç´¢ç‰¹å¾åœ¨GPUä¸Š
                    if not retrieved_features.is_cuda:
                        retrieved_features = retrieved_features.cuda()
                    if not retrieved_label.is_cuda:
                        retrieved_label = retrieved_label.cuda()
                    
                    # è®¡ç®—å¤šæ¨¡æ€ç‰¹å¾æƒé‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘è®¡ç®—å¤æ‚åº¦ï¼‰
                    if test_features.dim() > 1 and test_features.size(0) > 1:
                        # å¤šè§†å›¾æƒ…å†µï¼šä½¿ç”¨å¹³å‡æ± åŒ–ç®€åŒ–
                        weighted_test = test_features.mean(dim=0)
                    else:
                        weighted_test = test_features.squeeze(0) if test_features.dim() > 1 else test_features
                    
                    if retrieved_features.dim() > 1 and retrieved_features.size(0) > 1:
                        # å¤šè§†å›¾æƒ…å†µï¼šä½¿ç”¨å¹³å‡æ± åŒ–ç®€åŒ–
                        weighted_retrieved = retrieved_features.mean(dim=0)
                    else:
                        weighted_retrieved = retrieved_features.squeeze(0) if retrieved_features.dim() > 1 else retrieved_features
                    
                    # L2å½’ä¸€åŒ–
                    weighted_test = weighted_test / (weighted_test.norm() + 1e-8)
                    weighted_retrieved = weighted_retrieved / (weighted_retrieved.norm() + 1e-8)
                    
                    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                    similarity = torch.dot(weighted_test, weighted_retrieved)
                    similarities.append(similarity)
                    retrieved_labels.append(retrieved_label)
                    
                except Exception as e:
                    print(f"âš ï¸  è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ (æ ·æœ¬ {i}): {e}")
                    continue
            
            if len(similarities) == 0:
                print(f"âš ï¸  æ ·æœ¬ {i} æ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼åº¦è®¡ç®—")
                total_predictions += 1
                continue
            
            # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„æ£€ç´¢æ ·æœ¬
            similarities = torch.stack(similarities)
            retrieved_labels = torch.stack(retrieved_labels)
            
            max_idx = torch.argmax(similarities)
            predicted_label = retrieved_labels[max_idx]
            
            # è¯„ä¼°é¢„æµ‹ç»“æœ
            is_correct = (predicted_label == target).item()
            if is_correct:
                correct_predictions += 1
            
            total_predictions += 1
            
            # è®¡ç®—å½“å‰å‡†ç¡®ç‡ç”¨äºè¿›åº¦æ˜¾ç¤º
            current_acc = (correct_predictions / total_predictions) * 100.0
            top1.update(current_acc, 1)
            
            # æ›´æ–°æ—¶é—´ç»Ÿè®¡
            batch_time.update(time.time() - start_time)
            
            # å®šæœŸæ˜¾ç¤ºè¿›åº¦
            if (i + 1) % args.print_freq == 0:
                progress.display(i)
                print(f"  å½“å‰å‡†ç¡®ç‡: {current_acc:.2f}% ({correct_predictions}/{total_predictions})")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æµ‹è¯•æ ·æœ¬ {i} å¤±è´¥: {e}")
            total_predictions += 1
            continue
    
    # è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡
    final_accuracy = (correct_predictions / total_predictions) if total_predictions > 0 else 0.0
    
    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print(f"\n" + "="*60)
    print(f"ğŸ‰ MECè¯„ä¼°å®Œæˆ: {dataset_name}")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_predictions}")
    print(f"âœ… æ­£ç¡®é¢„æµ‹: {correct_predictions}")
    print(f"ğŸ¯ æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)")
    print(f"â±ï¸  æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
    print("="*60)
    
    return final_accuracy


# ç®€åŒ–çš„ä¸»å·¥ä½œå‡½æ•°ï¼Œä¸“ä¸ºdiscovering.pyé›†æˆè®¾è®¡
def main_worker(args):
    """
    ç®€åŒ–çš„ä¸»å·¥ä½œå‡½æ•°
    ä¸“ä¸ºä¸discovering.pyå¿«æ…¢æ€è€ƒç³»ç»Ÿé›†æˆè€Œè®¾è®¡
    """
    print(f"ğŸš€ å¼€å§‹MECè¯„ä¼°: {args.test_set}")
    print(f"ğŸ“ æ¨¡å‹æ¶æ„: {args.arch}")
    
    try:
        # åŠ è½½CLIPæ¨¡å‹
        print("ğŸ”„ åŠ è½½CLIPæ¨¡å‹...")
        clip_model = load_clip_to_cpu(args.arch)
        clip_model = clip_model.cuda()
        clip_model.float()
        clip_model.eval()

        # å†»ç»“æ‰€æœ‰å‚æ•°
        for _, param in clip_model.named_parameters():
            param.requires_grad_(False)
        
        print("âœ… CLIPæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æ‰§è¡Œå¤šæ¨¡æ€å¢å¼ºåˆ†ç±»è¯„ä¼°
        print("ğŸš€ å¼€å§‹å¤šæ¨¡æ€å¢å¼ºåˆ†ç±»è¯„ä¼°...")
        accuracy = Multimodal_Enhanced_Classification_evaluation(clip_model, args)
        
        if accuracy > 0:
            print(f"ğŸ‰ MECè¯„ä¼°å®Œæˆ! å‡†ç¡®ç‡: {accuracy:.4f}")
            return accuracy
        else:
            print("âŒ MECè¯„ä¼°å¤±è´¥!")
            return 0.0
            
    except Exception as e:
        print(f"âŒ MECè¯„ä¼°å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 0.0

# ä¸»ç¨‹åºå…¥å£
if __name__ == '__main__':
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='Multimodal Enhanced Classification evaluation')
    parser.add_argument('--test_set', type=str, help='dataset name')  # æµ‹è¯•æ•°æ®é›†åç§°
    parser.add_argument('-a', '--arch', metavar='ARCH', default='ViT-B/16')  # æ¨¡å‹æ¶æ„
    parser.add_argument('-p', '--print-freq', default=1000, type=int, metavar='N', help='print frequency (default: 10)')  # æ‰“å°é¢‘ç‡
    parser.add_argument('--seed', type=int, default=0)  # éšæœºç§å­
    parser.add_argument('--descriptor_path', type=str)  # æè¿°æ–‡ä»¶è·¯å¾„
    parser.add_argument('--num_descriptor', type=int, default=50)  # æ¯ä¸ªç±»åˆ«ä½¿ç”¨çš„æè¿°æ•°é‡

    args = parser.parse_args()
    # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯é‡å¤æ€§
    set_random_seed(args.seed)
    # å¯åŠ¨ä¸»å·¥ä½œå‡½æ•°
    main_worker(args)
